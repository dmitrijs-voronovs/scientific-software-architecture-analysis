id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/root-project/root/issues/10898:4991,deployability,fail,failures,4991,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5191,deployability,unload,unloading,5191,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5242,deployability,unload,unloaded,5242,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5274,deployability,updat,update,5274,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5384,deployability,unload,unloaded,5384,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5647,deployability,upgrad,upgrade,5647,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:83,energy efficiency,Resourc,ResourceTracker,83,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:707,energy efficiency,optim,optimized,707,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:946,energy efficiency,optim,optimized,946,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1434,energy efficiency,optim,optimized,1434," namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::defau",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2733,energy efficiency,alloc,allocator,2733,"671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2895,energy efficiency,optim,optimized,2895,"5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3400,energy efficiency,Core,Core,3400,"untimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3452,energy efficiency,Resourc,ResourceTracker,3452,"meDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3585,energy efficiency,Core,Core,3585,"0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:52,modifiability,upgrad,upgrade,52,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5647,modifiability,upgrad,upgrade,5647,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:83,performance,Resourc,ResourceTracker,83,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:177,performance,Memor,Memory,177,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:293,performance,Memor,Memory,293,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:707,performance,optimiz,optimized,707,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:946,performance,optimiz,optimized,946,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1139,performance,Memor,MemoryManager,1139,"unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1317,performance,Memor,MemoryManager,1317,"4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1371,performance,Memor,MemoryManager,1371,":releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1434,performance,optimiz,optimized,1434," namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::defau",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1571,performance,Memor,MemoryManager,1571,"ryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1625,performance,Memor,MemoryManager,1625,"ionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1816,performance,Memor,MemoryManager,1816,"ger.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::Runt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1870,performance,Memor,MemoryManager,1870,"oryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7ffffff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2061,performance,Memor,MemoryManager,2061,"p:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2115,performance,Memor,MemoryManager,2115,"vm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2306,performance,Memor,MemoryManager,2306,"ld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2360,performance,Memor,MemoryManager,2360,"ld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2414,performance,Memor,MemoryManager,2414,", __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2468,performance,Memor,MemoryManager,2468,"its/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2656,performance,Memor,MemoryManager,2656,"7feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2710,performance,Memor,MemoryManager,2710,"1. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/ll",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2778,performance,Memor,MemoryManager,2778,":unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2832,performance,Memor,MemoryManager,2832,"ault_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecut",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2895,performance,optimiz,optimized,2895,"5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3452,performance,Resourc,ResourceTracker,3452,"meDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4968,performance,memor,memory,4968,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4991,performance,failur,failures,4991,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4991,reliability,fail,failures,4991,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:83,safety,Resourc,ResourceTracker,83,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3452,safety,Resourc,ResourceTracker,3452,"meDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4986,safety,test,test,4986,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5274,safety,updat,update,5274,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5140,security,hack,hack,5140,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5274,security,updat,update,5274,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:83,testability,Resourc,ResourceTracker,83,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:3452,testability,Resourc,ResourceTracker,3452,"meDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4986,testability,test,test,4986,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5041,testability,assert,assertUnload-auto,5041,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:24,usability,support,support,24,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:177,usability,Memor,Memory,177,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:280,usability,Support,Support,280,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:293,usability,Memor,Memory,293,"TClingCallFunc needs to support unloading; With the upgrade to llvm13, `llvm::orc::ResourceTracker` takes care of deleting the code sections upon unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1139,usability,Memor,MemoryManager,1139,"unloading:. ```. #0 llvm::sys::Memory::releaseMappedMemory (M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/Support/Unix/Memory.inc:162. #1 0x00007fffee4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1317,usability,Memor,MemoryManager,1317,"4988ab in llvm::(anonymous namespace)::DefaultMMapper::releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1371,usability,Memor,MemoryManager,1371,":releaseMappedMemory (. this=0x7ffff6a3c620 <llvm::(anonymous namespace)::DefaultMMapperInstance>, M=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1571,usability,Memor,MemoryManager,1571,"ryManager.cpp:263. #2 0x00007fffee498701 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1625,usability,Memor,MemoryManager,1625,"ionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1816,usability,Memor,MemoryManager,1816,"ger.cpp:237. #3 0x00007fffee4987a0 in llvm::SectionMemoryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::Runt",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:1870,usability,Memor,MemoryManager,1870,"oryManager::~SectionMemoryManager (this=0x5555588b0570, . __in_chrg=<optimized out>). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/SectionMemoryManager.cpp:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7ffffff",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2061,usability,Memor,MemoryManager,2061,"p:239. #4 0x00007fffee41a1b4 in std::default_delete<llvm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2115,usability,Memor,MemoryManager,2115,"vm::RuntimeDyld::MemoryManager>::operator() (this=0x5555587feb70, . __ptr=0x5555588b0570) at /usr/include/c++/11/bits/unique_ptr.h:85. #5 0x00007fffee418420 in std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2306,usability,Memor,MemoryManager,2306,"ld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2360,usability,Memor,MemoryManager,2360,"ld::MemoryManager> >::~unique_ptr (this=0x5555587feb70, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2414,usability,Memor,MemoryManager,2414,", __in_chrg=<optimized out>). at /usr/include/c++/11/bits/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2468,usability,Memor,MemoryManager,2468,"its/unique_ptr.h:361. #6 0x00007fffee41f27f in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__pointer=0x5555587feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2656,usability,Memor,MemoryManager,2656,"7feb70) at /usr/include/c++/11/bits/stl_construct.h:151. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (th",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2710,usability,Memor,MemoryManager,2710,"1. #7 0x00007fffee41e671 in std::_Destroy_aux<false>::__destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/ll",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2778,usability,Memor,MemoryManager,2778,":unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:2832,usability,Memor,MemoryManager,2832,"ault_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:163. #8 0x00007fffee41cf98 in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*> (__first=0x5555587feb70, __last=0x5555587feb78). at /usr/include/c++/11/bits/stl_construct.h:196. #9 0x00007fffee41ae3b in std::_Destroy<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >*, std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > (__first=0x5555587feb70, __last=0x5555587feb78) at /usr/include/c++/11/bits/alloc_traits.h:848. #10 0x00007fffee4192ad in std::vector<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> >, std::allocator<std::unique_ptr<llvm::RuntimeDyld::MemoryManager, std::default_delete<llvm::RuntimeDyld::MemoryManager> > > >::~vector (this=0x7fffffff9280, __in_chrg=<optimized out>). at /usr/include/c++/11/bits/stl_vector.h:680. #11 0x00007fffee4162c1 in llvm::orc::RTDyldObjectLinkingLayer::handleRemoveResources (this=0x55555587cd40, . K=93825045309680). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/RTDyldObjectLinkingLayer.cpp:336. #12 0x00007fffee378503 in llvm::orc::ExecutionSession::removeResourceTracker (this=0x555555cc9bb0, RT=...). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:2162. #13 0x00007fffee36932a in llvm::orc::ResourceTracker::remove (this=0x5555587f28f0). at /home/axel/build/root/llvmupgrade/src/interpreter/llvm/src/lib/ExecutionEngine/Orc/Core.cpp:53. #14 0x00007fffec164fc7 in cling::IncrementalJIT::removeModule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecut",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:4968,usability,memor,memory,4968,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/issues/10898:5153,usability,progress,progress,5153,"dule (this=0x5555557aaed0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:184. #15 0x00007fffec0320a6 in cling::IncrementalExecutor::unloadModule (this=0x555555750eb0, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/IncrementalExecutor.h:181. #16 0x00007fffec031858 in cling::TransactionUnloader::RevertTransaction (this=0x7fffffff9610, T=0x55555886b420). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/TransactionUnloader.cpp:119. #17 0x00007fffec004b0f in cling::Interpreter::unload (this=0x555555607950, T=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1551. #18 0x00007fffec004c64 in cling::Interpreter::unload (this=0x555555607950, numberOfTransactions=1). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/Interpreter/Interpreter.cpp:1572. #19 0x00007fffec28e780 in cling::MetaSema::actOnUCommand (this=0x5555561e0910, file=...). at /home/axel/build/root/llvmupgrade/src/interpreter/cling/lib/MetaProcessor/MetaSema.cpp:222. #20 0x00007fffec2a04dd in cling::MetaParser::isUCommand (this=0x7fffffff9940, . actionResult=@0x7fffffff993c: cling::MetaSema::AR_Success). ```. This leaves `TClingCallFunc::fWrapper` point to invalid memory and causes test failures at least in `roottest-root-meta-callfunc-assertUnload-auto`. I have disabled the deletion of the code segments, but that's just a temporary hack to make progress. We need a callback from the unloading to inform all `TClingCallFunc`s that use unloaded sections (including an update of `gWrapperStore` and friends), such that they can re-emit/-JIT the code if their `Decl` has not been unloaded. This serves as a marker to re-enable the deletion of the Sections, by enabling the `#if 0`'ed code around `interpreter/cling/lib/Interpreter/IncrementalJIT.cpp:189` (in `IncrementalJIT::removeModule(const Transaction& T)`), as introduced by the llvm 13 upgrade.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10898
https://github.com/root-project/root/pull/10899:318,availability,slo,slot,318,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:139,deployability,patch,patch,139,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:492,energy efficiency,load,loading,492,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:503,integrability,event,event,503,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:271,interoperability,share,share,271,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:184,performance,cach,cache,184,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:492,performance,load,loading,492,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:318,reliability,slo,slot,318,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:364,reliability,doe,does,364,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:139,safety,patch,patch,139,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10899:139,security,patch,patch,139,"[DF] Centralize RDefineReaders and RVariationReaders ; Rather than constructing a different reader for each node that. needs it, with this patch we now leverage RColumnRegister as. a ""cache"" of RDefineReaders and RVariationReaders so that nodes. in the computation graph share the same reader objects (per. processing slot). This is analogous to what RLoopManager does. for RDSColumnReaders and RTreeColumnReaders. Sharing column readers across the computation graph will be useful. for bulk loading of event values (which we do not want to repeat. for different instances of a given column's reader).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10899
https://github.com/root-project/root/pull/10900:205,availability,error,error-in-debian-bullseye,205,"Fix generation of G__NetxNG.cxx in paths with special characters; Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10900
https://github.com/root-project/root/pull/10900:199,deployability,build,build-error-in-debian-bullseye,199,"Fix generation of G__NetxNG.cxx in paths with special characters; Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10900
https://github.com/root-project/root/pull/10900:205,performance,error,error-in-debian-bullseye,205,"Fix generation of G__NetxNG.cxx in paths with special characters; Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10900
https://github.com/root-project/root/pull/10900:205,safety,error,error-in-debian-bullseye,205,"Fix generation of G__NetxNG.cxx in paths with special characters; Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10900
https://github.com/root-project/root/pull/10900:205,usability,error,error-in-debian-bullseye,205,"Fix generation of G__NetxNG.cxx in paths with special characters; Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10900
https://github.com/root-project/root/pull/10901:222,deployability,updat,updated,222,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10901:261,interoperability,Format,Formatted,261,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10901:192,safety,test,tested,192,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10901:222,safety,updat,updated,222,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10901:222,security,updat,updated,222,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10901:192,testability,test,tested,192,"[RF] Convert three RooStats tutorials to Python; # This Pull request:. ## Changes or fixes:. Add rs401c_FeldmanCousins.py, IntervalExamples.py, rs_numbercountingutils.py. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). - [x] Formatted with `black --line-length=120 <tutorial file>.py`. This PR is a partial fix for #8758 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10901
https://github.com/root-project/root/pull/10903:286,availability,error,error-in-debian-bullseye,286,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:280,deployability,build,build-error-in-debian-bullseye,280,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:320,deployability,Updat,Update,320,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:333,deployability,modul,modules,333,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:333,modifiability,modul,modules,333,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:286,performance,error,error-in-debian-bullseye,286,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:286,safety,error,error-in-debian-bullseye,286,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:320,safety,Updat,Update,320,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:333,safety,modul,modules,333,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:320,security,Updat,Update,320,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:362,security,auth,authored-by,362,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:415,security,auth,authored-by,415,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10903:286,usability,error,error-in-debian-bullseye,286,"Fix generation of G__NetxNG.cxx in paths with special characters (#10; 900). * Fix generation of G__NetxNG.cxx in paths with special characters. Fix generation of `G__NetxNG.cxx` in paths with special characters, as described on the forum:. https://root-forum.cern.ch/t/6-26-04-build-error-in-debian-bullseye/50412. * Update cmake/modules/RootMacros.cmake. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>. Co-authored-by: Axel Naumann <Axel.Naumann@cern.ch>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10903
https://github.com/root-project/root/pull/10904:34,integrability,Batch,BatchNorm,34,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:87,integrability,Batch,Batch,87,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:107,modifiability,layer,layer,107,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:34,performance,Batch,BatchNorm,34,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:87,performance,Batch,Batch,87,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:14,usability,Support,Support,14,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10904:67,usability,support,support,67,[TMVA][SOFIE] Support for parsing BatchNorm in Keras; This PR adds support for parsing Batch Normalization layer in `SOFIE::PyKeras`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10904
https://github.com/root-project/root/pull/10905:23,availability,state,statement,23,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:62,availability,state,statement,62,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:294,availability,state,statement,294,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:15,deployability,log,logging,15,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:54,deployability,log,logging,54,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:253,deployability,log,logging,253,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:75,energy efficiency,estimat,estimate,75,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:23,integrability,state,statement,23,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:62,integrability,state,statement,62,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:294,integrability,state,statement,294,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:209,performance,time,time,209,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:15,safety,log,logging,15,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:54,safety,log,logging,54,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:253,safety,log,logging,253,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:15,security,log,logging,15,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:54,security,log,logging,54,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:253,security,log,logging,253,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:329,security,control,control,329,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:15,testability,log,logging,15,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:54,testability,log,logging,54,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:253,testability,log,logging,253,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:329,testability,control,control,329,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10905:231,usability,user,user,231,"[DF][NFC] Move logging statement to DEBUG; There is a logging statement to estimate whether the number of requested. partitions is reasonable given the entries in the first file. This. should not happen every time, but on explicit user request. Python. logging defaults to WARNING, so move the statement to DEBUG to give. better control.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10905
https://github.com/root-project/root/pull/10906:147,availability,operat,operator,147,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:177,availability,operat,operator,177,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:230,availability,operat,operator,230,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:243,availability,Error,Errors,243,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:47,performance,memor,memory,47,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:243,performance,Error,Errors,243,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:243,safety,Error,Errors,243,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:47,usability,memor,memory,47,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10906:243,usability,Error,Errors,243,Fix problems in several graf classes; 1. Major memory leak in `TMathText` - renderer was never deleted. 2. `TMathTex`t copy constructor and assign operator. 3. `TLegend` assign operator. 4. `TPaveText` copy constructor and assign operator. 5. Errors in `TPaveText::GetLine` and `TPaveText::GetLineWidth`.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10906
https://github.com/root-project/root/pull/10908:113,availability,error,error,113,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:158,availability,operat,operators,158,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:77,energy efficiency,alloc,allocated,77,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:87,performance,memor,memory,87,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:113,performance,error,error,113,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:113,safety,error,error,113,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:87,usability,memor,memory,87,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10908:113,usability,error,error,113,Fix several `Copy(TObject &)` methods; Typical problem - direct copy of self-allocated memory which will lead to error in destructor. Also adjust some assign operators where `Copy` can be used. .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10908
https://github.com/root-project/root/pull/10909:927,deployability,contain,contained,927,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:28,integrability,Batch,BatchMode,28,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:157,integrability,Batch,BatchMode,157,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:539,modifiability,paramet,parameters,539,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:28,performance,Batch,BatchMode,28,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:157,performance,Batch,BatchMode,157,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:305,usability,visual,visualized,305,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10909:576,usability,user,user-images,576,"[RF] Improvements to RooFit BatchMode for clean and correct computation graph of compiled likelihood; This set commits applies various changes to the RooFit BatchMode with the single goal to have clean and correct computatoin graphs for the compiled likelihoods returned by `createNLL` that can be easily visualized and analyzed. More details in the commit descriptions. Here is an example of how the computation graph for a HistFactory likelihood would look like then, compiled for the RooFitDriver (it's the hf001 example with the alpha parameters removed):. ![nll](https://user-images.githubusercontent.com/6578603/177576443-0f691e16-bfaa-474e-97d3-79b06d232129.png). Idea for a followup on this: right now there is a RooAddition that sums all the channels, and then another RooAddition that sums the channel nlls with the RooConstraintSum. This should be done in one RooAddition. The backport of this PR to ROOT 6.26.06 is contained in this PR:. https://github.com/root-project/root/pull/10986.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10909
https://github.com/root-project/root/pull/10910:51,deployability,modul,modules,51,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:167,deployability,modul,modules,167,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:202,deployability,modul,module,202,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:328,deployability,modul,modules,328,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:26,energy efficiency,load,loading,26,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:144,energy efficiency,load,load,144,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:257,energy efficiency,load,load,257,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:299,energy efficiency,load,loading,299,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:51,modifiability,modul,modules,51,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:167,modifiability,modul,modules,167,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:202,modifiability,modul,module,202,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:328,modifiability,modul,modules,328,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:26,performance,load,loading,26,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:144,performance,load,load,144,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:257,performance,load,load,257,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:299,performance,load,loading,299,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:20,safety,Avoid,Avoid,20,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:51,safety,modul,modules,51,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:167,safety,modul,modules,167,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:202,safety,modul,module,202,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:293,safety,avoid,avoid,293,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:328,safety,modul,modules,328,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:87,security,ident,identifier,87,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10910:337,security,Sign,Signed-off-by,337,"[cxxmodules][cling] Avoid loading some unnecessary modules; When we run into an unkown identifier that is a namespace, we don't. really need to load its corresponding modules. Instead, we create a new. module that forward declared all namespaces and always load it first. By. doing so, we can avoid loading a lot of unnecessary modules. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10910
https://github.com/root-project/root/pull/10911:26,availability,state,state,26,[cling] Reset pragma diag state after fwd decls.; Possibly fixes cling suppressing -Wreturn-type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10911
https://github.com/root-project/root/pull/10911:26,integrability,state,state,26,[cling] Reset pragma diag state after fwd decls.; Possibly fixes cling suppressing -Wreturn-type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10911
https://github.com/root-project/root/pull/10911:14,reliability,pra,pragma,14,[cling] Reset pragma diag state after fwd decls.; Possibly fixes cling suppressing -Wreturn-type.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10911
https://github.com/root-project/root/pull/10912:589,availability,error,error,589,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:633,integrability,event,event,633,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:763,integrability,event,events,763,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:589,performance,error,error,589,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:604,performance,time,time,604,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:589,safety,error,error,589,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:27,testability,context,context,27,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:690,testability,context,context,690,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:589,usability,error,error,589,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10912:658,usability,user,user,658,"[RF] Use generic generator context if RooAddPdf/AddModel have negative coefficients; If a RooAddPdf or RooAddModel has negative coefficients, the. RooAddGenContext can't be used and we need to fall back to the generic. RooGenContext. To achieve this without code duplication, a new templated static. function has been added to the `RooAddGenContext` that returns either a. new RooAddGenContext when there are no negative coeffiecients, or a. generic RooGenContext when there are. If for an existing RooAddGenContext the coeficients of the pdf are. changed to be negative, it will throw an error the next time you try to. generate an event and kindly ask the user to create a new generator. context. It was checked with the example code from #7252 that generating events for AddPdfs with negative coefficients works now. A separate commit in this PR applies some general code modernization to the RooAddGenContext.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10912
https://github.com/root-project/root/pull/10913:30,availability,operat,operator,30,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:203,availability,operat,operator,203,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:342,deployability,updat,updated,342,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:73,safety,test,tests,73,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:174,safety,test,tests,174,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:263,safety,test,tests,263,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:272,safety,valid,validate,272,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:312,safety,test,tested,312,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:342,safety,updat,updated,342,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:272,security,validat,validate,272,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:342,security,updat,updated,342,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:68,testability,unit,unit,68,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:73,testability,test,tests,73,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:169,testability,unit,unit,169,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:174,testability,test,tests,174,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:258,testability,unit,unit,258,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:263,testability,test,tests,263,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10913:312,testability,test,tested,312,"[GSOC][TMVA][SOFIE] Tanh ONNX operator added with the corresponding unit tests; . # This Pull request: Adds the Tanh Activation function to SOFIE with the corresponding unit tests. 1. Adds the Tanh ONNX operator, an activation function to SOFIE. 2. Adds the unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10913
https://github.com/root-project/root/pull/10914:338,deployability,updat,updated,338,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:338,safety,updat,updated,338,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:389,safety,avoid,avoid,389,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:338,security,updat,updated,338,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:13,usability,document,documentation,13,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:206,usability,document,documentation,206,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:300,usability,document,documentation,300,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:372,usability,document,documentation,372,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:481,usability,document,documentation,481,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10914:532,usability,Close,Closes,532,"[RF] Improve documentation for RooChi2Var; In the RooChi2Var and the related `createChi2` functions in RooAbsReal. and RooAbsPdf, the `DataError` was not explained precisely enough. This commit changes the documentation of the RooChi2Var constructor to. exactly explain what is going on, and the the documentation of the. `createChi2` is updated to link to the RooChi2Var documentation to avoid. code duplication. This commit also replaces some LaTeX formulae from titiles in the. documentation because they are not rendered there. Closes #8615.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10914
https://github.com/root-project/root/pull/10915:190,availability,operat,operator,190,"Properly use `Copy(TObject &)` methods in `graf` classes ; This is virtual method and can be overriden in derived classes. Therefore when such method used in copy constructor or assignment. operator, one have to explicitly specify class which used. Fix bug in `TLatex::Copy()`. Provide proper implementation of `TLegend::Copy()`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10915
https://github.com/root-project/root/pull/10915:223,interoperability,specif,specify,223,"Properly use `Copy(TObject &)` methods in `graf` classes ; This is virtual method and can be overriden in derived classes. Therefore when such method used in copy constructor or assignment. operator, one have to explicitly specify class which used. Fix bug in `TLatex::Copy()`. Provide proper implementation of `TLegend::Copy()`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10915
https://github.com/root-project/root/issues/10919:677,availability,Error,ErrorHandler,677,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:459,deployability,Stack,StackTrace,459,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:492,deployability,build,build,492,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:623,deployability,build,build,623,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:710,deployability,build,build,710,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:836,deployability,build,build,836,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:955,deployability,build,build,955,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:1053,deployability,build,build,1053,"ile virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:1267,deployability,build,build,1267," a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cli",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:1403,deployability,build,build,1403,"b64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::T",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:1770,deployability,build,build,1770,"Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::Comp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:1931,deployability,build,build,1931," () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorC",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2211,deployability,build,build,2211,"alizersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2446,deployability,build,build,2446,"07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2630,deployability,build,build,2630,"on*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2824,deployability,build,build,2824,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2960,deployability,build,build,2960,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3089,deployability,build,build,3089,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3189,deployability,build,build,3189,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3296,deployability,build,build,3296,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3407,deployability,build,build,3407,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3497,deployability,build,build,3497,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3596,deployability,build,build,3596,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:3688,deployability,build,build,3688,"ui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem::DispatchOneEvent(bool) () from /home/linev/build/webgui/lib/libCore.so. #23 0x00007f22941cd19c in TSystem::Run() () from /home/linev/build/webgui/lib/libCore.so. #24 0x00007f229415d293 in TApplication::Run(bool) () from /home/linev/build/webgui/lib/libCore.so. #25 0x00007f2294552843 in TRint::Run(bool) () from /home/linev/build/webgui/lib/libRint.so. #26 0x0000000000400e4d in main (). ```. Will be fixed by #10942",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2086,energy efficiency,alloc,allocator,2086,"7f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:2357,energy efficiency,alloc,allocator,2357,"cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interpreter::EvaluateInternal(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::CompilationOptions, cling::Value*, cling::Transaction**, unsigned long) () from /home/linev/build/webgui/lib/libCling.so. #15 0x00007f228efd4f25 in cling::Interpreter::process(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, cling::Value*, cling::Transaction**, bool) () from /home/linev/build/webgui/lib/libCling.so. #16 0x00007f228f0c6b17 in cling::MetaProcessor::process(llvm::StringRef, cling::Interpreter::CompilationResult&, cling::Value*, bool) () from /home/linev/build/webgui/lib/libCling.so. #17 0x00007f228eedaeac in HandleInterpreterException(cling::MetaProcessor*, char const*, cling::Interpreter::CompilationResult&, cling::Value*) () from /home/linev/build/webgui/lib/libCling.so. #18 0x00007f228eefbbb8 in TCling::ProcessLine(char const*, TInterpreter::EErrorCode*) () from /home/linev/build/webgui/lib/libCling.so. #19 0x00007f2294550ab7 in TRint::ProcessLineNr(char const*, char const*, int*) () from /home/linev/build/webgui/lib/libRint.so. #20 0x00007f2294550e8d in TRint::HandleTermInput() () from /home/linev/build/webgui/lib/libRint.so. #21 0x00007f22942c2236 in TUnixSystem::CheckDescriptors() () from /home/linev/build/webgui/lib/libCore.so. #22 0x00007f22942c5198 in TUnixSystem",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:677,performance,Error,ErrorHandler,677,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:677,safety,Error,ErrorHandler,677,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:149,testability,Simpl,Simplest,149,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:149,usability,Simpl,Simplest,149,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10919:677,usability,Error,ErrorHandler,677,"Histograms copy constructor has wrong implementation; While virtual `Copy(TObject &obj)` method is used in copy constructors, wrong cast may happen. Simplest reproducer:. ```. TProfile p;. TH1D h(p);. ```. Causes fatal crash:. ```. Fatal in <TProfile::Copy>: Cannot copy a TProfile in a TH1D. aborting. #0 0x00007f2293b0a83a in wait4 () from /lib64/libc.so.6. #1 0x00007f2293a7403b in do_system () from /lib64/libc.so.6. #2 0x00007f22942c5a3d in TUnixSystem::StackTrace() () from /home/linev/build/webgui/lib/libCore.so. #3 0x00007f229418294c in DefaultErrorHandler(int, bool, char const*, char const*) () from /home/linev/build/webgui/lib/libCore.so. #4 0x00007f22942497bd in ErrorHandler () from /home/linev/build/webgui/lib/libCore.so. #5 0x00007f22941988f4 in TObject::Fatal(char const*, char const*, ...) const () from /home/linev/build/webgui/lib/libCore.so. #6 0x00007f227d6fbde8 in TProfile::Copy(TObject&) const [clone .cold] () from /home/linev/build/webgui/lib/libHist.so. #7 0x00007f227d80aba7 in TH1D::TH1D(TH1D const&) () from /home/linev/build/webgui/lib/libHist.so. #8 0x00007f228c9dc028 in ?? (). #9 0x00007f2293f83460 in ?? (). #10 0x00007f228f062cfe in cling::IncrementalExecutor::runStaticInitializersOnce(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #11 0x00007f228efd6ea4 in cling::Interpreter::executeTransaction(cling::Transaction&) () from /home/linev/build/webgui/lib/libCling.so. #12 0x00007f228f07511c in cling::IncrementalParser::commitTransaction(llvm::PointerIntPair<cling::Transaction*, 2u, cling::IncrementalParser::EParseResult, llvm::PointerLikeTypeTraits<cling::Transaction*>, llvm::PointerIntPairInfo<cling::Transaction*, 2u, llvm::PointerLikeTypeTraits<cling::Transaction*> > >&, bool) () from /home/linev/build/webgui/lib/libCling.so. #13 0x00007f228f076c68 in cling::IncrementalParser::Compile(llvm::StringRef, cling::CompilationOptions const&) () from /home/linev/build/webgui/lib/libCling.so. #14 0x00007f228efd4bb8 in cling::Interp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10919
https://github.com/root-project/root/issues/10920:1076,availability,Error,Error,1076,"trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x00000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1265,availability,avail,available,1265,"### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2908,availability,Operat,Operating,2908, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:116,deployability,contain,contains,116,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:841,deployability,contain,contains,841,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1413,deployability,stack,stack,1413,"ame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1661,deployability,Stack,StackTrace,1661,"Tree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2417,deployability,stack,stack,2417, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2887,deployability,version,version,2887, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:618,integrability,Filter,Filter,618,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2351,integrability,sub,submit,2351, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2887,integrability,version,version,2887, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:34,modifiability,variab,variables,34,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:133,modifiability,variab,variables,133,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:895,modifiability,variab,variable,895,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1189,modifiability,variab,variable,1189,"n 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2887,modifiability,version,version,2887, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1076,performance,Error,Error,1076,"trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x00000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1265,reliability,availab,available,1265,"### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:538,safety,test,testtuple,538,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:710,safety,input,input,710,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:722,safety,test,testtuple,722,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:830,safety,input,input,830,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1076,safety,Error,Error,1076,"trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x00000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1265,safety,avail,available,1265,"### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1265,security,availab,available,1265,"### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://r",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1862,security,sign,signal,1862, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ``,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:538,testability,test,testtuple,538,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:722,testability,test,testtuple,722,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1419,testability,trace,trace,1419,"x"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2423,testability,trace,trace,2423, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:248,usability,behavi,behavior,248,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:290,usability,minim,minimal,290,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:710,usability,input,input,710,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:830,usability,input,input,830,"[DF] RDataFrame confused by array variables in 6.26/04; ### What's wrong. When trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa88",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:1076,usability,Error,Error,1076,"trying to Snapshot a RDataFrame that contains certain variables of the array type, segmentation violation occurs in 6.26/04. This however works in 6.24/00. ### Expected behavior. No crash... ### To Reproduce. A minimal reproducer can be called by running this code. ```C++. #include ""TROOT.h"". #include ""TChain.h"". #include ""ROOT/RDataFrame.hxx"". using namespace ROOT;. void preselect_test(){. ROOT::EnableImplicitMT(3);. TChain tree(""DecayTree"");. tree.Add(""testtuple.root"");. RDataFrame df1(tree);. TCut AllCuts = ""1>0"";. auto df2 = df1.Filter(AllCuts.GetTitle());. df2.Snapshot(""DecayTree"", ""myoutput.root"");. }. ```. where the input file `testtuple.root` can be found here: https://cernbox.cern.ch/index.php/s/ujgGnDwpDpQZo44 . In my example, the input file contains a few branches, in particular the array-type variable `Lambda_DTFL_KS_M` which has a size of `Lambda_DTFL_KS_nPV`. In ROOT 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x00000",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2184,usability,hint,hint,2184, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2228,usability,help,help,2228, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/issues/10920:2499,usability,help,help,2499, 6.24/00 this code runs smoothly producing an output file. In ROOT 6.26/04 the following happens:. ```. Error in <TBranch::TBranch>: Illegal leaf: Lambda_DTFL_KS_M/Lambda_DTFL_KS_M[Lambda_DTFL_KS_nPV]/F. If this is a variable size C array it's possible that the branch holding the size is not available. *** Break *** segmentation violation. ===========================================================. There was a crash. This is the entire stack trace of all threads:. ===========================================================. #0 0x00007f3f0f1ec60c in waitpid () from /lib64/libc.so.6. #1 0x00007f3f0f169f62 in do_system () from /lib64/libc.so.6. #2 0x00007f3f0f79f545 in TUnixSystem::StackTrace() () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #3 0x00007f3f0f79c8c7 in TUnixSystem::DispatchSignals(ESignals) () from /opt/miniconda/envs/root_forge/lib/libCore.so.6.26. #4 <signal handler called>. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. The lines below might hint at the cause of the crash. You may get help by asking at the ROOT forum https://root.cern/forum. Only if you are really convinced it is a bug in ROOT then please submit a. report at https://root.cern/bugs Please post the ENTIRE stack trace. from above as an attachment in addition to anything else. that might help us fixing this issue. ===========================================================. #5 0x00007f3efbe302d0 in ?? (). #6 0x0000009900000224 in ?? (). #7 0x0046561992848cc0 in ?? (). #8 0x00007f3f0fa886ba in ?? () from /opt/miniconda/envs/root_forge/lib/libstdc++.so.6. #9 0x0000000000000000 in ?? (). ===========================================================. ```. ### Setup. 1. ROOT version: 6.26/04. 2. Operating system: centos7. 3. How you obtained ROOT: from conda.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10920
https://github.com/root-project/root/pull/10921:498,deployability,updat,updated,498,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:25,safety,Avoid,Avoid,25,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:110,safety,Avoid,Avoid,110,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:468,safety,test,tested,468,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:498,safety,updat,updated,498,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:498,security,updat,updated,498,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10921:468,testability,test,tested,468,"[RF] RooBarlowBeestonLL: Avoid removing elements of RooArgSet while looping over them ; # This Pull request:. Avoid removing elements of `RooArgSet` in `RooBarlowBeestonLL` while looping over them. This was broken since ROOT v6.18, after `RooAbsCollection` was moved to `std::vector` . This (re)enables the analytical treatment of statistical uncertainties in bins with the Barlow-Beeston-Lite procedure. ## Changes or fixes:. As described above. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10921
https://github.com/root-project/root/pull/10922:261,deployability,instal,installing,261,[skip-ci] Fix an issue with `root-config --has-whatever`; Fix an issue with `root-config --has-whatever` as described on the forum: https://root-forum.cern.ch/t/tpythia8-h-file-not-found/50682. The `all_features` list in the `root-config` script was empty when installing it (but was OK in the build directory).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10922
https://github.com/root-project/root/pull/10922:294,deployability,build,build,294,[skip-ci] Fix an issue with `root-config --has-whatever`; Fix an issue with `root-config --has-whatever` as described on the forum: https://root-forum.cern.ch/t/tpythia8-h-file-not-found/50682. The `all_features` list in the `root-config` script was empty when installing it (but was OK in the build directory).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10922
https://github.com/root-project/root/pull/10923:320,deployability,instal,installing,320,[skip-ci] Fix an issue with `root-config --has-whatever` (#10922); * Fix an issue with `root-config --has-whatever`. Fix an issue with `root-config --has-whatever` as described on the forum: https://root-forum.cern.ch/t/tpythia8-h-file-not-found/50682. The `all_features` list in the `root-config` script was empty when installing it (but was OK in the build directory). * [skip-ci] Fix the comment.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10923
https://github.com/root-project/root/pull/10923:353,deployability,build,build,353,[skip-ci] Fix an issue with `root-config --has-whatever` (#10922); * Fix an issue with `root-config --has-whatever`. Fix an issue with `root-config --has-whatever` as described on the forum: https://root-forum.cern.ch/t/tpythia8-h-file-not-found/50682. The `all_features` list in the `root-config` script was empty when installing it (but was OK in the build directory). * [skip-ci] Fix the comment.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10923
https://github.com/root-project/root/issues/10924:547,availability,Operat,Operating,547,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:622,availability,down,download,622,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:685,availability,Operat,Operating,685,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:535,deployability,version,version,535,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:604,deployability,instal,install,604,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:668,deployability,version,version,668,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:720,deployability,Build,Build,720,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:21,integrability,compon,components,21,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:129,integrability,compon,components,129,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:535,integrability,version,version,535,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:668,integrability,version,version,668,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:21,interoperability,compon,components,21,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:129,interoperability,compon,components,129,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:21,modifiability,compon,components,21,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:129,modifiability,compon,components,129,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:535,modifiability,version,version,535,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:668,modifiability,version,version,668,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:300,usability,user,user-images,300,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/issues/10924:409,usability,behavi,behavior,409,"ROOT can't recognize components in `std::experimental`; - [x] Checked for duplicates. ### Describe the bug. ROOT can't recognize components like `std::experimental::tuple` ( Maybe it is because there're two `tuple`, one in `std` and one in `std::experimental`, so ROOT is confused). ![image](https://user-images.githubusercontent.com/77525145/177772823-0411a239-ecd0-4845-a5f9-966d628d4bb0.png). ### Expected behavior. works fine. ### To Reproduce. type `std::experimental::tuple<int, double> T;` in the repl. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. * ROOT version: main. * Operating System: Ubuntu 22 LTS. * Build ROOT from source.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10924
https://github.com/root-project/root/pull/10926:45,integrability,sub,substring,45,[skip-ci][win] Fix thisroot.bat; Fix correct substring length when setting `ROOTSYS`,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10926
https://github.com/root-project/root/pull/10927:342,availability,cluster,cluster,342,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:517,availability,cluster,cluster,517,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:706,availability,avail,available,706,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1770,availability,cluster,cluster,1770,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1845,availability,cluster,cluster,1845,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:157,deployability,contain,containers,157,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:342,deployability,cluster,cluster,342,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:517,deployability,cluster,cluster,517,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1770,deployability,cluster,cluster,1770,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1845,deployability,cluster,cluster,1845,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1905,deployability,updat,updated,1905,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:317,energy efficiency,alloc,allocates,317,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:762,energy efficiency,alloc,allocated,762,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1240,energy efficiency,current,currently,1240,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1724,energy efficiency,alloc,allocated,1724,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1063,integrability,abstract,abstract,1063,"ll request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distributio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:191,interoperability,distribut,distribution,191,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:369,interoperability,distribut,distribution,369,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:543,interoperability,distribut,distributed,543,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1138,interoperability,distribut,distribution,1138,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:2056,interoperability,distribut,distribution,2056,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1063,modifiability,abstract,abstract,1063,"ll request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distributio",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1476,modifiability,variab,variable,1476,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:706,reliability,availab,available,706,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:706,safety,avail,available,706,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1807,safety,test,tested,1807,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1866,safety,test,tests,1866,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1905,safety,updat,updated,1905,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:706,security,availab,available,706,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:837,security,modif,modifying,837,"[ntuple,daos] Generalize and introduce page-object mapping; This pull request introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping t",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1905,security,updat,updated,1905,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1807,testability,test,tested,1807,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1861,testability,unit,unit,1861,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/pull/10927:1866,testability,test,tests,1866,"uest introduces a structure (`RDaosKey`) to represent a blob's location within DAOS containers (comprising object ID, distribution key and attribute key) and adds a new mapping between ntuple pages to DAOS. The new mapping ( `kOidPerCluster` ) allocates one object per cluster and determines the distribution key from the column ID - with each page addressable by its own attribute key - , thus perpetuating the adjacency of values in the same cluster and column in the distributed store. I.e., neighboring values that are likely to be fetched together are coalesced to the same physical device in DAOS. The original mapping remains available as `kOidPerPage`, where each page is uniquely allocated its own object. In future, other mappings may be easily added by modifying the templated function `GetPageDaosKey` with that use case. RW calls in `RPageStorageDaos` use the mapping set in `kDefaultDaosMapping`, which is `kOidPerCluster`. ## Changes or fixes:. - Introduces `RDaosKey` as an abstract representation of a blob's location in DAOS comprising object ID, distribution key and attribute key. - Mapping strategies are listed in the enumerator `EDaosMapping`, currently with values `kOidPerPage`, `kOidPerCluster`. . - The function `GetPageDaosKey` determines the correct `RDaosKey` from page metadata in accordance with the strategy given by the templated argument of type `EDaosMapping`. - The variable `kDefaultDaosMapping`, set to `kOidPerCluster`, holds the mapping for `RPageStorageDaos` RW calls. - RNTuple page metadata (anchor, header, footer) blobs are mapped to a single object with three attribute keys, while a dedicated object is allocated to hold the pagelists (one for each cluster group). ## Checklist:. - [x] tested changes locally and on openlab cluster: passes unit tests, LHCb dataset on DAOS 2.0. - [x] updated the docs (if necessary). This PR partially fixes #8080 by introducing the new mapping that stores ""page groups"" as sharing the same object and distribution key.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10927
https://github.com/root-project/root/issues/10928:150,usability,help,helpful,150,"SaveGraph producing unclear results, when the TChain has no name; If the underlying TChain has no name (""""), then the output of SaveGraph is far from helpful. The following script:. ```cpp. #include<ROOT/RDataFrame.hxx>. #include<ROOT/RDFHelpers.hxx>. #include<TSystem.h>. using namespace ROOT;. int main(){. ROOT::RDataFrame(1).Define(""x"", ""42"").Snapshot(""t"", ""f.root"");. TChain ch("""");. ch.Add(""f.root?#t"");. RDataFrame df(ch);. auto df2 = df.Count();. ROOT::RDF::SaveGraph(df, ""res.dot"");. gSystem->Exec(""dot -Tpng res.dot -o img_res.png"");. //df.Describe().Print();. }. ```. Produces:. ![img_res](https://user-images.githubusercontent.com/46775299/177795165-da210d75-b4c7-4e42-a66c-6a6bd233c105.png). Example solution: if the chain has no name => call the source node `TChain with no name`. (Remark, same comment is applicable for the `Describe()` action. The commented line would produce `Dataframe from TChain in file f.root [...]`. Notice the 2 spaces after ""TChain"".). CC: @eguiraud @vepadulano",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928
https://github.com/root-project/root/issues/10928:609,usability,user,user-images,609,"SaveGraph producing unclear results, when the TChain has no name; If the underlying TChain has no name (""""), then the output of SaveGraph is far from helpful. The following script:. ```cpp. #include<ROOT/RDataFrame.hxx>. #include<ROOT/RDFHelpers.hxx>. #include<TSystem.h>. using namespace ROOT;. int main(){. ROOT::RDataFrame(1).Define(""x"", ""42"").Snapshot(""t"", ""f.root"");. TChain ch("""");. ch.Add(""f.root?#t"");. RDataFrame df(ch);. auto df2 = df.Count();. ROOT::RDF::SaveGraph(df, ""res.dot"");. gSystem->Exec(""dot -Tpng res.dot -o img_res.png"");. //df.Describe().Print();. }. ```. Produces:. ![img_res](https://user-images.githubusercontent.com/46775299/177795165-da210d75-b4c7-4e42-a66c-6a6bd233c105.png). Example solution: if the chain has no name => call the source node `TChain with no name`. (Remark, same comment is applicable for the `Describe()` action. The commented line would produce `Dataframe from TChain in file f.root [...]`. Notice the 2 spaces after ""TChain"".). CC: @eguiraud @vepadulano",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10928
https://github.com/root-project/root/pull/10929:45,integrability,sub,substring,45,[skip-ci][win] Fix thisroot.bat; Fix correct substring length when setting ROOTSYS.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10929
https://github.com/root-project/root/pull/10930:353,availability,avail,available,353,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:390,deployability,depend,dependent,390,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:646,deployability,depend,depends,646,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:939,deployability,updat,updated,939,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:363,energy efficiency,CPU,CPUs,363,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:390,integrability,depend,dependent,390,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:646,integrability,depend,depends,646,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:507,interoperability,Specif,Specifically,507,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:390,modifiability,depend,dependent,390,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:400,modifiability,variab,variable,400,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:646,modifiability,depend,depends,646,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:363,performance,CPU,CPUs,363,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:353,reliability,availab,available,353,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:751,reliability,doe,does,751,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:353,safety,avail,available,353,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:390,safety,depend,dependent,390,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:646,safety,depend,depends,646,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:909,safety,test,tested,909,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:939,safety,updat,updated,939,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:353,security,availab,available,353,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:478,security,modif,modifyClassWebpage,478,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:522,security,modif,modifyClassWebpages,522,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:564,security,modif,modifyClassWebpage,564,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:623,security,modif,modifyClassWebpage,623,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:859,security,modif,modifyClassWebpage,859,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:939,security,updat,updated,939,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:390,testability,depend,dependent,390,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:646,testability,depend,depends,646,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:909,testability,test,tested,909,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:177,usability,document,documentation,177,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/pull/10930:245,usability,command,command,245,"[Doxygen] fix generation of collaboration diagrams; This pull request applies a number of fixes after the merge or PR #5913 (see below). ## Changes or fixes:. - Fix issues with documentation generation on macOS. In particular: . 1. Fix `mktemp` command lines to only use template `X`s at the end. 2. Use `sysctl -n hw.ncpu` instead to get the number of available CPUs on Darwin. 3. Move OS-dependent variable assignments to the `Makefile`. - Ensure `libs.C` is ACLiC'ed before `modifyClassWebpage.sh` runs. Specifically, `modifyClassWebpages.sh` might spawn many `modifyClassWebpage.sh` processes via `xargs -P`. In turn, `modifyClassWebpage.sh` depends on `libs.C` which is ACLiC'ed if to generate `libs_C.so` where required. However, if `libs_C.so` does not exist, multiple processes might race to create it. Thus, ensure that the macro is ACLiC'ed before `modifyClassWebpage.sh` runs. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10930
https://github.com/root-project/root/issues/10931:632,availability,error,error,632,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/issues/10931:153,energy efficiency,optim,optimal,153,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/issues/10931:430,energy efficiency,optim,optimal,430,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/issues/10931:632,performance,error,error,632,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/issues/10931:632,safety,error,error,632,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/issues/10931:632,usability,error,error,632,"[RF] Improve the position of the legend in the RooMCStudy output; In the ROOT 6.26 the default position of the legend in the output of RooMCStudy is not optimal, as part of numbers is cut away: see the top-right plot in the rf801 example https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html . This used to be better positioned in 6.24: https://root.cern.ch/doc/v624/rf801__mcstudy_8C.html . It would be great to make the position optimal by default. (In the meantime, is there an easy way to change it manually?). Extra wish: would it be possible to invoke the Gaussian fit not only for the pull plot, but also for the ""value"" and ""error"" plots? (The two other plots in the top row of the rf801 example).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10931
https://github.com/root-project/root/pull/10932:7,energy efficiency,core,core,7,Adjust core gui classes; Do not split methods declaration and implementation because of compiler warnings. Use `(void) arg` instead.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10932
https://github.com/root-project/root/pull/10933:28,availability,operat,operators,28,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:77,availability,operat,operator,77,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:131,availability,operat,operator,131,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:288,availability,operat,operator,288,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:41,energy efficiency,core,core,41,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:4,performance,memor,memory,4,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10933:4,usability,memor,memory,4,"Fix memory leaks and assign operators in core classes; 1. In `TExMap` assign operator. 2. In `TRefArray::Init()` method via assign operator. 3. Mark `TSystemDirectory` and `TRefTable` copy constr/assign methods as deleted, default implementation makes only problem. 4. Fix `TTask` assign operator. 5. Initialize `gObjectTable` to `nullptr`",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10933
https://github.com/root-project/root/pull/10935:88,availability,operat,operator,88,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10935:137,availability,operat,operator,137,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10935:251,availability,operat,operator,251,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10935:27,energy efficiency,core,core,27,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10935:54,performance,memor,memory,54,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10935:54,usability,memor,memory,54,Fixes several issues with `core/meta` classes; 1. Fix memory leak in TDataMember assign operator. 2. Provide copy constructor and assign operator for TEnum - default will not work or should be deleted. 3. Not forget to reset pointer in TGlobal assign operator. 4. Make TProtoClass::Delete reentrant.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10935
https://github.com/root-project/root/pull/10936:236,deployability,updat,updated,236,[cling-cpt] Fixed argument nomenclature [skip-ci]; # This Pull request: Rewrote parser arguments for better nomenclature. ## Changes or fixes: Multiple arguments now have with prefix. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936
https://github.com/root-project/root/pull/10936:205,safety,test,tested,205,[cling-cpt] Fixed argument nomenclature [skip-ci]; # This Pull request: Rewrote parser arguments for better nomenclature. ## Changes or fixes: Multiple arguments now have with prefix. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936
https://github.com/root-project/root/pull/10936:236,safety,updat,updated,236,[cling-cpt] Fixed argument nomenclature [skip-ci]; # This Pull request: Rewrote parser arguments for better nomenclature. ## Changes or fixes: Multiple arguments now have with prefix. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936
https://github.com/root-project/root/pull/10936:236,security,updat,updated,236,[cling-cpt] Fixed argument nomenclature [skip-ci]; # This Pull request: Rewrote parser arguments for better nomenclature. ## Changes or fixes: Multiple arguments now have with prefix. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936
https://github.com/root-project/root/pull/10936:205,testability,test,tested,205,[cling-cpt] Fixed argument nomenclature [skip-ci]; # This Pull request: Rewrote parser arguments for better nomenclature. ## Changes or fixes: Multiple arguments now have with prefix. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10936
https://github.com/root-project/root/pull/10937:22,deployability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:84,deployability,depend,dependent,84,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:306,deployability,updat,updated,306,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:22,integrability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:84,integrability,depend,dependent,84,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:22,modifiability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:84,modifiability,depend,dependent,84,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:193,performance,time,time,193,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:248,performance,time,time,248,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:22,safety,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:84,safety,depend,dependent,84,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:275,safety,test,tested,275,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:306,safety,updat,updated,306,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:306,security,updat,updated,306,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:22,testability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:84,testability,depend,dependent,84,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10937:275,testability,test,tested,275,[cling-cpt] Added new dependent arguments [skip-ci]; # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10937
https://github.com/root-project/root/pull/10938:628,interoperability,distribut,distribution,628,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:104,modifiability,paramet,parameter,104,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:395,modifiability,paramet,parameter,395,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:459,modifiability,variab,variable,459,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:13,performance,content,content,13,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:737,security,control,control,737,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:737,testability,control,control,737,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:388,usability,custom,custom,388,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:648,usability,user,user,648,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:821,usability,visual,visualizations,821,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:908,usability,document,documentation,908,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:939,usability,Close,Closes,939,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10938:1066,usability,user,user-images,1066,"[RF] Improve content and position of the RooMCStudy pull plot legend; It can easily happen that the fit parameter labels in the `plotPull()`. produced by the RooMCStudy don't fit on the canvas, for example in the. `rf801` tutorial:. https://root.cern.ch/doc/v626/rf801__mcstudy_8C.html. This commit suggests to improve the likelihood that the labels overshoot. the canvas in two ways:. * custom parameter label text with greek letters instead of. written-out variable letters to save space. * move the labels a bit to the left. If the legend is still not looking good in a given usecase, the Gaussian. should be fit to the pull distribution by the user outside of. `plotPull()`, which only takes a handful lines and then they have full. control over the plot. The built-in Gaussian fit to `plotPull()` is only. for quick visualizations anyway. It is now explained how to do the. Gaussian fit yourself in the documentation of `plotPull()`. Closes #10931. Here is how the output of the `rs401c_FeldmanCousins.py` tutorial looks with this PR:. ![rf801_mcstudy](https://user-images.githubusercontent.com/6578603/178079738-d5490b09-c0a5-4f7a-b8f9-e820cd650304.png).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10938
https://github.com/root-project/root/pull/10941:25,usability,document,documentation,25,[doc] fix typos in cppyy documentation.; Fix typos in cppyy documentation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10941
https://github.com/root-project/root/pull/10941:60,usability,document,documentation,60,[doc] fix typos in cppyy documentation.; Fix typos in cppyy documentation.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10941
https://github.com/root-project/root/pull/10942:189,availability,operat,operator,189,"Properly use `Copy(TObject &)` methods in `hist` classes; This is virtual method and can be overriden in derived classes. Therefore when such method used in copy constructor or assignment. operator, one have to explicitly specify class which used. Fixes #10919",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10942
https://github.com/root-project/root/pull/10942:222,interoperability,specif,specify,222,"Properly use `Copy(TObject &)` methods in `hist` classes; This is virtual method and can be overriden in derived classes. Therefore when such method used in copy constructor or assignment. operator, one have to explicitly specify class which used. Fixes #10919",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10942
https://github.com/root-project/root/pull/10943:318,availability,error,errors,318,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:349,availability,Error,Error,349,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:338,deployability,log,log,338,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:376,deployability,build,build,376,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:569,deployability,updat,updated,569,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:318,performance,error,errors,318,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:349,performance,Error,Error,349,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:318,safety,error,errors,318,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:338,safety,log,log,338,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:349,safety,Error,Error,349,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:539,safety,test,tested,539,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:569,safety,updat,updated,569,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:18,security,modif,modifyClassWebpage,18,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:338,security,log,log,338,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:569,security,updat,updated,569,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:338,testability,log,log,338,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:539,testability,test,tested,539,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:318,usability,error,errors,318,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10943:349,usability,Error,Error,349,"[Doxygen,skipci] `modifyClassWebpage.sh`: remove trailing whitespace after library name; This pull request fixes a remaining issue after merging #5913 and #10930 (see below). ## Changes or fixes:. - Remove the `.so` suffix and any trailing whitespace in the output generated by `libs.C`. This should fix the following errors found in the log:. ```. Error: file /home/sftnight/build/workspace/root-makedoc-master/rootspi/rdoc/master_TMP/html/libRMVA.so __coll__graph.svg not found. ```. - Remove dead code in `libs.C`. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10943
https://github.com/root-project/root/pull/10944:606,availability,cluster,cluster,606,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1676,availability,cluster,cluster,1676,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:606,deployability,cluster,cluster,606,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1676,deployability,cluster,cluster,1676,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1718,deployability,updat,updated,1718,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:689,energy efficiency,optim,optimizations,689,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:784,energy efficiency,Load,LoadClusters,784,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1417,energy efficiency,optim,optimized,1417,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:553,integrability,buffer,buffered,553,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:623,integrability,batch,batch,623,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:741,integrability,batch,batched,741,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1433,integrability,batch,batched,1433,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1541,integrability,interfac,interface,1541,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:864,interoperability,Distribut,Distribution,864,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1541,interoperability,interfac,interface,1541,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:67,modifiability,exten,extends,67,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1522,modifiability,refact,refactored,1522,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1541,modifiability,interfac,interface,1541,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:14,performance,Parallel,Parallelizable,14,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:623,performance,batch,batch,623,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:656,performance,I/O,I/O,656,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:660,performance,parallel,parallelization,660,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:689,performance,optimiz,optimizations,689,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:741,performance,batch,batched,741,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:784,performance,Load,LoadClusters,784,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1417,performance,optimiz,optimized,1417,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1433,performance,batch,batched,1433,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1522,performance,refactor,refactored,1522,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1638,safety,test,tested,1638,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1718,safety,updat,updated,1718,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:160,security,sign,signature,160,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:396,security,modif,modifies,396,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1081,security,ident,identifies,1081,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1274,security,Modif,Modifies,1274,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1718,security,updat,updated,1718,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1638,testability,test,tested,1638,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:417,usability,behavi,behavior,417,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10944:1295,usability,behavi,behavior,1295,"[ntuple,daos] Parallelizable page vector writes; This Pull request extends `RPageSink::RPageSinkDaos` to implement `RPageSinkDaos::CommitSealedPageVImpl()`, of signature: . ```c++. vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(span<RPageStorage::RSealedPageGroup> ranges). ```. , which is virtually declared in the parent class `RPageSink` since PR #10775. . The implemented method modifies the default behavior for committing page ranges, i.e. calling `::CommitSealedPage` repeatedly for each individual page. . Instead, it coalesces the buffered page ranges - e.g. all pages in a column or cluster - into a batch of vector writes, enabling I/O parallelization after recent optimizations to the `RDaos` library. . As with the batched fetching case in `RPageSourceDaos::LoadClusters()`, the page write requests are aggregated by the pair (Object ID, Distribution Key). This pair is part of the `RDaosKey` determined by the mapping strategy set in `kDefaultDaosMapping` from the pages metadata and the `RPageSinkDaos` instance's atomic counter `fPageId` that uniquely identifies pages in the storage sink. ## Changes or fixes:. * Implements `std::vector<RNTupleLocator> RPageSinkDaos::CommitSealedPageVImpl(std::span<RPageStorage::RSealedPageGroup> ranges)`. * Modifies the default behavior in `RPageSink::CommitSealedPageV()` to coalesce pages before sending out the write request to storage. * Enables optimized (i.e. batched) vector write requests of multiple pages within a column range by exploiting the refactored `RDaos` interface and the generalized ntuple-object mappings in `RPageStorageDaos`. ## Checklist:. - [x] tested changes locally and on openlab cluster `olsky-03` with DAOS 2.0.x. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10944
https://github.com/root-project/root/pull/10945:22,deployability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:86,deployability,depend,dependent,86,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:308,deployability,updat,updated,308,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:22,integrability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:86,integrability,depend,dependent,86,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:22,modifiability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:86,modifiability,depend,dependent,86,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:195,performance,time,time,195,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:250,performance,time,time,250,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:22,safety,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:86,safety,depend,dependent,86,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:277,safety,test,tested,277,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:308,safety,updat,updated,308,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:308,security,updat,updated,308,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:22,testability,depend,dependent,22,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:86,testability,depend,dependent,86,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10945:277,testability,test,tested,277,[cling-cpt] Added new dependent arguments [skip-ci]; . # This Pull request: Added new dependent arguments to the argument parser. ## Changes or fixes: Cannot call llvm tar and binary at the same time and cannot call llvm tar and llvm url at the same time. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue mentioned in #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10945
https://github.com/root-project/root/pull/10946:28,availability,Operat,Operator,28,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:132,availability,Operat,Operator,132,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:248,deployability,updat,updated,248,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:86,safety,test,tests,86,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:169,safety,test,tests,169,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:178,safety,valid,validate,178,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:218,safety,test,tested,218,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:248,safety,updat,updated,248,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:178,security,validat,validate,178,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:248,security,updat,updated,248,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:81,testability,unit,unit,81,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:86,testability,test,tests,86,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:164,testability,unit,unit,164,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:169,testability,test,tests,169,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10946:218,testability,test,tested,218,[GSOC][TMVA][SOFIE]Neg ONNX Operator implemented in SOFIE with the corresponding unit tests; # This Pull request: Adds the Neg ONNX Operator with the corresponding unit tests to validate the code. ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10946
https://github.com/root-project/root/pull/10947:241,deployability,updat,updated,241,[RF] Replaced legacy iterators with range-based loops; # This Pull request:. ## Changes or fixes:. Replaced while loops with the legacy iterators fwdIterator() with range based for loops. . ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10947
https://github.com/root-project/root/pull/10947:211,safety,test,tested,211,[RF] Replaced legacy iterators with range-based loops; # This Pull request:. ## Changes or fixes:. Replaced while loops with the legacy iterators fwdIterator() with range based for loops. . ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10947
https://github.com/root-project/root/pull/10947:241,safety,updat,updated,241,[RF] Replaced legacy iterators with range-based loops; # This Pull request:. ## Changes or fixes:. Replaced while loops with the legacy iterators fwdIterator() with range based for loops. . ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10947
https://github.com/root-project/root/pull/10947:241,security,updat,updated,241,[RF] Replaced legacy iterators with range-based loops; # This Pull request:. ## Changes or fixes:. Replaced while loops with the legacy iterators fwdIterator() with range based for loops. . ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10947
https://github.com/root-project/root/pull/10947:211,testability,test,tested,211,[RF] Replaced legacy iterators with range-based loops; # This Pull request:. ## Changes or fixes:. Replaced while loops with the legacy iterators fwdIterator() with range based for loops. . ## Checklist:. - [X] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10947
https://github.com/root-project/root/issues/10948:13,availability,state,statements,13,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:78,availability,error,error,78,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:522,availability,error,error,522,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:745,availability,error,error,745,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2805,availability,state,statements,2805,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2965,availability,state,statements,2965,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3055,availability,state,statement,3055,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3357,availability,Operat,Operating,3357,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2985,deployability,depend,depend,2985,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3336,deployability,version,version,3336,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3407,deployability,fail,fail,3407,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3454,deployability,version,versions,3454,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:13,integrability,state,statements,13,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:528,integrability,messag,message,528,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2805,integrability,state,statements,2805,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2965,integrability,state,statements,2965,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2985,integrability,depend,depend,2985,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3055,integrability,state,statement,3055,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3336,integrability,version,version,3336,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3454,integrability,version,versions,3454,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:528,interoperability,messag,message,528,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2985,modifiability,depend,depend,2985,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3336,modifiability,version,version,3336,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3454,modifiability,version,versions,3454,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:78,performance,error,error,78,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:522,performance,error,error,522,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:745,performance,error,error,745,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2976,reliability,doe,does,2976,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3407,reliability,fail,fail,3407,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:78,safety,error,error,78,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:522,safety,error,error,522,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:745,safety,error,error,745,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2985,safety,depend,depend,2985,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:48,testability,unit,unit,48,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2893,testability,unit,unit,2893,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2985,testability,depend,depend,2985,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3479,testability,context,context,3479,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:3508,testability,context,context,3508,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:78,usability,error,error,78,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:522,usability,error,error,522,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:631,usability,User,Users,631,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:745,usability,error,error,745,"Two ClassImp statements in the same compilation unit result in a redefinition error; - [ x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When compiling some of my classes I got the following error message. The code was compiling before I removed some lines in one of the included header files. ```. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:1659,usability,User,Users,1659,"bmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisSpectrum.cxx:78:1: error: redefinition of 'R__dummyintdefault78'. ClassImp(PairAnalysisSpectrum). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/issues/10948:2679,usability,behavi,behavior,2679,"ne _NAME2_(name1,name2) name1##name2. ^. <scratch space>:81:1: note: expanded from here. R__dummyintdefault78. ^. /Users/uhlig/software/fair/cbm/cbmroot_git/analysis/PWGDIL/dielectron/papaframework/PairAnalysisHistos.h:78:1: note: previous definition is here. ClassImp(PairAnalysisHn). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:361:24: note: expanded from macro 'ClassImp'. #define ClassImp(name) ClassImpUnique(name,default). ^. /opt/fairsoft/apr21p2/include/root/Rtypes.h:356:21: note: expanded from macro 'ClassImpUnique'. static int _R__UNIQUE_(_NAME2_(R__dummyint,key)) __attribute__((unused)) = \. ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:456:27: note: expanded from macro '_R__UNIQUE_'. # define _R__UNIQUE_(X) _R__JOIN_(X,__LINE__). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:453:27: note: expanded from macro '_R__JOIN_'. # define _R__JOIN_(X,Y) _NAME2_(X,Y). ^. /opt/fairsoft/apr21p2/include/root/ROOT/RConfig.hxx:435:33: note: expanded from macro '_NAME2_'. # define _NAME2_(name1,name2) name1##name2. ^. <scratch space>:59:1: note: expanded from here. R__dummyintdefault78. ```. ### Expected behavior. The code should compile without problems. ### To Reproduce. Put together some code which by chance has two ClassImp statements in the same line in two different files which end up in the same compilation unit. In the end it turned out that the name expanded from the ClassImp statements does not depend on the name of the class but only one the line of the ClassImp statement in the code. Both calls. `ClassImp(PairAnalysisSpectrum)` . and . `ClassImp(PairAnalysisHn)`. generated the same name. `R__dummyintdefault78`. which is only defined by the line number. Adding one empty line in one of the files work around the problem. ### Setup. 1. ROOT version: 6.22.08. 2. Operating system: macosx 11 and 12. Probably will fail also on other systems and with newer ROOT versions. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10948
https://github.com/root-project/root/pull/10950:25,energy efficiency,alloc,allocation,25,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:150,energy efficiency,alloc,allocation,150,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:18,performance,memor,memory,18,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:143,performance,memor,memory,143,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:192,performance,memor,memory,192,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:5,safety,Avoid,Avoid,5,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:18,usability,memor,memory,18,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:143,usability,memor,memory,143,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10950:192,usability,memor,memory,192,"[RF] Avoid manual memory allocation in RooConvGenContext; The RooConvGenContext code is modernized to use `std::unique_ptr`. instead of manual memory allocation. In two cases, this also fixes memory leaks where the `RooArgSet * `. returned by `getParameters` was not deleted.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10950
https://github.com/root-project/root/pull/10951:143,deployability,fail,failing,143,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10951:143,reliability,fail,failing,143,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10951:33,safety,test,test,33,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10951:198,security,modif,modified,198,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10951:33,testability,test,test,33,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10951:171,usability,behavi,behaviour,171,"[DF] Fix the broken RDatasetSpec test; `RDatasetSpec({{""tree""s}, {""specTestFile0.root""s}})` was calling the first ctor on unix systems and was failing on windows. Neither behaviour was desired. The modified `RDatasetSpec({{""tree""s, ""specTestFile0.root""s}})` always invokes the third ctor as requested.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10951
https://github.com/root-project/root/pull/10952:1005,deployability,fail,fail,1005,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:611,integrability,event,events,611,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:176,modifiability,paramet,parameters,176,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:711,modifiability,paramet,parameters,711,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:846,modifiability,paramet,parameter,846,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:884,modifiability,paramet,parameters,884,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:1051,modifiability,paramet,parameters,1051,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:12,performance,cach,cache,12,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:158,performance,cach,cache,158,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:213,performance,cach,cache,213,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:689,performance,cach,caching,689,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:789,performance,cach,cache,789,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:839,performance,cach,cached,839,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:1121,performance,cach,cache,1121,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:1005,reliability,fail,fail,1005,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:829,usability,user,user,829,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10952:1113,usability,clear,cleared,1113,"[RF] Remove cache sets in workspace when invalidated by object removal; The RooWorkspace sometimes stores some RooArgSet prefixed with `CACHE_`. in itself to cache for example parameters or constraint sets. These cache sets are invalidated when elements are removed from them by. `RooWorkspace::RecursiveRemove()`. In this case, they should be removed. from the workspace such that they can be correctly recomputed later. This change fixes problems like this one reported on the forum:. https://root-forum.cern.ch/t/how-to-properly-redefine-pdf-in-rooworkspace/50757. In that usecase, the following sequence of events happened:. 1. Create pdf in workspace. 2. Fit this pdf (triggering the caching of the set of parameters). 3. Recursively remove everything from the workspace, but not the cache. sets as they are hidden from the user. The cached parameter sets are. now empty, as all parameters got removed from the workspace. 4. The same pdf from step 1 is recreated. 5. Fitting of this new pdf will now fail, because RooFit thinks it has. zero free parameters, as the call to `getParameters()` now returns. the cleared cache set! An additional commit in this PR applies some general modernization of the RooWorkspace code.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10952
https://github.com/root-project/root/pull/10953:107,integrability,translat,translations,107,[RF] Convert RooStats tutorials to Python ; # This Pull request:. ## Changes or fixes:. These new tutorial translations are added:. * tutorials/roostats/FourBinInstructional.py. * tutorials/roostats/MultivariateGaussianTest.py. * tutorials/roostats/Zbi_Zgamma.py. * tutorials/roostats/rs601_HLFactoryexample.py. * tutorials/roostats/rs701_BayesianCalculator.py. * tutorials/roostats/rs_bernsteinCorrection.py. ## Checklist:. - [x] tested changes locally. - [x] Formatted with black --line-length=120 <tutorial file>.py. This PR is a partial fix for #8758.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10953
https://github.com/root-project/root/pull/10953:107,interoperability,translat,translations,107,[RF] Convert RooStats tutorials to Python ; # This Pull request:. ## Changes or fixes:. These new tutorial translations are added:. * tutorials/roostats/FourBinInstructional.py. * tutorials/roostats/MultivariateGaussianTest.py. * tutorials/roostats/Zbi_Zgamma.py. * tutorials/roostats/rs601_HLFactoryexample.py. * tutorials/roostats/rs701_BayesianCalculator.py. * tutorials/roostats/rs_bernsteinCorrection.py. ## Checklist:. - [x] tested changes locally. - [x] Formatted with black --line-length=120 <tutorial file>.py. This PR is a partial fix for #8758.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10953
https://github.com/root-project/root/pull/10953:461,interoperability,Format,Formatted,461,[RF] Convert RooStats tutorials to Python ; # This Pull request:. ## Changes or fixes:. These new tutorial translations are added:. * tutorials/roostats/FourBinInstructional.py. * tutorials/roostats/MultivariateGaussianTest.py. * tutorials/roostats/Zbi_Zgamma.py. * tutorials/roostats/rs601_HLFactoryexample.py. * tutorials/roostats/rs701_BayesianCalculator.py. * tutorials/roostats/rs_bernsteinCorrection.py. ## Checklist:. - [x] tested changes locally. - [x] Formatted with black --line-length=120 <tutorial file>.py. This PR is a partial fix for #8758.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10953
https://github.com/root-project/root/pull/10953:431,safety,test,tested,431,[RF] Convert RooStats tutorials to Python ; # This Pull request:. ## Changes or fixes:. These new tutorial translations are added:. * tutorials/roostats/FourBinInstructional.py. * tutorials/roostats/MultivariateGaussianTest.py. * tutorials/roostats/Zbi_Zgamma.py. * tutorials/roostats/rs601_HLFactoryexample.py. * tutorials/roostats/rs701_BayesianCalculator.py. * tutorials/roostats/rs_bernsteinCorrection.py. ## Checklist:. - [x] tested changes locally. - [x] Formatted with black --line-length=120 <tutorial file>.py. This PR is a partial fix for #8758.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10953
https://github.com/root-project/root/pull/10953:431,testability,test,tested,431,[RF] Convert RooStats tutorials to Python ; # This Pull request:. ## Changes or fixes:. These new tutorial translations are added:. * tutorials/roostats/FourBinInstructional.py. * tutorials/roostats/MultivariateGaussianTest.py. * tutorials/roostats/Zbi_Zgamma.py. * tutorials/roostats/rs601_HLFactoryexample.py. * tutorials/roostats/rs701_BayesianCalculator.py. * tutorials/roostats/rs_bernsteinCorrection.py. ## Checklist:. - [x] tested changes locally. - [x] Formatted with black --line-length=120 <tutorial file>.py. This PR is a partial fix for #8758.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10953
https://github.com/root-project/root/issues/10954:799,reliability,doe,doesn,799,"[PyROOT] Functions with `const char*` arguments can't accept `ROOT.nullptr`; ### Describe the bug. It is not possible to pass `ROOT.nullptr` to a function that takes a `const char*`. ### Expected behavior. A `ROOT.nullptr` should by accepted by cppyy overloads when a `const char*` is expected. In RooFit, it happens often that the user is expected to pass `nullptr`, for example in [RooAbsArg::setStringAttribute()](https://root.cern.ch/doc/master/classRooAbsArg.html#a3792b218558aba2552f432fbd4d91c9c), where passing a `nullptr` removes an attribute with a given name. So it would be great if PyROOT supports that! ### To Reproduce. ```Python. import ROOT. ROOT.gInterpreter.Declare("""""". void foo(char*) {}. void bar(const char*) {}. """"""). ROOT.foo(ROOT.nullptr) # works! ROOT.bar(ROOT.nullptr) # doesn't work. ```. ### Setup. ROOT `master` on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10954
https://github.com/root-project/root/issues/10954:196,usability,behavi,behavior,196,"[PyROOT] Functions with `const char*` arguments can't accept `ROOT.nullptr`; ### Describe the bug. It is not possible to pass `ROOT.nullptr` to a function that takes a `const char*`. ### Expected behavior. A `ROOT.nullptr` should by accepted by cppyy overloads when a `const char*` is expected. In RooFit, it happens often that the user is expected to pass `nullptr`, for example in [RooAbsArg::setStringAttribute()](https://root.cern.ch/doc/master/classRooAbsArg.html#a3792b218558aba2552f432fbd4d91c9c), where passing a `nullptr` removes an attribute with a given name. So it would be great if PyROOT supports that! ### To Reproduce. ```Python. import ROOT. ROOT.gInterpreter.Declare("""""". void foo(char*) {}. void bar(const char*) {}. """"""). ROOT.foo(ROOT.nullptr) # works! ROOT.bar(ROOT.nullptr) # doesn't work. ```. ### Setup. ROOT `master` on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10954
https://github.com/root-project/root/issues/10954:332,usability,user,user,332,"[PyROOT] Functions with `const char*` arguments can't accept `ROOT.nullptr`; ### Describe the bug. It is not possible to pass `ROOT.nullptr` to a function that takes a `const char*`. ### Expected behavior. A `ROOT.nullptr` should by accepted by cppyy overloads when a `const char*` is expected. In RooFit, it happens often that the user is expected to pass `nullptr`, for example in [RooAbsArg::setStringAttribute()](https://root.cern.ch/doc/master/classRooAbsArg.html#a3792b218558aba2552f432fbd4d91c9c), where passing a `nullptr` removes an attribute with a given name. So it would be great if PyROOT supports that! ### To Reproduce. ```Python. import ROOT. ROOT.gInterpreter.Declare("""""". void foo(char*) {}. void bar(const char*) {}. """"""). ROOT.foo(ROOT.nullptr) # works! ROOT.bar(ROOT.nullptr) # doesn't work. ```. ### Setup. ROOT `master` on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10954
https://github.com/root-project/root/issues/10954:602,usability,support,supports,602,"[PyROOT] Functions with `const char*` arguments can't accept `ROOT.nullptr`; ### Describe the bug. It is not possible to pass `ROOT.nullptr` to a function that takes a `const char*`. ### Expected behavior. A `ROOT.nullptr` should by accepted by cppyy overloads when a `const char*` is expected. In RooFit, it happens often that the user is expected to pass `nullptr`, for example in [RooAbsArg::setStringAttribute()](https://root.cern.ch/doc/master/classRooAbsArg.html#a3792b218558aba2552f432fbd4d91c9c), where passing a `nullptr` removes an attribute with a given name. So it would be great if PyROOT supports that! ### To Reproduce. ```Python. import ROOT. ROOT.gInterpreter.Declare("""""". void foo(char*) {}. void bar(const char*) {}. """"""). ROOT.foo(ROOT.nullptr) # works! ROOT.bar(ROOT.nullptr) # doesn't work. ```. ### Setup. ROOT `master` on Arch Linux.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10954
https://github.com/root-project/root/pull/10955:317,availability,error,error,317,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:122,deployability,version,version,122,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:568,energy efficiency,model,model,568,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:574,energy efficiency,adapt,adapt,574,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:122,integrability,version,version,122,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:574,integrability,adapt,adapt,574,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:730,integrability,event,events,730,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:258,interoperability,format,formatting,258,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:574,interoperability,adapt,adapt,574,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:122,modifiability,version,version,122,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:574,modifiability,adapt,adapt,574,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:317,performance,error,error,317,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:298,safety,avoid,avoid,298,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:317,safety,error,error,317,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:400,safety,avoid,avoid,400,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:769,safety,avoid,avoid,769,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:568,security,model,model,568,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:317,usability,error,error,317,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10955:502,usability,command,command,502,"[RF] Fix wrong fit and improve rf212_plottingInRanges_blinding tutorial; Sone changes are made to both the Python and C++ version of the. `rf212_plottingInRanges_blinding` tutorial:. * move around the `-----` that denote section headers to fix the. notebook formatting. * rename `exp` to `expo` to avoid an ambiguity error because of. `std::expr` in C++ tutorial notebook. * use `std::unique_ptr` to avoid leaking of datasets. In particular, the call to `fitTo` includes now the. `Range(""left,right"")` command argument. Otherthise, the fit would also. try to make the model adapt to the empty bins in the blinded region,. giving a wrong fit result (it can be easily seen that the fit was wrong. before by increasing the number of events in the toy dataset to 100k). To avoid that the plotting takes the (now correct) fit range as. `NormRange()` and we can't show what happens if the normalization range. is not set, the `fitrange` string attribute is reset after fitting.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10955
https://github.com/root-project/root/pull/10956:91,energy efficiency,estimat,estimations,91,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10956:348,integrability,event,event,348,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10956:403,safety,test,test,403,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10956:398,testability,unit,unit,398,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10956:403,testability,test,test,403,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10956:5,usability,Support,Support,5,"[RF] Support weighted datasets in RooKeysPdf; So far, a `RooKeysPdf` produced wrong kernel estimations for weighted. datasets, as sometimes the number of entries was used in place of the. sum of weights. This is fixed now. Also, the normalization by the sum of. weights is moved from the private `RooKeysPdf::g()` function that is. called for each event to the global normalization constant. A new unit test that checks if weighted datasets are correctly handled. by both the RooKeysPdf and the RooNDKeysPdf is also implemented.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10956
https://github.com/root-project/root/pull/10957:317,usability,support,supported,317,"[RF] New `RooAbsArg::removeStringAttribute(const char* key)` method; So far, one had to remove string attributes of a RooAbsArg with the. `RooAbsArg::removeStringAttribute(const char* key, const char* value)`. method, passing `nullptr` as a value. Passing a `nullptr` to a function. that takes a `const char*` is not supported in PyROOT, as explained in. GitHub issue #10954. Therefore, a new function is added to RooAbsArg to. remove a string attribute without having to use `nullptr`. This new function called `removeStringAttribute()` is now used in all. the ROOT code to remove string attributes from RooAbsArgs, and also. mentioned in the warnings that tell the user that they might want to. remove the `fitrange` attribute. The verb `remove` was chosen instead of `delete`, `clear`, or `erase`,. because there was already a `RooAbsArg::removeServer()` method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10957
https://github.com/root-project/root/pull/10957:667,usability,user,user,667,"[RF] New `RooAbsArg::removeStringAttribute(const char* key)` method; So far, one had to remove string attributes of a RooAbsArg with the. `RooAbsArg::removeStringAttribute(const char* key, const char* value)`. method, passing `nullptr` as a value. Passing a `nullptr` to a function. that takes a `const char*` is not supported in PyROOT, as explained in. GitHub issue #10954. Therefore, a new function is added to RooAbsArg to. remove a string attribute without having to use `nullptr`. This new function called `removeStringAttribute()` is now used in all. the ROOT code to remove string attributes from RooAbsArgs, and also. mentioned in the warnings that tell the user that they might want to. remove the `fitrange` attribute. The verb `remove` was chosen instead of `delete`, `clear`, or `erase`,. because there was already a `RooAbsArg::removeServer()` method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10957
https://github.com/root-project/root/pull/10957:781,usability,clear,clear,781,"[RF] New `RooAbsArg::removeStringAttribute(const char* key)` method; So far, one had to remove string attributes of a RooAbsArg with the. `RooAbsArg::removeStringAttribute(const char* key, const char* value)`. method, passing `nullptr` as a value. Passing a `nullptr` to a function. that takes a `const char*` is not supported in PyROOT, as explained in. GitHub issue #10954. Therefore, a new function is added to RooAbsArg to. remove a string attribute without having to use `nullptr`. This new function called `removeStringAttribute()` is now used in all. the ROOT code to remove string attributes from RooAbsArgs, and also. mentioned in the warnings that tell the user that they might want to. remove the `fitrange` attribute. The verb `remove` was chosen instead of `delete`, `clear`, or `erase`,. because there was already a `RooAbsArg::removeServer()` method.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10957
https://github.com/root-project/root/issues/10958:60,deployability,contain,container,60,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/issues/10958:259,deployability,contain,containers,259,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/issues/10958:334,deployability,contain,container,334,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/issues/10958:106,performance,I/O,I/O,106,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/issues/10958:165,usability,document,documentation,165,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/issues/10958:281,usability,support,support,281,"[ntuple,daos] Allow multiple ntuples to be stored in a DAOS container; As per a past discussion on a ROOT I/O meeting with @pcanal and @jblomer, and given that the [documentation](https://docs.daos.io/v2.0/overview/storage/) suggests a limit of ""hundreds"" of containers, we should support storage of multiple ntuples in a single DAOS container.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10958
https://github.com/root-project/root/pull/10959:121,availability,operat,operation,121,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,deployability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:171,deployability,depend,dependency,171,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:312,deployability,depend,dependsOnValue,312,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:777,deployability,releas,released,777,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:590,energy efficiency,model,models,590,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,integrability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:171,integrability,depend,dependency,171,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:312,integrability,depend,dependsOnValue,312,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,interoperability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,modifiability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:171,modifiability,depend,dependency,171,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:312,modifiability,depend,dependsOnValue,312,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,reliability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:171,safety,depend,dependency,171,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:312,safety,depend,dependsOnValue,312,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:836,safety,avoid,avoid,836,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,security,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:590,security,model,models,590,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:14,testability,integr,integral,14,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:171,testability,depend,dependency,171,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10959:312,testability,depend,dependsOnValue,312,"[RF] Speed up integral creation for large computation graphs; In the `RooRealIntegral` constructor, there was a `O(N^2)` operation on. the computation graph, checking the dependency of the top-level function. on each other node. This is very expensive in the numer of RooAbsArgs N. is large. Instead of calling `dependsOnValue` for each leaf node, which is. very expensive because it's a recursive function, the value server. leaves are all put in a RooArgSet before the leaf iteration to check. quickly if a leaf is also a value server. This change speeds up the `createNLL` step of large models like the. ATLAS Higgs combination by at least a factor of two or three. In the same PR, I also bring a little other commit, where the ownership of the `cloneSet` in `cloneTree` is released before removing the top node element, in order to avoid ownership ambiguities.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10959
https://github.com/root-project/root/pull/10960:354,deployability,updat,updated,354,[cling-cpt] Added skip-cleanup flags for check-requirements and create-dev-env [skip-ci]; # This Pull request: Set skip-cleanup flags to true for check-requirements and create-dev-env. ## Changes or fixes: Set the skip-cleanup value to true for the create-dev-env option and check-requirements option. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in meta-issue list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10960
https://github.com/root-project/root/pull/10960:323,safety,test,tested,323,[cling-cpt] Added skip-cleanup flags for check-requirements and create-dev-env [skip-ci]; # This Pull request: Set skip-cleanup flags to true for check-requirements and create-dev-env. ## Changes or fixes: Set the skip-cleanup value to true for the create-dev-env option and check-requirements option. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in meta-issue list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10960
https://github.com/root-project/root/pull/10960:354,safety,updat,updated,354,[cling-cpt] Added skip-cleanup flags for check-requirements and create-dev-env [skip-ci]; # This Pull request: Set skip-cleanup flags to true for check-requirements and create-dev-env. ## Changes or fixes: Set the skip-cleanup value to true for the create-dev-env option and check-requirements option. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in meta-issue list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10960
https://github.com/root-project/root/pull/10960:354,security,updat,updated,354,[cling-cpt] Added skip-cleanup flags for check-requirements and create-dev-env [skip-ci]; # This Pull request: Set skip-cleanup flags to true for check-requirements and create-dev-env. ## Changes or fixes: Set the skip-cleanup value to true for the create-dev-env option and check-requirements option. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in meta-issue list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10960
https://github.com/root-project/root/pull/10960:323,testability,test,tested,323,[cling-cpt] Added skip-cleanup flags for check-requirements and create-dev-env [skip-ci]; # This Pull request: Set skip-cleanup flags to true for check-requirements and create-dev-env. ## Changes or fixes: Set the skip-cleanup value to true for the create-dev-env option and check-requirements option. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue in meta-issue list #406 (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10960
https://github.com/root-project/root/pull/10961:162,availability,servic,services,162,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10961:162,deployability,servic,services,162,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10961:1,energy efficiency,core,core,1,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10961:56,energy efficiency,core,core,56,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10961:162,integrability,servic,services,162,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10961:162,modifiability,servic,services,162,"[core] Replace `sprintnf` calls with `snprintf` in ROOT core; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10961
https://github.com/root-project/root/pull/10962:61,safety,test,tests,61,"[DF] Remove the extra R__USE_IMT fixture in the RDatasetSpec tests; The guard R__USE_IMT was wrongly put around the class declaration, hence. none of the tests inside RDatasetSpecTest would compile if R__USE_IMT is. not defined.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10962
https://github.com/root-project/root/pull/10962:154,safety,test,tests,154,"[DF] Remove the extra R__USE_IMT fixture in the RDatasetSpec tests; The guard R__USE_IMT was wrongly put around the class declaration, hence. none of the tests inside RDatasetSpecTest would compile if R__USE_IMT is. not defined.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10962
https://github.com/root-project/root/pull/10962:61,testability,test,tests,61,"[DF] Remove the extra R__USE_IMT fixture in the RDatasetSpec tests; The guard R__USE_IMT was wrongly put around the class declaration, hence. none of the tests inside RDatasetSpecTest would compile if R__USE_IMT is. not defined.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10962
https://github.com/root-project/root/pull/10962:154,testability,test,tests,154,"[DF] Remove the extra R__USE_IMT fixture in the RDatasetSpec tests; The guard R__USE_IMT was wrongly put around the class declaration, hence. none of the tests inside RDatasetSpecTest would compile if R__USE_IMT is. not defined.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10962
https://github.com/root-project/root/issues/10963:559,availability,Error,Error,559,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:2124,availability,Operat,Operating,2124,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:663,deployability,Modul,Modules,663,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:739,deployability,configurat,configuration,739,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:821,deployability,version,version,821,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:853,deployability,configurat,configuration,853,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:966,deployability,version,version,966,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1036,deployability,version,version,1036,"CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1057,deployability,Stack,Stack,1057," for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `ro",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1113,deployability,releas,releases,1113,"://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1500,deployability,releas,releases,1500,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:2042,deployability,build,build,2042,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:2103,deployability,version,version,2103,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1665,energy efficiency,Core,Core,1665,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:739,integrability,configur,configuration,739,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:821,integrability,version,version,821,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:853,integrability,configur,configuration,853,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:966,integrability,version,version,966,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1036,integrability,version,version,1036,"CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1654,integrability,COMPON,COMPONENTS,1654,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:2103,integrability,version,version,2103,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:646,interoperability,share,share,646,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:795,interoperability,compatib,compatible,795,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1654,interoperability,COMPON,COMPONENTS,1654,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:663,modifiability,Modul,Modules,663,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:739,modifiability,configur,configuration,739,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:762,modifiability,pac,package,762,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:821,modifiability,version,version,821,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:853,modifiability,configur,configuration,853,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:966,modifiability,version,version,966,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1036,modifiability,version,version,1036,"CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1654,modifiability,COMPON,COMPONENTS,1654,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:2103,modifiability,version,version,2103,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:559,performance,Error,Error,559,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1614,performance,content,contents,1614,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:509,safety,compl,complains,509,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:559,safety,Error,Error,559,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:663,safety,Modul,Modules,663,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1996,safety,input,input,1996,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:509,security,compl,complains,509,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:739,security,configur,configuration,739,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:853,security,configur,configuration,853,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:559,usability,Error,Error,559,"[CMake] troubles with ROOT 6.26.04 from CVMFS; - [ ] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1260,usability,clear,clear,1260,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1308,usability,behavi,behavior,1308,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1334,usability,clear,clear,1334,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1851,usability,behavi,behavior,1851,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/issues/10963:1996,usability,input,input,1996,". for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. When trying to compile a project against ROOT 6.26.04 sourced from CVMFS, cmake complains about nlohmann_json missing. ```. CMake Error at /cvmfs/atlas.cern.ch/repo/ATLASLocalRootBase/x86_64/Cmake/3.21.3/Linux-x86_64/share/cmake-3.21/Modules/CMakeFindDependencyMacro.cmake:47 (find_package):. Could not find a configuration file for package ""nlohmann_json"" that is. compatible with requested version ""3.10.5"". The following configuration files were considered but not accepted:. /usr/lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. /lib64/cmake/nlohmann_json/nlohmann_jsonConfig.cmake, version: 3.6.1. Call Stack (most recent call first):. /cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/cmake/ROOTConfig.cmake:114 (find_dependency). CMakeLists.txt:1 (find_package). ```. <!--. A clear and concise description of what the wrong behavior is. -->. <!--. A clear and concise description of what you expected to happen. -->. ### To Reproduce. Use a CentOS7 machine and setup ROOT 6.26.04 from CVMFS. (/cvmfs/sft.cern.ch/lcg/releases/LCG_102/ROOT/6.26.04/x86_64-centos7-gcc11-opt/bin/root). Create a CMakeLists.txt file with the following contents:. `find_package( ROOT REQUIRED COMPONENTS Core RIO MathCore Matrix HistFactory RooFitCore RooFit Hist RooStats Minuit2 Minuit )`. Go to an empty folder, and call `cmake` on that CMakeLists.txt file. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. 1. ROOT version: 6.26.04. 2. Operating system: CentOS7. 3. How you obtained ROOT: ```setupATLAS; lsetup ""root 6.26.04-x86_64-centos7-gcc11-opt""```.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10963
https://github.com/root-project/root/pull/10964:49,deployability,patch,patch,49,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:88,deployability,upgrad,upgrade,88,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:110,deployability,patch,patch,110,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:88,modifiability,upgrad,upgrade,88,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:8,safety,Avoid,Avoid,8,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:49,safety,patch,patch,49,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:110,safety,patch,patch,110,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:25,security,ident,ident,25,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:49,security,patch,patch,49,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:110,security,patch,patch,110,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/pull/10964:181,security,sign,significantly,181,"Revert ""Avoid dupe ""llvm.ident"" operands.""; This patch was developed as part of an llvm upgrade in 2015. This patch is not needed anymore considering that the LLVM JIT has advanced significantly.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10964
https://github.com/root-project/root/issues/10965:1083,availability,down,downloaded,1083,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:979,deployability,version,version,979,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1018,deployability,version,version,1018,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:979,integrability,version,version,979,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1018,integrability,version,version,1018,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1124,integrability,repositor,repository,1124,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1124,interoperability,repositor,repository,1124,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:979,modifiability,version,version,979,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1018,modifiability,version,version,1018,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1146,safety,test,tested,1146,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:1146,testability,test,tested,1146,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/issues/10965:292,usability,behavi,behavior,292,"Invalid RDataFrames returned from functions in pyROOT when constructing from a TChain due to garbage collection; ### Describe the bug. RDataFrame constructed within a function with a TChain becomes inaccessible when returned, unless TChain is returned with it (segfault occurs). ### Expected behavior. RDataFrame constructed with a TChain should be able to be returned from a function. ### To Reproduce. ```python. import ROOT. import glob. def build_rdataframe(filepath, tree):. chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return chain, Rdf. chain, df = build_rdataframe(""path/to/files"", ""tree""). print(df.Count().GetValue()). # works. def build_rdataframe_2(filepath, tree): . chain = ROOT.TChain(tree). for file in glob.glob(filepath):. chain.Add(file). Rdf = ROOT.RDataFrame(chain). return Rdf. df = build_rdataframe_2(""path/to/files"", ""tree""). print(df.Count().GetValue()). # segfault. ```. ### Setup. 1. ROOT version 6.24.00 / Python 3.10.4 | ROOT version 6.20.06 / Python 2.7.5. 2. Arch Linux / Centos7. 3. ROOT downloaded from conda-forge / Arch linux repository / lxplus. (tested on multiple OSs/environments)",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10965
https://github.com/root-project/root/pull/10966:1857,availability,sli,slightly,1857,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1079,deployability,fail,failing,1079,"equest:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this ma",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2157,deployability,updat,updated,2157,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2212,deployability,updat,updated,2212,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1728,energy efficiency,optim,optimization,1728,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1826,energy efficiency,reduc,reduces,1826,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:371,integrability,event,event-level,371,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:675,integrability,event,events,675,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:686,integrability,compon,components,686,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:787,integrability,sub,subsidiary,787,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:798,integrability,compon,components,798,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2324,integrability,interfac,interface,2324,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:654,interoperability,specif,specify,654,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:686,interoperability,compon,components,686,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:798,interoperability,compon,components,798,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1093,interoperability,specif,specific,1093,"anges or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2324,interoperability,interfac,interface,2324,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:686,modifiability,compon,components,686,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:760,modifiability,exten,extended,760,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:798,modifiability,compon,components,798,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1569,modifiability,variab,variable,1569,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2324,modifiability,interfac,interface,2324,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:321,performance,time,time,321,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:348,performance,parallel,parallelization,348,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1728,performance,optimiz,optimization,1728,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1848,performance,overhead,overhead,1848,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1079,reliability,fail,failing,1079,"equest:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this ma",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1857,reliability,sli,slightly,1857,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2286,reliability,doe,doesn,2286,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:48,safety,Test,TestStatistics,48,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1070,safety,test,test,1070,"This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2098,safety,review,review,2098,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2127,safety,test,tested,2127,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2157,safety,updat,updated,2157,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2212,safety,updat,updated,2212,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2157,security,updat,updated,2157,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2212,security,updat,updated,2212,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:48,testability,Test,TestStatistics,48,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1070,testability,test,test,1070,"This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I h",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2098,testability,review,review,2098,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2127,testability,test,tested,2127,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:23,usability,support,support,23,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:235,usability,minim,minimizations,235,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:427,usability,minim,minimization,427,"[RF] add LikelihoodJob support and some RooFit::TestStatistics fixes; # This Pull request:. ## Changes or fixes:. The main feature is that this PR makes it possible (in the final commit 5227996a9941918404d0a36037daa2c91e29833a) to run minimizations with both LikelihoodGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1262,usability,minim,minimization,1262,"dGradientJob and LikelihoodJob activated at the same time. This adds likelihood parallelization at the event-level to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't thi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1380,usability,user,user,1380," to the non-gradient phases of Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just d",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1421,usability,prefer,prefer,1421,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:1807,usability,efficien,efficiently,1807,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2190,usability,Document,Documentation,2190,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/pull/10966:2319,usability,user,user,2319,"f Minuit migrad minimization: 1. the setup phase where the initial gradient is calculated and 2. the line search phases. To make the above possible, a few bugs had to be fixed:. - `RooAbsL` classes have `evaluatePartition` which allows you to specify the range of events and components over which to evaluate the likelihood. This had some bugs: the extended term and possible subsidiary components were added for each partition, leading to N duplicates (for N partitions). Commits 3db2e0dd36478813cfb534451f459348e8d90da9 and c2a8bc9df029f65ee575e140825af6c509860538. - As a result of this fix, which reorders some terms in the sum, the LikelihoodGradientJob test was failing for a specific case due to increased floating point differences. We would like to add back in an option for retaining bit-wise exact same results in the future, but since the minimization still converges to the same value within the desired precision, for now we leave it like this, since the user can still pick the old ways if they prefer their exact old results. Commit b7f7fa7b705e2dfb767187dce3f6a32275f30d9e. - `LikelihoodJob` had a bug where it didn't reset its `result` sum variable to zero before doing a new sum. Commits 042e1577d8c303d532016537e7467d6e2fbfcd9c and 44197a2a64f77b47587e5ee200d360c4514b8098. Finally, I made a mini optimization in `LikelihoodJob` by using `publish_from_master_to_workers` more efficiently, which reduces communication overhead slightly (and makes the code a bit cleaner). Also in commit 567b7988d56b6c1db6102d857b523fc2da607dbc. Note that although this is a bit of a big PR, the commits are factored out into the above list of changes, so I hope this makes it easy to review. ## Checklist:. - [x] tested changes locally. - [ ] updated the docs (if necessary). Documentation not yet updated, I will check if this is necessary (I didn't think so, because it doesn't actually add much to the user interface, all the classes were already there, they just didn't work before like this).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10966
https://github.com/root-project/root/issues/10967:38,deployability,updat,updated,38,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:537,deployability,API,API,537,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:537,integrability,API,API,537,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:537,interoperability,API,API,537,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:130,performance,parallel,parallelizing,130,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:38,safety,updat,updated,38,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:327,safety,Test,TestStatistics,327,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:381,safety,test,test,381,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:588,safety,test,tests,588,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:38,security,updat,updated,38,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:327,testability,Test,TestStatistics,327,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:381,testability,test,test,381,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:588,testability,test,tests,588,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10967:177,usability,minim,minimization,177,"[RF] MultiProcess README.md should be updated to include LikelihoodJob; #10966 fixes LikelihoodJob so that it can now be used for parallelizing non-gradient parts of the migrad minimization. This should be reflected in the relevant README.md section here: https://github.com/root-project/root/tree/master/roofit/roofitcore/src/TestStatistics#calculators. We have yet to thoroughly test the class on real life fits. We intend to do this in the coming weeks. After this, we will rewrite the docs, taking into account any possible fixes or API changes that may have been necessary after our tests.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10967
https://github.com/root-project/root/issues/10968:512,energy efficiency,Draw,Draw,512,"Have the plotting canvas from experiments; Hi all! I was thinking that it would be very nice to have the option to have the canvas for different **styles** from the most common experiments, this will allow you to easily match the style of your plots. . For example, if you want your functions to look like the ones normally generated in ATLAS you should be able to do something like. ```bash. root [0] TGraph g;. root [1] for (auto i : {0,1,2,3,4}) g.SetPoint(i,i,i*i). root [2] g.SetCanvas(""ATLAS""). root [3] g.Draw(""APL""). ```. This idea comes from the [mplhep](https://github.com/scikit-hep/mplhep) library. They support canvas from a variety of collaborations such as ATLAS, ALICE, CMS... Best regards",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10968
https://github.com/root-project/root/issues/10968:616,usability,support,support,616,"Have the plotting canvas from experiments; Hi all! I was thinking that it would be very nice to have the option to have the canvas for different **styles** from the most common experiments, this will allow you to easily match the style of your plots. . For example, if you want your functions to look like the ones normally generated in ATLAS you should be able to do something like. ```bash. root [0] TGraph g;. root [1] for (auto i : {0,1,2,3,4}) g.SetPoint(i,i,i*i). root [2] g.SetCanvas(""ATLAS""). root [3] g.Draw(""APL""). ```. This idea comes from the [mplhep](https://github.com/scikit-hep/mplhep) library. They support canvas from a variety of collaborations such as ATLAS, ALICE, CMS... Best regards",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10968
https://github.com/root-project/root/pull/10969:73,deployability,patch,patch,73,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:209,performance,memor,memory,209,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:7,safety,compl,completely,7,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:73,safety,patch,patch,73,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:280,safety,test,test,280,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:351,safety,review,review,351,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:7,security,compl,completely,7,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:25,security,ident,identifiers,25,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:73,security,patch,patch,73,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:119,security,ident,identifiers,119,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:370,security,Sign,Signed-off-by,370,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:85,testability,verif,verify,85,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:280,testability,test,test,280,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:351,testability,review,review,351,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:209,usability,memor,memory,209,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/pull/10969:298,usability,close,closed,298,"Try to completely remove identifiers that are namespace in the GMI; This patch is to verify if we really need to store identifiers that. are namespace in GlobalModuleIndex, which greatly increase the maximum. memory pressure. Send this to trigger ROOT's CI so we can have a full. test, and will be closed if the direction is wrong. **No need for code review or merge**. Signed-off-by: Jun Zhang <jun@junz.org>.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10969
https://github.com/root-project/root/issues/10970:335,availability,avail,available,335,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:389,availability,Sli,Slightly,389,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1275,availability,avail,available,1275,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:294,deployability,infrastructur,infrastructure,294,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:703,deployability,continu,continue,703,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1072,deployability,build,build,1072,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1165,deployability,build,build,1165,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1355,deployability,build,build,1355,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:351,energy efficiency,load,loading,351,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:464,energy efficiency,core,core,464,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:505,energy efficiency,core,core,505,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:588,energy efficiency,core,core,588,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:634,energy efficiency,core,core,634,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1291,energy efficiency,load,loading,1291,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:694,integrability,pub,public,694,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:351,performance,load,loading,351,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1291,performance,load,loading,1291,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:335,reliability,availab,available,335,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:389,reliability,Sli,Slightly,389,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1275,reliability,availab,available,1275,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:335,safety,avail,available,335,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1275,safety,avail,available,1275,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:335,security,availab,available,335,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:398,security,modif,modify,398,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1275,security,availab,available,1275,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1078,testability,assert,asserts,1078,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1171,testability,assert,asserts,1171,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1361,testability,assert,asserts,1361,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1043,usability,User,Users,1043,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1136,usability,User,Users,1136,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/issues/10970:1326,usability,User,Users,1326,"[cling] DynamicLibraryManager finds non-exported symbols on macOS; At least with the [llvm13 branch](https://github.com/vgvassilev/root/tree/llvm13) on macOS, `cling::DynamicLibraryManager::searchLibrariesForSymbol` sometimes finds non-exported symbols and confuses the rest of the autoloading infrastructure because the symbol is not available after loading that library. ### Reproducer. Slightly modify the new `AutoloadLibraryGenerator`:. ```diff. diff --git a/core/metacling/src/TClingCallbacks.cxx b/core/metacling/src/TClingCallbacks.cxx. index 1401f04ee6..b538695533 100644. --- a/core/metacling/src/TClingCallbacks.cxx. +++ b/core/metacling/src/TClingCallbacks.cxx. @@ -188,6 +188,8 @@ public:. continue;. }. + printf(""found symbol '%s' in '%s'\n"", (*name).str().c_str(), libName.c_str());. +. found[libName].push_back(name);. }. ```. Then execute the following Python file:. ```py. import ROOT. print(ROOT.kTRUE). ```. The output (on `macitois22`) is:. ```. found symbol '__ZN5cling7runtime8internal15setValueNoAllocEPvS2_S2_cy' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libCling.so' . found symbol '__ZL5kTRUE' in '/Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so'. 1. ```. where `kTRUE` should not be found. Or at least the symbols is still not available after loading `libRIO`, and:. ```. $ nm /Users/sftnight/jhahnfel/root.build.asserts/lib/libRIO.so | grep kTRUE. 0000000000272988 s __ZL5kTRUE. ```. From the `man`-page of `nm`:. > If the symbol is local (non-external), the symbol's type is instead represented by the corresponding lowercase letter.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10970
https://github.com/root-project/root/pull/10971:29,availability,Operat,Operator,29,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:119,availability,Operat,Operator,119,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:81,safety,test,tests,81,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:168,safety,test,tests,168,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:177,safety,valid,validate,177,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:225,safety,test,tested,225,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:177,security,validat,validate,177,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:76,testability,unit,unit,76,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:81,testability,test,tests,81,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:163,testability,unit,unit,163,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:168,testability,test,tests,168,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10971:225,testability,test,tested,225,[GSOC][TMVA][SOFIE] Pow ONNX Operator added to SOFIE with the corresponding unit tests.; # This Pull request: Pow ONNX Operator implemented with the corresponding unit tests to validate the written code. ## Checklist:. - [X] tested changes locally.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10971
https://github.com/root-project/root/pull/10972:107,interoperability,format,formatted,107,"Fix typos in tutorials; Fix improper display of vectorizedFit documentation/tutorial. The header was badly formatted (everything on one line) which resulted in only part it being displayed. This can be seen here (https://root.cern/doc/master/vectorizedFit_8C.html) where only `use it for fitting an histogram` is displayed instead of the complete sentence: `tutorial for creating a Vectorized TF1 function using a formula expression and use it for fitting an histogram`. Also, fixed some typos.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10972
https://github.com/root-project/root/pull/10972:338,safety,compl,complete,338,"Fix typos in tutorials; Fix improper display of vectorizedFit documentation/tutorial. The header was badly formatted (everything on one line) which resulted in only part it being displayed. This can be seen here (https://root.cern/doc/master/vectorizedFit_8C.html) where only `use it for fitting an histogram` is displayed instead of the complete sentence: `tutorial for creating a Vectorized TF1 function using a formula expression and use it for fitting an histogram`. Also, fixed some typos.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10972
https://github.com/root-project/root/pull/10972:338,security,compl,complete,338,"Fix typos in tutorials; Fix improper display of vectorizedFit documentation/tutorial. The header was badly formatted (everything on one line) which resulted in only part it being displayed. This can be seen here (https://root.cern/doc/master/vectorizedFit_8C.html) where only `use it for fitting an histogram` is displayed instead of the complete sentence: `tutorial for creating a Vectorized TF1 function using a formula expression and use it for fitting an histogram`. Also, fixed some typos.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10972
https://github.com/root-project/root/pull/10972:62,usability,document,documentation,62,"Fix typos in tutorials; Fix improper display of vectorizedFit documentation/tutorial. The header was badly formatted (everything on one line) which resulted in only part it being displayed. This can be seen here (https://root.cern/doc/master/vectorizedFit_8C.html) where only `use it for fitting an histogram` is displayed instead of the complete sentence: `tutorial for creating a Vectorized TF1 function using a formula expression and use it for fitting an histogram`. Also, fixed some typos.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10972
https://github.com/root-project/root/pull/10974:163,availability,servic,services,163,"Replace `sprintnf` calls with `snprintf` in multiple packages; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/. After this PR, there will only be a final PR necessacy to fix these. warnings in TMVA.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10974
https://github.com/root-project/root/pull/10974:163,deployability,servic,services,163,"Replace `sprintnf` calls with `snprintf` in multiple packages; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/. After this PR, there will only be a final PR necessacy to fix these. warnings in TMVA.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10974
https://github.com/root-project/root/pull/10974:163,integrability,servic,services,163,"Replace `sprintnf` calls with `snprintf` in multiple packages; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/. After this PR, there will only be a final PR necessacy to fix these. warnings in TMVA.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10974
https://github.com/root-project/root/pull/10974:53,modifiability,pac,packages,53,"Replace `sprintnf` calls with `snprintf` in multiple packages; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/. After this PR, there will only be a final PR necessacy to fix these. warnings in TMVA.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10974
https://github.com/root-project/root/pull/10974:163,modifiability,servic,services,163,"Replace `sprintnf` calls with `snprintf` in multiple packages; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/. After this PR, there will only be a final PR necessacy to fix these. warnings in TMVA.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10974
https://github.com/root-project/root/pull/10975:157,availability,servic,services,157,"[TMVA] Replace `sprintnf` calls with `snprintf` in TMVA; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10975
https://github.com/root-project/root/pull/10975:157,deployability,servic,services,157,"[TMVA] Replace `sprintnf` calls with `snprintf` in TMVA; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10975
https://github.com/root-project/root/pull/10975:157,integrability,servic,services,157,"[TMVA] Replace `sprintnf` calls with `snprintf` in TMVA; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10975
https://github.com/root-project/root/pull/10975:157,modifiability,servic,services,157,"[TMVA] Replace `sprintnf` calls with `snprintf` in TMVA; This is to suppress the warnings we see now in the nightlies on the. macbeta nodes:. https://lcgapp-services.cern.ch/root-jenkins/view/ROOT%20Nightly/job/root-nightly-master/LABEL=macbeta,SPEC=cxx17,V=master/lastBuild/parsed_console/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10975
https://github.com/root-project/root/pull/10976:69,availability,error,error,69,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:265,deployability,updat,updated,265,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:140,integrability,complian,compliant,140,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:69,performance,error,error,69,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:69,safety,error,error,69,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:140,safety,compl,compliant,140,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:234,safety,test,tested,234,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:265,safety,updat,updated,265,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:140,security,compl,compliant,140,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:265,security,updat,updated,265,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:234,testability,test,tested,234,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10976:69,usability,error,error,69,[cling-cpt] Added extra spacing between functions to get rid of E302 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: I inserted more space between functions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10976
https://github.com/root-project/root/pull/10977:42,availability,operat,operators,42,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:71,availability,error,error,71,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:193,availability,operat,operators,193,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:256,deployability,updat,updated,256,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:137,integrability,complian,compliant,137,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:71,performance,error,error,71,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:71,safety,error,error,71,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:137,safety,compl,compliant,137,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:225,safety,test,tested,225,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:256,safety,updat,updated,256,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:137,security,compl,compliant,137,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:256,security,updat,updated,256,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:225,testability,test,tested,225,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10977:71,usability,error,error,71,[cling-cpt] Added extra whitespace around operators to get rid of E225 error. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added whitespace around operators. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10977
https://github.com/root-project/root/pull/10978:63,availability,error,error,63,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:278,deployability,updat,updated,278,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:134,integrability,complian,compliant,134,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:63,performance,error,error,63,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:63,safety,error,error,63,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:134,safety,compl,compliant,134,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:247,safety,test,tested,247,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:278,safety,updat,updated,278,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:134,security,compl,compliant,134,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:278,security,updat,updated,278,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:247,testability,test,tested,247,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10978:63,usability,error,error,63,[cling-cpt] Fixed invalid escape characters to get rid of W605 error. [skip-ci]; # This Pull request: This makes the code more flake8 compliant. ## Changes or fixes: Added an extra backslash to the escape sequence characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10978
https://github.com/root-project/root/pull/10979:67,availability,error,error,67,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:266,deployability,updat,updated,266,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:138,integrability,complian,compliant,138,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:67,performance,error,error,67,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:67,safety,error,error,67,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:138,safety,compl,compliant,138,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:235,safety,test,tested,235,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:266,safety,updat,updated,266,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:138,security,compl,compliant,138,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:266,security,updat,updated,266,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:235,testability,test,tested,235,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:34,usability,visual,visual,34,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10979:67,usability,error,error,67,[cling-cpt] Added indentation for visual indent to get rid of E128 error code. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation for under indented lines. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10979
https://github.com/root-project/root/pull/10981:135,deployability,stack,stack,135,"Revert ""Use quotes around PATHs. Should fix #10759""; The quotes are causing issues in some autoconf macros for two packages in the LCG stack. This reverts commit ade40b1ea048ec9fe6f590914a16b16391374c8a.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10981
https://github.com/root-project/root/pull/10981:115,modifiability,pac,packages,115,"Revert ""Use quotes around PATHs. Should fix #10759""; The quotes are causing issues in some autoconf macros for two packages in the LCG stack. This reverts commit ade40b1ea048ec9fe6f590914a16b16391374c8a.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10981
https://github.com/root-project/root/pull/10982:51,availability,cluster,cluster,51,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:181,availability,cluster,cluster,181,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:303,availability,cluster,cluster,303,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:325,availability,cluster,cluster,325,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:358,availability,cluster,clusters,358,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:575,availability,cluster,clusters,575,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:912,availability,cluster,cluster,912,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1045,availability,cluster,cluster,1045,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1177,availability,cluster,clusters,1177,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:51,deployability,cluster,cluster,51,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:181,deployability,cluster,cluster,181,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:303,deployability,cluster,cluster,303,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:325,deployability,cluster,cluster,325,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:358,deployability,cluster,clusters,358,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:575,deployability,cluster,clusters,575,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:912,deployability,cluster,cluster,912,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1045,deployability,cluster,cluster,1045,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1177,deployability,cluster,clusters,1177,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1310,deployability,updat,updated,1310,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:112,energy efficiency,Load,LoadClusters,112,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:394,energy efficiency,Load,LoadClusters,394,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1097,energy efficiency,Load,LoadClusters,1097,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:527,integrability,asynchron,asynchronous,527,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:593,integrability,queue,queue,593,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1136,integrability,batch,batch,1136,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:587,interoperability,share,share,587,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:753,interoperability,distribut,distribution,753,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:947,interoperability,distribut,distribution,947,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:84,modifiability,refact,refactors,84,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1122,modifiability,refact,refactored,1122,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:84,performance,refactor,refactors,84,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:112,performance,Load,LoadClusters,112,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:394,performance,Load,LoadClusters,394,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:415,performance,time,time,415,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:527,performance,asynch,asynchronous,527,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:593,performance,queue,queue,593,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:610,performance,time,time,610,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:641,performance,parallel,parallelize,641,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:679,performance,throughput,throughput,679,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1000,performance,parallel,parallelized,1000,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1097,performance,Load,LoadClusters,1097,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1122,performance,refactor,refactored,1122,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1136,performance,batch,batch,1136,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1259,safety,test,tested,1259,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1310,safety,updat,updated,1310,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:836,security,modif,modification,836,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1310,security,updat,updated,1310,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:1259,testability,test,tested,1259,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10982:856,usability,support,support,856,"[ntuple,daos] Coalesce fetch requests for pages in cluster bunch; This Pull request refactors `RPageSourceDaos::LoadClusters()` to coalesce the fetch requests for pages in the same cluster bunch before calling `RDaosContainer::ReadV`, instead of launching a call to remote storage for the pages of each cluster separately. A cluster bunch corresponds to all clusters being fetched together by `LoadClusters()` at a time. . Since the call by `ReadV()` is ultimately blocking until all requests are done, this change enables the asynchronous page fetch requests from different clusters to share queue and flight time; thus, remote storage can parallelize them toward a higher read throughput. . The requests are still coalesced according to object ID and distribution key resulting from the mapping strategy in `kDefaultDaosMapping`. The modification allows support for new mappings that do not feature the ntuple cluster ID among the object ID and distribution key (i.e. such page requests may now be parallelized despite not being from the same cluster). ## Changes or fixes:. - `RPageSourceDaos::LoadClusters()` has been refactored to batch up page requests from all provided clusters before the blocking `RDaosContainer::ReadV()` call. ## Checklist:. - [x] tested changes locally + openlab `olsky-03`. - [ ] updated the docs (if necessary).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10982
https://github.com/root-project/root/pull/10983:122,deployability,stack,stack,122,Remove several double-quotes; Some of the quotes are causing issues in some `autoconf` macros for two packages in the LCG stack.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10983
https://github.com/root-project/root/pull/10983:102,modifiability,pac,packages,102,Remove several double-quotes; Some of the quotes are causing issues in some `autoconf` macros for two packages in the LCG stack.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10983
https://github.com/root-project/root/issues/10984:544,availability,error,error,544,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2028,availability,error,error,2028,"is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4064,availability,Error,Error,4064,"_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configur",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4204,availability,Error,Error,4204,"preterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4287,availability,Error,Error,4287,"l<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4819,availability,Operat,Operating,4819,"~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4894,availability,down,download,4894,"ects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang bu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:12,deployability,fail,fails,12,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:580,deployability,build,builddir,580,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:619,deployability,build,builddir,619,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:657,deployability,build,builddir,657,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:700,deployability,build,builddir,700,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:738,deployability,build,builddir,738,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:786,deployability,build,builddir,786,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:865,deployability,Updat,UpdateIsOnHeap,865,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:926,deployability,build,builddir,926,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1107,deployability,build,builddir,1107,".com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, st",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1349,deployability,build,builddir,1349," still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1398,deployability,build,builddir,1398,"be the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1437,deployability,build,builddir,1437,"escription of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1475,deployability,build,builddir,1475,"is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1518,deployability,build,builddir,1518,"d, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1556,deployability,build,builddir,1556,"file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1921,deployability,build,builddir,1921,"<builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2770,deployability,fail,failed,2770,"alue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uni",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:3984,deployability,build,build,3984,"nterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), wi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4102,deployability,build,builddir,4102,"Value, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Pr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4242,deployability,build,builddir,4242,"preterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4325,deployability,build,builddir,4325,"~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=for",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4465,deployability,fail,fail,4465,"tr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4709,deployability,build,build,4709,"ol <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4807,deployability,version,version,4807,"t;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4876,deployability,instal,install,4876,"ote: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimag",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5030,deployability,configurat,configuration,5030,".dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5059,deployability,Configurat,Configuration,5059,"ror 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5172,deployability,Build,Build,5172,"iles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared sover",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5189,deployability,Instal,Install,5189,"G.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tm",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5743,deployability,Modul,Module,5743,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6383,deployability,build,build,6383,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5116,energy efficiency,core,core,5116,"[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5130,energy efficiency,Core,Core,5130,"eFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5148,energy efficiency,CPU,CPU,5148,"3593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6201,energy efficiency,cpu,cpu,6201,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2757,integrability,sub,substitution,2757,"terpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 2",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4807,integrability,version,version,4807,"t;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5030,integrability,configur,configuration,5030,".dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5059,integrability,Configur,Configuration,5059,"ror 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5326,interoperability,format,format-security,5326,"'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any o",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5508,interoperability,format,format-security,5508,"e behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last c",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5775,interoperability,Share,Shared,5775,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6163,interoperability,share,shared,6163,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6278,interoperability,xml,xml,6278,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6402,interoperability,share,shared,6402,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1790,modifiability,paramet,parameter-,1790,"/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2502,modifiability,inherit,inherited,2502,"44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uni",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:3165,modifiability,inherit,inherited,3165,"tr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/C",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4807,modifiability,version,version,4807,"t;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5030,modifiability,configur,configuration,5030,".dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5059,modifiability,Configur,Configuration,5059,"ror 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5743,modifiability,Modul,Module,5743,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:544,performance,error,error,544,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1331,performance,memor,memory,1331,"for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2028,performance,error,error,2028,"is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4064,performance,Error,Error,4064,"_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configur",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4204,performance,Error,Error,4204,"preterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4287,performance,Error,Error,4287,"l<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5148,performance,CPU,CPU,5148,"3593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5349,performance,time,time,5349,"ted behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context abou",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5531,performance,time,time,5531,"our code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 year",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6201,performance,cpu,cpu,6201,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:12,reliability,fail,fails,12,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2770,reliability,fail,failed,2770,"alue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uni",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4456,reliability,doe,does,4456,"/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<sr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4465,reliability,fail,fail,4465,"tr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:544,safety,error,error,544,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:865,safety,Updat,UpdateIsOnHeap,865,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2028,safety,error,error,2028,"is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4064,safety,Error,Error,4064,"_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configur",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4204,safety,Error,Error,4204,"preterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4287,safety,Error,Error,4287,"l<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4663,safety,input,input,4663,"p = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5743,safety,Modul,Module,5743,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5980,safety,except,exceptions,5980,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:865,security,Updat,UpdateIsOnHeap,865,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5030,security,configur,configuration,5030,".dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5059,security,Configur,Configuration,5059,"ror 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mat",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5333,security,secur,security,5333,"```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any othe",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5515,security,secur,security,5515,"ehavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last chan",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5831,security,hash,hash-style,5831,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6187,security,ssl,ssl,6187,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6310,testability,context,context,6310,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:6339,testability,context,context,6339,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:422,usability,clear,clear,422,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:470,usability,behavi,behavior,470,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:544,usability,error,error,544,"Compilation fails with VecGeom; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:1331,usability,memor,memory,1331,"for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When compiling with VecGeom enabled, I get this compile error:. ```. In file included from <builddir>/include/TObject.h:18,. from <builddir>/include/TNamed.h:25,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. <builddir>/include/TStorage.h: In static member function static void TStorage::UpdateIsOnHeap(const volatile UInt_t&, volatile UInt_t&):. <builddir>/include/TStorage.h:133:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, s",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:2028,usability,error,error,2028,"is deprecated [-Wvolatile]. 133 | bits |= kIsOnHeap;. | ~~~~~^~~~~~~~~~~~. <builddir>/include/TStorage.h:135:12: warning: compound assignment with volatile-qualified left operand is deprecated [-Wvolatile]. 135 | bits &= ~kIsOnHeap;. | ~~~~~^~~~~~~~~~~~~. In file included from /usr/include/c++/11/memory:76,. from <builddir>/include/ROOT/TypeTraits.hxx:15,. from <builddir>/include/TString.h:30,. from <builddir>/include/TNamed.h:26,. from <builddir>/include/TDictionary.h:44,. from <builddir>/include/TClass.h:23,. from <builddir>/geom/vecgeom/G__ConverterVG.cxx:14:. /usr/include/c++/11/bits/unique_ptr.h: In instantiation of constexpr std::unique_ptr<_Tp, _Dp>::unique_ptr(std::nullptr_t) [with _Del = std::default_delete<TInterpreterValue>; <template-parameter-2-2> = void; _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; std::nullptr_t = std::nullptr_t]:. <builddir>/include/TInterpreter.h:280:85: required from here. /usr/include/c++/11/bits/unique_ptr.h:321:11: error: no matching function for call to std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(). 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: template<class _Del> std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterpreterValue>, true, true>::__uniq_ptr_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer, _Del&&) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: template argument deduction/substitution failed:. /usr/include/c++/11/bits/unique_ptr.h:321:11: note: candidate expects 2 arguments, 0 provided. 321 | : _M_t(). | ^~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate: std::__uniq_ptr_data<TInterpreterValue, std::default_delete<TInterp",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4064,usability,Error,Error,4064,"_data(std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >::pointer) [inherited from std::__uniq_ptr_impl<TInterpreterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configur",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4204,usability,Error,Error,4204,"preterValue, std::default_delete<TInterpreterValue> >]. 210 | using __uniq_ptr_impl<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4287,usability,Error,Error,4287,"l<_Tp, _Dp>::__uniq_ptr_impl;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstac",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4355,usability,behavi,behavior,4355,"/bits/unique_ptr.h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FO",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4373,usability,clear,clear,4373,"h:210:40: note: candidate expects 1 argument, 0 provided. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate: std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -W",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4518,usability,behavi,behavior,4518," _Dp, <anonymous>, <anonymous> >::__uniq_ptr_data(std::__uniq_ptr_data<_Tp, _Dp, <anonymous>, <anonymous> >&&) [with _Tp = TInterpreterValue; _Dp = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-securit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:4663,usability,input,input,4663,"p = std::default_delete<TInterpreterValue>; bool <anonymous> = true; bool <anonymous> = true]. 211 | __uniq_ptr_data(__uniq_ptr_data&&) = default;. | ^~~~~~~~~~~~~~~. /usr/include/c++/11/bits/unique_ptr.h:211:7: note: candidate expects 1 argument, 0 provided. make[3]: *** [geom/vecgeom/CMakeFiles/G__ConverterVG.dir/build.make:96: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/G__ConverterVG.cxx.o] Error 1. make[3]: Leaving directory '<builddir>'. make[2]: *** [CMakeFiles/Makefile2:33593: geom/vecgeom/CMakeFiles/G__ConverterVG.dir/all] Error 2. make[2]: Leaving directory '<builddir>'. make[1]: *** [Makefile:159: all] Error 2. make[1]: Leaving directory '<builddir>'. ```. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. The compilation does not fail. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10984:5861,usability,support,support,5861,"e that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. Compile with `vecgeom` option. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Compiling ROOT v6.26.04 on Debian Unstable (amd64), with GCC 11.3.0 and VecGeom 1.2.0, with this configuration:. ```. -- ROOT Configuration . System Linux-5.18.0-2-amd64. Processor 4 core Intel(R) Core(TM) i5-8250U CPU @ 1.60GHz (x86_64). Build type None. Install path /usr. Compiler GNU 11.3.0. Compiler flags:. C -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -Wno-implicit-fallthrough -pipe -Wall -W -pthread . C++ -g -O2 -ffile-prefix-map=<srcdir>=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -std=c++17 -Wno-implicit-fallthrough -Wno-noexcept-type -pipe -Wshadow -Wall -W -Woverloaded-virtual -fsigned-char -pthread . Linker flags:. Executable -Wl,-z,relro -Wl,-z,now -rdynamic. Module -Wl,-z,relro -Wl,-z,now. Shared -Wl,-z,relro -Wl,-z,now -Wl,--no-undefined -Wl,--hash-style=""both"". -- Enabled support for: asimage builtin_clang builtin_cling builtin_llvm builtin_unuran builtin_vdt ccache dataframe davix dcache exceptions fftw3 fitsio fortran gdml gfal gnuinstall gsl_shared gviz http fcgi imt mathmore mlp minuit2 mpi mysql odbc opengl pgsql pyroot qt5web qt6web r roofit root7 rpath shadowpw shared soversion sqlite ssl tmva tmva-cpu tmva-sofie tmva-pymva tmva-rmva spectrum unuran uring vc vdt veccore x11 xml xrootd. ```. ### Additional context. <!--. Add any other context about the problem here. -->. I have build VecGeom as a shared library, but this shouldn't make a difference. I think the VecGeom part of ROOT is just out of date (last change made 2 years ago).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10984
https://github.com/root-project/root/issues/10985:243,deployability,instal,installation,243,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:1161,deployability,automat,automatically,1161,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:1180,deployability,build,building,1180,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:162,energy efficiency,current,currently,162,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:221,integrability,repositor,repositories,221,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:221,interoperability,repositor,repositories,221,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:300,interoperability,share,shared,300,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:404,interoperability,conflict,conflict,404,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:448,interoperability,share,shared,448,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:664,interoperability,share,share,664,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:477,modifiability,pac,packages,477,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:521,modifiability,pac,package,521,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:972,performance,time,time-consuming,972,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:836,testability,simpl,simply,836,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:1161,testability,automat,automatically,1161,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/issues/10985:836,usability,simpl,simply,836,"Please prefix generic library names with ROOT; ### Explain what you would like to see improved. <!--. Explain what isn't as good as it could be and why. -->. I'm currently working on getting ROOT into the official Debian repositories for easy installation. However, a major hassle is the name of the shared libraries: these include very generic names like for example `libCore.so`, `libGui.so`, etc. The conflict here is that Debian usually splits shared libraries in separate packages with their library name. However a package with e.g. the name `libcore` is just not explicit enough. A better and much more precise name would be `libROOTCore.so`. ### Optional: share how it could be improved. <!--. If you already have an idea what we could improve, then please tell us. -->. I see two possible ways to achieve this: one would be to simply add a prefix to all libraries globally, the other would be to rename the libraries in CMake itself. The latter one is probably a time-consuming task, and also needs to handle cases like e.g. `libHist`, since both `libHist` and `libROOTHist` exist. The prior one could be easily added with a CMake option, or just done automatically when building with `gnuinstall=ON`.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10985
https://github.com/root-project/root/pull/10986:48,deployability,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/pull/10986:175,deployability,patch,patches,175,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/pull/10986:48,safety,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/pull/10986:175,safety,patch,patches,175,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/pull/10986:48,security,patch,patches,48,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/pull/10986:175,security,patch,patches,175,"[v626][RF] Backports of RooFit PRs to `v6-26-00-patches`: Part 17; This is a backport of all the relevant bugfix RooFit PRs that were recently merged to `master` to `v6-26-00-patches` (in the right order, to not have the commit history diverge too much). 1. https://github.com/root-project/root/pull/10884. 2. https://github.com/root-project/root/pull/10885. 3. https://github.com/root-project/root/pull/10832. 4. https://github.com/root-project/root/pull/10921. 5. https://github.com/root-project/root/pull/10909.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10986
https://github.com/root-project/root/issues/10988:357,deployability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,deployability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,integrability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,integrability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,interoperability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,interoperability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,modifiability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,modifiability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:29,performance,cach,cache,29,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:387,performance,cach,cache,387,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,reliability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:393,reliability,doe,does,393,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,reliability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,security,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,security,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:357,testability,integr,integral,357,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:510,testability,integr,integral,510,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:89,usability,experien,experiencing,89,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:110,usability,behavi,behaviour,110,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:406,usability,clear,cleared,406,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/issues/10988:450,usability,behavi,behaviour,450,"[RF] RooAddPdf::fixCoefRange cache issue with createIntegral; ### Describe the bug. I am experiencing strange behaviour with `RooAddPdf::fixCoefRange`. When I call `createIntegral` on a `RooAddPdf`, then call `fixCoefRange`, then call `createIntegral` again, the same value is returned (whilst the change of definition of the coefficients should change the integral). It seems to me the cache does not get cleared when calling `fixCoefRange`, as the behaviour is correct when calling `fixCoefRange` before any integral computation. ### To Reproduce. ```cpp. RooWorkspace w1;. w1.factory(""x[3., 0., 10.]"");. w1.var(""x"")->setRange(""range_int"", 0., 4.);. w1.factory(""AddPdf::sum(Gaussian(x, mean1[1.], sigma1[2.]), Gaussian(x, mean2[5.], sigma2[10.]), coef[0.3])"");. RooWorkspace w2(w1);. //Call createIntegral on workspace w1 only. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. w1.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w1.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. w2.var(""x"")->setRange(""fixCoefRange"", 0., 1.);. static_cast<RooAddPdf*>(w2.pdf(""sum""))->fixCoefRange(""fixCoefRange"");. cout << w1.pdf(""sum"")->createIntegral(RooArgSet(*w1.var(""x"")),RooFit::NormSet(RooArgSet(*w1.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. cout << w2.pdf(""sum"")->createIntegral(RooArgSet(*w2.var(""x"")),RooFit::NormSet(RooArgSet(*w2.var(""x""))), RooFit::Range(""range_int""))->getVal() << endl;. ```. This prints :. ```. 0.548209 //Before calling RooAddPdf::fixCoefRange. 0.548209 //After calling RooAddPdf::fixCoefRange but with a previous call to createIntegral. 0.463998 //After calling RooAddPdf::fixCoefRange without any previous call. ```. whilst I would expect : . ```. 0.548209. 0.463998. 0.463998. ```. ### Setup. ROOT 6.26/02.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10988
https://github.com/root-project/root/pull/10989:1116,deployability,patch,patch,1116,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:1123,deployability,releas,release,1123,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:14,modifiability,paramet,parameter,14,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:96,modifiability,paramet,parameter,96,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:375,performance,time,time,375,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:399,safety,test,tested,399,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:440,safety,input,inputs,440,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:1116,safety,patch,patch,1116,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:1116,security,patch,patch,1116,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:399,testability,test,tested,399,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/pull/10989:440,usability,input,inputs,440,"[RF] Fixup to parameter index calculation in ParamHistFunc; Last year, with commit 3657e7c, the parameter index calculation was. changed to be on the fly instead of using a look-up map, which is much. faster. However, the implemented formula was not correct for two or three. dimensions, which is fixed by this commit. To make sure that the index computation is correct this time, the new. code was tested in this code snippet with various inputs:. ```C++. void runTest(int nx = 42, int ny = 42, int nz = 42) {. const int nxy = nx * ny;. const int nyz = ny * nz;. for (int i = 0; i < nx; ++i) {. for (int j = 0; j < ny; ++j) {. for (int k = 0; k < nz; ++k) {. const int index = k + j * nz + i * ny * nz;. const int gammaIndex = i + j * nx + k * nx * ny;. const int i2 = index / nyz;. const int tmp = index % nyz;. const int j2 = tmp / nz;. const int k2 = tmp % nz;. const int gammaIndex2 = i2 + j2 * nx + k2 * nxy;. if (gammaIndex2 != gammaIndex) {. std::cout << ""The unraveled indices were not correct!"". << std::endl;. return;. }. }. }. }. }. ```. Needs to be backported to the 6.26 branch to get into the 6.26.06 patch. release. This commit the following problem reported on the forum:. https://root-forum.cern.ch/t/cpycppyy-segfault-on-mac-m1/50822",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10989
https://github.com/root-project/root/issues/10990:485,deployability,patch,patch,485,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:661,deployability,patch,patch,661,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:668,deployability,contain,contains,668,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1589,deployability,build,build,1589,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1720,deployability,patch,patches,1720,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:774,modifiability,Extens,ExtensionBlockCount,774,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:806,modifiability,Extens,ExtensionBlocks,806,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:485,safety,patch,patch,485,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:661,safety,patch,patch,661,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1543,safety,input,input,1543,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1720,safety,patch,patches,1720,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:485,security,patch,patch,485,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:661,security,patch,patch,661,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1720,security,patch,patches,1720,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1808,testability,context,context,1808,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1837,testability,context,context,1837,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:733,usability,statu,status,733,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:876,usability,statu,status,876,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1329,usability,behavi,behavior,1329,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1398,usability,behavi,behavior,1398,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10990:1543,usability,input,input,1543,"libAfterImage: TEve broken with giflib 5; - [x] Checked for duplicates (related to https://sft.its.cern.ch/jira/browse/ROOT-7904). <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. A patch from Gentoo imported in d9ca8cb6e3b1e4bdd70041c43805f0851aea7c9e (https://gitweb.gentoo.org/repo/gentoo.git/plain/media-libs/libafterimage/files/libafterimage-giflib5-v2.patch) contains a bogus call. ```diff. +#if (GIFLIB_MAJOR>=5). + 		if ((status = GifAddExtensionBlock(&temp_save.ExtensionBlockCount, &temp_save.ExtensionBlocks,. + ExtCode, sizeof(ExtData), ExtData)) == GIF_OK). + status = DGifGetExtension(gif,&ExtCode,&ExtData);. +#else. ```. where. ```. GifByteType *ExtData;. ```. so `sizeof(ExtData)` is a size of a pointer when it's probably has to be a size of some data block. Which results in a crash when trying to use TEve:. ```. root [0] TEveManager::Create(). gif2ASImage():2300:</nix/store/jhzzgdncnmwzdb2jp9dhmv9bb2nyxcl3-root-6.24.06/icons/eve_text.gif> (null). *** Break *** segmentation violation. ```. ### Expected behavior. TEve works. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ### Setup. ROOT 6.24.06 compiled against an external libAfterImage, with the same Gentoo patches applied to compile against giflib 5 . Crash reproduced on macOS. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10990
https://github.com/root-project/root/issues/10991:1633,availability,sli,slightly,1633,"eters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Cen",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2520,availability,Operat,Operating,2520," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2595,availability,down,download,2595," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:612,deployability,contain,contains,612,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:657,deployability,observ,observable,657,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:796,deployability,fail,fails,796,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1414,deployability,build,build,1414,"ster"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2508,deployability,version,version,2508," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2577,deployability,instal,install,2577," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:599,energy efficiency,cpu,cpu,599,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:5,integrability,Batch,Batch,5,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:566,integrability,Batch,BatchMode,566,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2254,integrability,Batch,BatchMode,2254," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2444,integrability,Batch,BatchMode,2444," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2508,integrability,version,version,2508," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:57,modifiability,paramet,parameters,57,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:632,modifiability,paramet,parameters,632,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1146,modifiability,paramet,parameters,1146,"m/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.add",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2331,modifiability,paramet,parameter,2331," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2508,modifiability,version,version,2508," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:5,performance,Batch,Batch,5,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:566,performance,Batch,BatchMode,566,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:599,performance,cpu,cpu,599,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2254,performance,Batch,BatchMode,2254," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2444,performance,Batch,BatchMode,2444," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:796,reliability,fail,fails,796,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1633,reliability,sli,slightly,1633,"eters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Cen",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1368,safety,input,input,1368,"for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""App",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:657,testability,observ,observable,657,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2686,testability,context,context,2686," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:2715,testability,context,context,2715," the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""Approximation only"". . // works. //g.fitTo(*ds, RooFit::Save(true), RooFit::BatchMode(true))->Print(""V"");. }. ```. ### Setup. <!--. 1. ROOT version. 2. Operating system. 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. Centos7. ROOT 6.26.04 from LCG dev4. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:459,usability,clear,clear,459,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:507,usability,behavi,behavior,507,"[RF] Batch mode with RooSimultaneous introduces spurious parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1052,usability,behavi,behavior,1052," parameters; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynam",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1070,usability,clear,clear,1070,"] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCatego",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1223,usability,behavi,behavior,1223,"ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, Roo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/issues/10991:1368,usability,input,input,1368,"for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. When fitting a RooSimultaneous pdf using BatchMode(true) (which should be cpu) the fit contains additional parameters, one for each observable, called `_<first category label>_<obs name>`, where the category is the one used in the RooSimultaneous. The fit converges, but fails at the HESSE step, leading to an ""approximation only"" covariance matrix. The label used is, from what I understood, based on label ordering and not the indices. The mapping from category label to index however influences the fit result. ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. No extra parameters, successful HESSE. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. ```C++. void test_batchModeCategory() {. RooRealVar x(""x"", """", 0, 1);. RooRealVar rnd(""rnd"", """", 0, 1);. // change this mapping from labels to indices to change the fit result (slightly). RooThresholdCategory catThr(""cat"", """", rnd, ""a"", 2);. catThr.addThreshold(1./3, ""b"", 0);. catThr.addThreshold(2./3, ""c"", 1);. . RooRealVar m(""m"", """", 0.5, 0, 1);. RooGaussian g(""g"", """", x, m, RooFit::RooConst(0.1));. RooUniform rndPdf(""rndPdf"", """", rnd);. RooProdPdf pdf(""pdf"", """", RooArgSet(g, rndPdf));. . auto ds = pdf.generate(RooArgSet(x, rnd), RooFit::Name(""ds""), RooFit::NumEvents(100));. auto cat = dynamic_cast<RooCategory*>(ds->addColumn(catThr));. . RooSimultaneous sim(""sim"", """", *cat);. sim.addPdf(g, ""a"");. sim.addPdf(g, ""b"");. sim.addPdf(g, ""c"");. . sim.fitTo(*ds, RooFit::Save(true). , RooFit::BatchMode(true) // commenting this solves the issue. )->Print(""V"");. // _a_x parameter in results, cov matrix is ""App",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10991
https://github.com/root-project/root/pull/10992:297,deployability,updat,updated,297,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:139,integrability,complian,compliant,139,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:60,modifiability,variab,variable,60,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:234,modifiability,variab,variables,234,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:139,safety,compl,compliant,139,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:266,safety,test,tested,266,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:297,safety,updat,updated,297,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:139,security,compl,compliant,139,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:297,security,updat,updated,297,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10992:266,testability,test,tested,266,[cling-cpt] Added indentation and spacing as well as fixing variable references [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Added indentation and spacing as well as getting rid of unused variables. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10992
https://github.com/root-project/root/pull/10993:130,deployability,patch,patch,130,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:332,deployability,updat,updated,332,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:140,modifiability,extens,extensively,140,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:130,safety,patch,patch,130,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:152,safety,test,tested,152,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:302,safety,test,tested,302,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:332,safety,updat,updated,332,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:130,security,patch,patch,130,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:332,security,updat,updated,332,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:152,testability,test,tested,152,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10993:302,testability,test,tested,302,"Allow multidimensional treatment of Barlow-Beeston; . # This Pull request:. Enables Barlow-Beeston in multidimensional fits. This patch was extensively tested and used by P. Hamilton et al. in LHCb. ## Changes or fixes:. Loop over all entries, not just the x-axis of a histogram. ## Checklist:. - [x ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10993
https://github.com/root-project/root/pull/10994:288,availability,error,errors,288,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:315,availability,error,error,315,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:180,deployability,build,build,180,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:393,deployability,updat,updated,393,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:44,integrability,sub,subprocess,44,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:217,integrability,sub,subprocess,217,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:288,performance,error,errors,288,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:315,performance,error,error,315,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:288,safety,error,errors,288,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:315,safety,error,error,315,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:362,safety,test,tested,362,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:393,safety,updat,updated,393,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:393,security,updat,updated,393,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:362,testability,test,tested,362,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:288,usability,error,errors,288,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10994:315,usability,error,error,315,[cling-cpt] Used wget function to replace 3 subprocess calls and fixed up download_llvm_binary function [skip-ci]; # This Pull request: Is intended to fix the LLVM prebuilt binary build. ## Changes or fixes: Replaced subprocess calls that use wget with the wget function and fixed naming errors and fixed undefined error regarding llvm_dir. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10994
https://github.com/root-project/root/pull/10995:330,deployability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,integrability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:731,integrability,Batch,BatchMode,731,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,interoperability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,modifiability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:33,performance,cach,cache,33,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:177,performance,cach,cache,177,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:366,performance,cach,cache,366,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:731,performance,Batch,BatchMode,731,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,reliability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:391,safety,test,test,391,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,security,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:330,testability,integr,integration,330,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:386,testability,unit,unit,386,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:391,testability,test,test,391,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/pull/10995:471,usability,Close,Closes,471,"[RF] Fix RooAddPdf::fixCoefRange cache issue with createIntegral; When the normalization range for coefficient determination of a. RooAddPdf is changed, the AddPdf's projection cache needs to be reset,. just like it is already done in `RooAddPdf::fixCoefNormalization`. Otherwise, there will be problems in the pdf evaluation and integration. because the projection cache is invalid. A unit test based on the GitHub issue that reported this problem is also. implemented. Closes https://github.com/root-project/root/issues/10988. Furthermore, another potential RooAddPdf problem is fixed, where several instances of RooRecursiveFraction were created with the same name (which could become problematic for example when using the new BatchMode).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10995
https://github.com/root-project/root/issues/10996:18,deployability,fail,fails,18,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:567,deployability,Updat,Update,567,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:554,energy efficiency,Draw,Draw,554,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:721,energy efficiency,Draw,Draw,721,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:27,integrability,batch,batch,27,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:165,integrability,batch,batch,165,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:253,integrability,batch,batch,253,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:299,integrability,batch,batch,299,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:1416,integrability,batch,batch-not-in-interactive-mode,1416,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:27,performance,batch,batch,27,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:165,performance,batch,batch,165,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:253,performance,batch,batch,253,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:299,performance,batch,batch,299,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:1416,performance,batch,batch-not-in-interactive-mode,1416,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:18,reliability,fail,fails,18,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:148,reliability,doe,does,148,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:414,safety,test,test,414,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:567,safety,Updat,Update,567,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:191,security,rotat,rotation,191,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:567,security,Updat,Update,567,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:613,security,rotat,rotated,613,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:920,security,Team,Team,920,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:414,testability,test,test,414,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:1274,testability,context,context,1274,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:220,usability,behavi,behavior,220,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:1125,usability,help,help,1125,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/issues/10996:1429,usability,interact,interactive-mode,1429,"TASImage::FromPad fails in batch mode if combined with Flip; - [x] Checked for duplicates. ### Describe the bug. TASImage::FromPad + TASImage::Flip does not work in batch mode, no matter the rotation angle. ### Expected behavior. It should work also in batch mode. ### To Reproduce. Run the code in batch mode below to get a black output. Comment the line `Flip(0)` and you'll get the correct output. ```cpp. void test(). {. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. h->Draw();. c1->Update();. TCanvas *c2 = new TCanvas(""c2"",""c1 rotated"",600,600);. TASImage *img = new TASImage();. img->FromPad(c1);. img->Flip(0);. img->Mirror();. img->Draw(""x"");. c2->Print(""c2.png"");. }. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context. https://root-forum.cern.ch/t/bug-of-tasimage-when-use-tasimage-flip/50827/. https://root-forum.cern.ch/t/timage-rendered-in-black-in-batch-not-in-interactive-mode/16781.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/10996
https://github.com/root-project/root/pull/10997:313,deployability,Build,Build,313,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:441,deployability,updat,updated,441,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:53,energy efficiency,core,cores,53,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:153,energy efficiency,core,cores,153,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:216,energy efficiency,core,cores,216,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:326,energy efficiency,core,cores,326,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:31,interoperability,specif,specify,31,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:131,interoperability,specif,specify,131,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:341,modifiability,variab,variable,341,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:410,safety,test,tested,410,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:441,safety,updat,updated,441,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:441,security,updat,updated,441,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:410,testability,test,tested,410,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:23,usability,user,user,23,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:123,usability,user,user,123,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10997:369,usability,user,user,369,"[cling-cpt] Allows for user to specify the number of cores used during make [skip-ci]; # This Pull request: Allows for the user to specify the number of cores used during make. ## Changes or fixes: Added a number-of-cores option to the parser and added a condition to check if option was used, and if it is,. the Build object cores instance variable will be set to the user passed number. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10997
https://github.com/root-project/root/pull/10998:26,deployability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:43,deployability,fail,fail-on-missing,43,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:59,deployability,build,build,59,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:96,deployability,build,build,96,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:26,integrability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:26,modifiability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10998:43,reliability,fail,fail-on-missing,43,Require nlohmann_json 3.9 version also for fail-on-missing build; 3.9 was set only for `normal` build,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10998
https://github.com/root-project/root/pull/10999:17,modifiability,paramet,parameter,17,Properly set len parameter for GifAddExtensionBlock; May be fixes #10990,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/10999
https://github.com/root-project/root/pull/11000:26,deployability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/pull/11000:43,deployability,fail,fail-on-missing,43,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/pull/11000:59,deployability,build,build,59,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/pull/11000:26,integrability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/pull/11000:26,modifiability,version,version,26,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/pull/11000:43,reliability,fail,fail-on-missing,43,Require nlohmann_json 3.9 version also for fail-on-missing build [6.26]; Backport of #10998,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11000
https://github.com/root-project/root/issues/11002:470,availability,error,errors,470,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:513,availability,error,error,513,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:17,integrability,sub,substitution,17,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:413,integrability,Filter,Filter,413,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:677,integrability,sub,substitute,677,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:854,integrability,sub,substitutions,854,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:980,integrability,filter,filter-question,980,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:470,performance,error,errors,470,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:513,performance,error,error,513,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:840,performance,perform,perform,840,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:470,safety,error,errors,470,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:513,safety,error,error,513,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:538,security,ident,identifier,538,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:470,usability,error,errors,470,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:513,usability,error,error,513,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/issues/11002:840,usability,perform,perform,840,"[DF] Wrong regex substitution when generating code to jit; A reproducer:. ```cpp. #include <ROOT/RDataFrame.hxx>. int main() {. {. auto df = ROOT::RDataFrame(10).Define(""x"", [] { return 42; });. df.Snapshot(""t"", ""f.root"");. df.Snapshot(""fr"", ""fr.root"");. }. TFile f(""f.root"");. auto *t = f.Get<TTree>(""t"");. TFile frf(""fr.root"");. auto *fr = frf.Get<TTree>(""fr"");. t->AddFriend(fr);. ROOT::RDataFrame df(*t);. df.Filter(""x > 0 && fr.x > 0"").Count().GetValue();. }. ```. errors out with:. ```. input_line_32:2:67: error: use of undeclared identifier 'fr'. auto func0(const Int_t var0, const Int_t var1){return var0 > 0 && fr.var0 > 0. ^. ```. The reason is that in this case we substitute column names with `var0`, `var1` placeholder names starting with `""x""`, resulting in the broken expression with `fr.var0`. I think a possible fix is to perform these substitutions from the longest to the shortest column names. First reported at https://root-forum.cern.ch/t/rdataframe-string-filter-question/50872 .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11002
https://github.com/root-project/root/pull/11003:248,deployability,updat,updated,248,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:152,modifiability,paramet,parameters,152,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:163,modifiability,concern,concerning,163,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:218,safety,test,tested,218,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:248,safety,updat,updated,248,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:248,security,updat,updated,248,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:163,testability,concern,concerning,163,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:218,testability,test,tested,218,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/pull/11003:115,usability,document,documentation,115,[docu] Clarify window size vs canvas size; # This Pull request:. ## Changes or fixes:. Clarifies ambiguous doxygen documentation of TCanvas constructor parameters concerning window vs canvas size. ## Checklist:. - [ ] tested changes locally. - [x] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11003
https://github.com/root-project/root/issues/11004:32,integrability,batch,batch,32,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:45,integrability,batch,batch,45,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:222,integrability,Batch,Batch,222,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:318,integrability,batch,batch,318,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:32,performance,batch,batch,32,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:45,performance,batch,batch,45,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:222,performance,Batch,Batch,222,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:318,performance,batch,batch,318,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:413,safety,test,test,413,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:504,safety,test,test,504,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:528,safety,test,test,528,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:701,security,Team,Team,701,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:413,testability,test,test,413,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:504,testability,test,test,504,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:528,testability,test,test,528,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:186,usability,Interact,Interactive,186,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:263,usability,behavi,behavior,263,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/issues/11004:906,usability,help,help,906,"TCanvas size is inconsistent in batch vs non-batch mode; - [x] Checked for duplicates. ### Describe the bug. I see one small issue when saving a 600x600 TCanvas window as png. I get:. - Interactive mode: 598x571 pixels. - Batch mode: 596x572 pixels. ### Expected behavior. No pixel difference is found between running batch or not. Right now there is an offset of 1 up to 2 pixels. ### To Reproduce. ```cpp. void test() {. TCanvas *c = new TCanvas(""c1"",""c1"",600,600);. c->SaveAs(""c1.png"");. }. //root -l test.C -b -q. //root -l test.C -q. ```. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2021, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Jan 11 2022, 18:39:08 |. | From heads/master@v6-25-01-2870-gdac9b6398d |. | With c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0 |. | Try '.help', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11004
https://github.com/root-project/root/pull/11005:215,availability,Operat,Operations,215,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:14,deployability,Updat,Updated,14,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:370,deployability,updat,updated,370,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:487,deployability,updat,updated,487,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:280,reliability,doe,does,280,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:14,safety,Updat,Updated,14,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:370,safety,updat,updated,370,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:457,safety,test,tested,457,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:487,safety,updat,updated,487,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:14,security,Updat,Updated,14,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:370,security,updat,updated,370,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:487,security,updat,updated,487,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:457,testability,test,tested,457,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11005:325,usability,guid,guide,325,"[skip-ci][DF] Updated explanation of actions and fixes of grammar mistakes in df001;  tutorials. # This Pull request: df001_Introduction tutorial. ## Changes or fixes:. The explanation of the actions in the part ""Operations on dataframe"" using ForEach() and TActionResultPtr<T> does not match with the RDataFrame Reference guide and is hence outdated. Now there is an updated text. Also, a few grammar mistakes are now corrected for. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11005
https://github.com/root-project/root/pull/11006:217,deployability,updat,updated,217,[skip-ci][DF] Fix typos and grammar mistakes in df002 tutorials; # This Pull request: df002 tutorial. ## Changes or fixes:. Typos and grammar mistakes are now fixed. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11006
https://github.com/root-project/root/pull/11006:187,safety,test,tested,187,[skip-ci][DF] Fix typos and grammar mistakes in df002 tutorials; # This Pull request: df002 tutorial. ## Changes or fixes:. Typos and grammar mistakes are now fixed. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11006
https://github.com/root-project/root/pull/11006:217,safety,updat,updated,217,[skip-ci][DF] Fix typos and grammar mistakes in df002 tutorials; # This Pull request: df002 tutorial. ## Changes or fixes:. Typos and grammar mistakes are now fixed. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11006
https://github.com/root-project/root/pull/11006:217,security,updat,updated,217,[skip-ci][DF] Fix typos and grammar mistakes in df002 tutorials; # This Pull request: df002 tutorial. ## Changes or fixes:. Typos and grammar mistakes are now fixed. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11006
https://github.com/root-project/root/pull/11006:187,testability,test,tested,187,[skip-ci][DF] Fix typos and grammar mistakes in df002 tutorials; # This Pull request: df002 tutorial. ## Changes or fixes:. Typos and grammar mistakes are now fixed. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11006
https://github.com/root-project/root/pull/11007:196,deployability,updat,updated,196,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11007:166,safety,test,tested,166,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11007:196,safety,updat,updated,196,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11007:196,security,updat,updated,196,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11007:166,testability,test,tested,166,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11007:130,usability,document,documentation,130,[skip-ci][DF] Df004 fixes; # This Pull request: df004 tutorial. ## Changes or fixes:. Correction of minor grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11007
https://github.com/root-project/root/pull/11008:15,integrability,sub,substiution,15,[DF] Fix regex substiution in code to jit; This PR fixes https://github.com/root-project/root/issues/11002.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11008
https://github.com/root-project/root/pull/11009:109,usability,close,close,109,[RF] Replace `MakeIterator()` with range-based loops in RooFit; This is a code modernization that is done to close #8777.,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11009
https://github.com/root-project/root/pull/11010:48,availability,error,error,48,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:246,deployability,updat,updated,246,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:113,integrability,complian,compliant,113,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:48,performance,error,error,48,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:48,safety,error,error,48,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:113,safety,compl,compliant,113,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:215,safety,test,tested,215,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:246,safety,updat,updated,246,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:113,security,compl,compliant,113,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:246,security,updat,updated,246,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:215,testability,test,tested,215,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11010:48,usability,error,error,48,[cling-cpt] Split long lines to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11010
https://github.com/root-project/root/pull/11011:57,availability,error,error,57,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:261,deployability,updat,updated,261,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:128,integrability,complian,compliant,128,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:57,performance,error,error,57,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:57,safety,error,error,57,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:128,safety,compl,compliant,128,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:230,safety,test,tested,230,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:261,safety,updat,updated,261,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:128,security,compl,compliant,128,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:261,security,updat,updated,261,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:230,testability,test,tested,230,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11011:57,usability,error,error,57,[cling-cpt] More splitting lines for getting rid of E501 error cont. [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes issue #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11011
https://github.com/root-project/root/pull/11012:48,availability,error,error,48,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:246,deployability,updat,updated,246,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:113,integrability,complian,compliant,113,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:48,performance,error,error,48,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:48,safety,error,error,48,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:113,safety,compl,compliant,113,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:215,safety,test,tested,215,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:246,safety,updat,updated,246,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:113,security,compl,compliant,113,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:246,security,updat,updated,246,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:215,testability,test,tested,215,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11012:48,usability,error,error,48,[cling-cpt] Split lines more to get rid of E501 error [skip-ci]; # This Pull request: Makes the code more flake8 compliant. ## Changes or fixes: Split lines that were longer than 79 characters. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11012
https://github.com/root-project/root/pull/11013:132,deployability,continu,continuing-the-discussion-from-an-unwanted-horizontal-line-is-drawn-at-y-,132,THStack histogram line width should be 0; THStack fHistogram line width should be 0 as suggested here: https://root-forum.cern.ch/t/continuing-the-discussion-from-an-unwanted-horizontal-line-is-drawn-at-y-0/50877/17,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11013
https://github.com/root-project/root/pull/11013:194,energy efficiency,draw,drawn-at-y-,194,THStack histogram line width should be 0; THStack fHistogram line width should be 0 as suggested here: https://root-forum.cern.ch/t/continuing-the-discussion-from-an-unwanted-horizontal-line-is-drawn-at-y-0/50877/17,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11013
https://github.com/root-project/root/pull/11014:15,integrability,sub,substitution,15,[DF] Fix regex substitution in code to jit (v6.26); Fix https://github.com/root-project/root/issues/11002,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11014
https://github.com/root-project/root/pull/11015:193,deployability,depend,depending,193,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:250,deployability,depend,dependsOnValue,250,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:294,deployability,observ,observables,294,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:400,deployability,observ,observables,400,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:613,deployability,depend,depends,613,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:624,deployability,observ,observables,624,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:741,deployability,observ,observables,741,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:178,integrability,compon,component,178,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:193,integrability,depend,depending,193,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:250,integrability,depend,dependsOnValue,250,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:613,integrability,depend,depends,613,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:178,interoperability,compon,component,178,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:178,modifiability,compon,component,178,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:193,modifiability,depend,depending,193,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:250,modifiability,depend,dependsOnValue,250,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:548,modifiability,variab,variables,548,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:613,modifiability,depend,depends,613,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:651,modifiability,paramet,parameters,651,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:693,modifiability,paramet,parameters,693,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:163,performance,time,times,163,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:193,safety,depend,depending,193,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:250,safety,depend,dependsOnValue,250,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:613,safety,depend,depends,613,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:805,security,hash,hash-assisted,805,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:193,testability,depend,depending,193,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:250,testability,depend,dependsOnValue,250,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:294,testability,observ,observables,294,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:400,testability,observ,observables,400,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:613,testability,depend,depends,613,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:624,testability,observ,observables,624,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/pull/11015:741,testability,observ,observables,741,"[RF] Speed up RooProdPdf::getConstraints() for large computation graphs; In `RooProdPdf::getConstraints()`, the full computation graph was. traversed two or three times for each component pdf, depending on the. code branch. There were calls to `pdf->dependsOnValue()` and. `pdf->getParameters(&observables)`, but both are very expensive for. large computation graphs because they check if any of the observables is. in the server list of any RooAbsArg in the graph. It is much cheaper to call `pdf->getParameters(nullptr)` to get all. value server variables of a pdf, and then use `overlaps` to check if the. pdf depends on observables or constrained parameters. To get then the set of actual parameters, it is suggested to use. `tmp.remove(observables)`, which is is cheap for RooArgSets because of. the hash-assisted find by name. This commit speeds up the `createNLL()` call for the ATLAS Higgs. combination workspace by 30 %. Here one can see the flamegraphs for createNLL in the ATLAS Higgs combination fit [before this commit](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_before_11015.svg) and [after](https://rembserj.web.cern.ch/rembserj/flamegraphs/perf_after_11015.svg).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11015
https://github.com/root-project/root/issues/11016:60,deployability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,deployability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,deployability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,deployability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,deployability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1011,deployability,observ,observed,1011,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,deployability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,integrability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,integrability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,integrability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,integrability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,integrability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,integrability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,interoperability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,interoperability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,interoperability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,interoperability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,interoperability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,interoperability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,modifiability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,modifiability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,modifiability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,modifiability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,modifiability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:791,modifiability,paramet,parameters,791,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,modifiability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,reliability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,reliability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,reliability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,reliability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,reliability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,reliability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,security,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,security,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:171,security,ident,identical,171,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,security,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,security,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,security,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,security,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:60,testability,integr,integration,60,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:131,testability,integr,integration,131,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:236,testability,integr,integration,236,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:316,testability,integr,integration,316,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:461,testability,integr,integration,461,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1000,testability,context,context,1000,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1011,testability,observ,observed,1011,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1129,testability,integr,integrate-,1129,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:291,usability,behavi,behavior,291,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:434,usability,document,documentation,434,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:485,usability,support,supports,485,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11016:1036,usability,behavi,behavior,1036,"[hist] Fit to TH2 silently ignores the `""I""` option for bin integration; ### Describe the bug. When using the `""I""` option for bin integration to fit a TH2, the result is identical to the fit result without that option, even though bin integration should change the fit result. ### Expected behavior. Either the bin integration should be done and therefore the fit result changes, or there should be warning printed and a note in the documentation that the bin integration option only supports 1-d histograms. ### To Reproduce. ```C++. void script() {. auto f2 = new TF2(""f2"",""[norm]*(5-[coefx]*x)*(5-y)"",0,5,0,5);. f2->SetParameters(1.0, 1.0);. int nBins = 10;. auto h2 = new TH2D(""h2"", ""h2"", nBins, 0., 5., nBins, 0., 5.);. h2->FillRandom(""f2"", 500000);. gStyle->SetOptFit(1111);. // kick parameters a bit before fitting. f2->SetParameters(0.9, 0.9);. h2->Fit(f2, """", """");. // h2->Fit(f2, ""I"", """"); // gives exactly the the same result. }. ```. ### Setup. ROOT master on Arch Linux. ### Additional context. I observed this unexpected behavior when trying to reproduce a problem on the ROOT forum:. https://root-forum.cern.ch/t/integrate-tf2-function-over-each-bin/50882.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11016
https://github.com/root-project/root/issues/11017:2240,availability,Operat,Operating,2240,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2315,availability,down,download,2315,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1800,deployability,build,build,1800,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2228,deployability,version,version,2228,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2297,deployability,instal,install,2297,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2385,deployability,instal,install,2385,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1086,integrability,Filter,Filter,1086,"-. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2228,integrability,version,version,2228,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2228,modifiability,version,version,2228,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:22,reliability,doe,doesn,22,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:820,reliability,doe,doesn,820,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1754,safety,input,input,1754,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:947,testability,simpl,simplified,947,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2409,testability,context,context,2409,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:2438,testability,context,context,2438,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:446,usability,clear,clear,446,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:494,usability,behavi,behavior,494,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:947,usability,simpl,simplified,947,"[RF] RooDataSetHelper doesn't respect RooRealVar range; - [x] Checked for duplicates. <!--. Please search in. * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue). * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `R",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1188,usability,user,user-images,1188,"ttps://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT). for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooR",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1305,usability,user,user-images,1305,"re very welcome to add to the existing report, for instance ""issue still exists in today's master"". -->. ### Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / bin",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1414,usability,behavi,behavior,1414,"# Describe the bug. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1432,usability,clear,clear,1432,"g. <!--. A clear and concise description of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any oth",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1609,usability,behavi,behavior,1609,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/issues/11017:1754,usability,input,input,1754,"n of what the wrong behavior is. -->. I have some data in RDataFrame, and I want to fit them using RooFit. I book a `RooDataSet` using the `RooDataSetHelper` like this. ```cpp. auto data_set = df.Book<double, double>(. RooDataSetHelper(""data_set"", ""title"", RooArgSet(var1, var2)), {""var1"", ""var2""});. ```. The fit is wrong because the `data_set` doesn't respect the limits on `var1` and `var2`, resulting in an incorrect normalization. The only difference in the following simplified fits is that I used. ```cpp. auto data_set = df.Book<double, double>(. ```. for the first one, and . ```cpp. auto data_set = df.Filter(""var2>2005 && var2<2020"").Book<double, double>(. ```. for the second one. ![all_wrong](https://user-images.githubusercontent.com/23052054/180235896-9f9d8cdb-5804-4567-9f0f-e1279c141777.png). ![all_right](https://user-images.githubusercontent.com/23052054/180235919-42ba997b-7bcb-4462-8b81-eab405454b1d.png). ### Expected behavior. <!--. A clear and concise description of what you expected to happen. -->. I expected the RooDataSet to account for the RooRealVar range. ### To Reproduce. <!--. Steps to reproduce the behavior:. 1. Your code that triggers the issue: at least a part; ideally something we can run ourselves. 2. Don't forget to attach the required input files! 3. How to run your code and / or build it, e.g. `root myMacro.C`, ... -->. 1. Get any `RDataFrame`. 2. Create a `RooRealVar` with limits narrower than the corresponding data in the `RDataFrame`. 3. Use `RooDataSetHelper` to book a `RooDataSet` from the `RDataFrame` using the `RooRealVar`. 4. Fit the `RooRealVar` of the `RooDataSet`. 5. The fit will be wrong unless you cut on the `RDataFrame` to match the limits of the `RooRealVar`. ### Setup. <!--. 1. ROOT version. 6. Operating system. 7. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. -->. ROOT 6.26/04. macOS 12.4. Brew install. ### Additional context. <!--. Add any other context about the problem here. -->.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11017
https://github.com/root-project/root/pull/11018:97,availability,consist,consistent,97,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:248,deployability,log,logic,248,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:340,deployability,log,logic,340,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:510,deployability,observ,observed,510,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:279,energy efficiency,load,loadValues,279,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:23,integrability,event,events,23,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:171,integrability,event,events,171,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:503,integrability,event,events,503,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:279,performance,load,loadValues,279,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:248,safety,log,logic,248,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:301,safety,test,test,301,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:340,safety,log,logic,340,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:248,security,log,logic,248,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:340,security,log,logic,340,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:248,testability,log,logic,248,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:296,testability,unit,unit,296,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:301,testability,test,test,301,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:340,testability,log,logic,340,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:510,testability,observ,observed,510,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:58,usability,Help,Helper,58,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:97,usability,consist,consistent,97,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11018:538,usability,Close,Closes,538,"[RF] Skip out-of-range events in RDataFrame to RooDataSet Helper; The RDataFrameHelper should be consistent with creating a RooDataSet. from a TTree, meaning out-of-range events should be skipped. This is. implemented in this commit, borrowing the logic from. `RooTreeDataStore::loadValues()`. A unit test is also implemented. The previous logic of just taking just all values to fill the dataset. was very dangerous, because these values then clipped to the RooRealVar. limits and biased the number of events observed at the boundaries. Closes https://github.com/root-project/root/issues/11017.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11018
https://github.com/root-project/root/pull/11019:303,availability,state,statements,303,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:23,deployability,build,build,23,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:144,deployability,build,building,144,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:220,deployability,build,build,220,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:242,deployability,build,build,242,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:466,deployability,updat,updated,466,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:56,energy efficiency,current,current-dev,56,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:208,energy efficiency,current,current-dev-build,208,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:334,energy efficiency,current,current-dev,334,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:303,integrability,state,statements,303,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:165,modifiability,pac,packaging,165,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:391,modifiability,pac,packaging,391,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:435,safety,test,tested,435,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:466,safety,updat,updated,466,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:466,security,updat,updated,466,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:435,testability,test,tested,435,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11019:111,usability,user,users,111,"[cling-cpt] Made a new build option for last-stable and current-dev [skip-ci]; # This Pull request: Allows for users to have the option of just building the CPT not packaging it. ## Changes or fixes: Added a current-dev-build and last-stable-build option in the argument parser, and added additional if statements if it is the normal current-dev or last-stable option, so that there is also packaging like normal. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11019
https://github.com/root-project/root/pull/11020:296,availability,state,statements,296,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:18,deployability,build,build,18,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:121,deployability,build,build,121,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:138,deployability,build,building,138,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:211,deployability,build,build,211,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:417,deployability,updat,updated,417,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:296,integrability,state,statements,296,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:39,interoperability,platform,platform,39,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:158,interoperability,specif,specific,158,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:167,interoperability,platform,platform,167,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:233,interoperability,platform,platform,233,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:346,modifiability,pac,package,346,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:386,safety,test,tested,386,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:417,safety,updat,updated,417,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:417,security,updat,updated,417,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:386,testability,test,tested,386,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/pull/11020:332,usability,user,user,332,"[cling-cpt] Added build option for the platform tags to the argument parser [skip-ci]; # This Pull request: Adds another build option for building Cling with specific platform tags. . ## Changes or fixes: Added build options for the platform tags to the argument parser, then added additional if statements for checking whether the user wants to package it or not. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11020
https://github.com/root-project/root/issues/11021:549,availability,ERROR,ERROR,549,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:615,availability,ERROR,ERROR,615,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1230,availability,ERROR,ERROR,1230,"aussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1325,availability,ERROR,ERROR,1325,"tially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,60",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1020,deployability,fail,fails,1020,"Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubuserconte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1175,deployability,FAIL,FAILED,1175,"tion. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2463,energy efficiency,Draw,Draw,2463,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1706,interoperability,share,share,1706,"5290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:287,modifiability,paramet,parameters,287,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:577,modifiability,PARAMET,PARAMETER,577,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1275,modifiability,PARAMET,PARAMETER,1275,"ly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ``",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1633,modifiability,paramet,parameters,1633," 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. |",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1818,modifiability,paramet,parameters,1818,"e decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/ma",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1936,modifiability,paramet,parameter,1936,". (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.lic",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:549,performance,ERROR,ERROR,549,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:615,performance,ERROR,ERROR,615,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:857,performance,tune,tune,857,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1230,performance,ERROR,ERROR,1230,"aussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1325,performance,ERROR,ERROR,1325,"tially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,60",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1020,reliability,fail,fails,1020,"Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubuserconte",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1175,reliability,FAIL,FAILED,1175,"tion. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:549,safety,ERROR,ERROR,549,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:615,safety,ERROR,ERROR,615,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1009,safety,compl,completely,1009,"tting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.github",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1230,safety,ERROR,ERROR,1230,"aussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1325,safety,ERROR,ERROR,1325,"tially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,60",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2126,safety,compl,completely,2126,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1009,security,compl,completely,1009,"tting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.github",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2126,security,compl,completely,2126,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2710,security,Team,Team,2710,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:3064,testability,context,context,3064,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:361,usability,user,user-images,361,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:485,usability,STATU,STATUS,485,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:549,usability,ERROR,ERROR,549,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:615,usability,ERROR,ERROR,615,"[Fit Panel] Fitting to Gaus + Pol0 in two steps is unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1044,usability,user,user-images,1044," unnecessarily hard; ### Explain what you would like to see improved. My students and myself often encounter the following situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1168,usability,STATU,STATUS,1168,"g situation. We are trying to make a fit of a histogram to a Gaussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-im",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1230,usability,ERROR,ERROR,1230,"aussian. This works well and ROOT finds perfectly all parameters without having to set them initially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1325,usability,ERROR,ERROR,1325,"tially by hand. ![image](https://user-images.githubusercontent.com/10653970/180315415-84720a1c-e52c-4d32-a7ab-bc86b319967c.png). ```. FCN=220.83 FROM MIGRAD STATUS=CONVERGED 70 CALLS 71 TOTAL. EDM=6.98482e-10 STRATEGY= 1 ERROR MATRIX ACCURATE . EXT PARAMETER STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 Constant 3.92175e+02 4.99591e+00 2.81307e-02 6.15584e-06. 2 Mean 9.95290e-03 1.03175e-02 7.50080e-05 1.55399e-03. 3 Sigma 1.04566e+00 8.42889e-03 1.42471e-05 1.69822e-02. ```. Now, we decide it would be best to fine-tune the fit by also adding a pol0 constant. Thus we click on Add radio-button, pol0. (Results in gaus(0)+pol0(3)). Then, you click on Fit, and the fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,60",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:1996,usability,user,user-images,1996,"he fit completely fails. ![image](https://user-images.githubusercontent.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. --------------------------",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2164,usability,user,user-images,2164,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/issues/11021:2915,usability,help,help,2915,"t.com/10653970/180315692-d3b3f3de-e08d-49d7-9bbe-ddc01231bc00.png). ```. FCN=9324.48 FROM HESSE STATUS=FAILED 11 CALLS 179 TOTAL. EDM=3.13749e-15 STRATEGY= 1 ERROR MATRIX UNCERTAINTY 100.0 per cent. EXT PARAMETER APPROXIMATE STEP FIRST . NO. NAME VALUE ERROR SIZE DERIVATIVE . 1 p0 -2.89841e+05 4.24264e-01 -0.00000e+00 0.00000e+00. 2 p1 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 3 p2 0.00000e+00 1.41421e+00 -0.00000e+00 0.00000e+00. 4 p3 1.17552e+01 3.42858e-01 1.17552e+01 1.63372e-07. ```. So the manual workaround is to set by hand all the initial parameters of the first fit, so that it finally converges. ### Optional: share how it could be improved. After 'adding' a pol0, it would be nice that the initial values of the Gaussian parameters are not reset to zero, but are rescued from the previous fit where only the Gaussian was used. This is the parameter window just before adding pol0:. ![image](https://user-images.githubusercontent.com/10653970/180316740-e5f902e7-fde7-4404-893d-d78474d7e0e1.png). And this is just after adding it, completely 'reset':. ![image](https://user-images.githubusercontent.com/10653970/180316839-3bc72bb9-7146-45ca-8133-5322e69ebeca.png). ### To Reproduce. ```cpp. TCanvas *c1 = new TCanvas(""c1"",""c1"",600,600);. TH1F *h = new TH1F(""gaus"",""gaus"", 100, -5, 5);. h->FillRandom(""gaus"", 10000);. for(int i=1;i<=100;++i) h->AddBinContent(i,5);. h->Draw();. ```. Open Fit Panel, Fit ""gaus"". Then click ""Add"", ""pol0"", click on ""Fit"" again. ### Setup. ```. ------------------------------------------------------------------. | Welcome to ROOT 6.27/01 https://root.cern |. | (c) 1995-2022, The ROOT Team; conception: R. Brun, F. Rademakers |. | Built for linuxx8664gcc on Apr 25 2022, 22:21:18 |. | From heads/master@v6-25-01-3897-gf39eb0e984 |. | With c++ (Ubuntu 8.4.0-1ubuntu1~18.04) 8.4.0 |. | Try '.help'/'.?', '.demo', '.license', '.credits', '.quit'/'.q' |. ------------------------------------------------------------------. ```. ### Additional context.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11021
https://github.com/root-project/root/pull/11022:339,deployability,updat,updated,339,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:98,energy efficiency,Reduc,Reduces,98,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:121,integrability,sub,subprocess,121,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:240,integrability,sub,subprocess,240,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:308,safety,test,tested,308,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:339,safety,updat,updated,339,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:339,security,updat,updated,339,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11022:308,testability,test,tested,308,[cling-cpt] Created new extract_tar function to extract tar files [skip-ci]; # This Pull request: Reduces the use of the subprocess function and makes the code cleaner. ## Changes or fixes: Created a new extract_tar function to replace tar subprocess calls and pythonic tar extractions. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in (https://github.com/root-project/cling/issues/406).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11022
https://github.com/root-project/root/pull/11023:309,performance,memor,memory,309,"[RF] Enable streaming of RooLagrangianMorphFunc and other improvements; This PR enables the streaming of the RooLagrangianMorph by creating dictionaries also for `RooLagrangianMorph::Config`. Furthermore, some improvements are made to the RooLagrangianMorphFunc and its tutorials in separate commits. Tons of memory leaks are fixed in the `RooLagrangianMorphFunc` as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11023
https://github.com/root-project/root/pull/11023:309,usability,memor,memory,309,"[RF] Enable streaming of RooLagrangianMorphFunc and other improvements; This PR enables the streaming of the RooLagrangianMorph by creating dictionaries also for `RooLagrangianMorph::Config`. Furthermore, some improvements are made to the RooLagrangianMorphFunc and its tutorials in separate commits. Tons of memory leaks are fixed in the `RooLagrangianMorphFunc` as well.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11023
https://github.com/root-project/root/pull/11024:219,deployability,updat,updated,219,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11024:189,safety,test,tested,189,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11024:219,safety,updat,updated,219,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11024:219,security,updat,updated,219,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11024:189,testability,test,tested,189,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11024:153,usability,document,documentation,153,[skip-ci][DF] Fixes of grammar mistakes in the df009 tutorial; # This Pull request: df009 tutorial. ## Changes or fixes:. Fixing grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11024
https://github.com/root-project/root/pull/11025:210,deployability,updat,updated,210,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/pull/11025:180,safety,test,tested,180,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/pull/11025:210,safety,updat,updated,210,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/pull/11025:210,security,updat,updated,210,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/pull/11025:180,testability,test,tested,180,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/pull/11025:144,usability,document,documentation,144,[skip-ci][DF] Fixes of grammar mistakes in the df012 tutorials; # This Pull request: df012. ## Changes or fixes:. Fixes grammar mistakes in the documentation. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary). This PR fixes # .,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11025
https://github.com/root-project/root/issues/11026:2003,availability,state,statements,2003," LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2942,energy efficiency,load,loadResult,2942,"following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2973,energy efficiency,Load,LoadTree,2973,"le classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3106,energy efficiency,load,loadResult,3106," See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3122,energy efficiency,load,loadResult,3122," those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3573,energy efficiency,load,loadResult,3573," "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-proje",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:4771,energy efficiency,Load,LoadTree,4771,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:691,integrability,sub,sublist,691,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:703,integrability,sub,sublist,703,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:733,integrability,sub,sublist,733,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:768,integrability,sub,sublist,768,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:821,integrability,sub,sublist,821,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:948,integrability,sub,sublist,948,"Integer overflow in TEntryList; ### Describe the bug. With the following reproducer. ```cpp. #include <TChain.h>. #include <TEntryList.h>. #include <RtypesCore.h>. #include <ROOT/RDataFrame.hxx>. #include <TTreeReader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print deb",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1973,integrability,coupl,couple,1973,"numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->Loa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2003,integrability,state,statements,2003," LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2518,integrability,sub,sublist,2518,"eenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got inpu",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2808,interoperability,format,format,2808,"ryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I gi",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1973,modifiability,coupl,couple,1973,"numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->Loa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2942,performance,load,loadResult,2942,"following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the n",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2973,performance,Load,LoadTree,2973,"le classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3106,performance,load,loadResult,3106," See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3122,performance,load,loadResult,3122," those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and e",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3573,performance,load,loadResult,3573," "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-proje",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:4771,performance,Load,LoadTree,4771,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:5169,reliability,Pra,Practically,5169,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1210,safety,input,input,1210,"ader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1433,safety,input,input,1433,"::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2566,safety,input,input,2566,"eenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3323,safety,input,input,3323,"///////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3351,safety,input,input,3351,"841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which shou",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3422,safety,input,input,3422,"um). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3450,safety,input,input,3450,"dTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but in",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3518,safety,input,input,3518,"list will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3817,safety,input,input,3817,"/**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/roo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3961,safety,input,input,3961,"lLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:4181,security,sign,signature,4181,"repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1973,testability,coupl,couple,1973,"numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->Loa",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1210,usability,input,input,1210,"ader.h>. #include <iostream>. #include <limits>. #include <string>. auto LIMIT = std::numeric_limits<int>::max();. Long64_t OVERLIMIT = 2147483648; // LIMIT + 1. ULong64_t NENTRIES = LIMIT / 100;. void write_tree(). {. ROOT::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1433,usability,input,input,1433,"::RDataFrame df{NENTRIES};. df.Define(""x"", ""rdfentry_"").Snapshot<ULong64_t>(""tree"", ""file.root"", {""x""});. }. void repro(). {. TChain chain{""tree""};. TEntryList elists{};. for (int i = 0; i < 101; i++){. chain.Add(""file.root?#tree"", NENTRIES);. TEntryList sublist{};. sublist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1704,usability,statu,status,1704,"ist.SetTreeName(""tree"");. sublist.SetFileName(""file.root"");. sublist.EnterRange(0, NENTRIES);. elists.AddSubList(&sublist);. }. chain.SetCacheEntryRange(0, OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +1",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1858,usability,statu,status,1858,", OVERLIMIT);. chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:1871,usability,statu,status,1871,". chain.SetEntryList(&elists, ""sync""); // This sets the tree index in the sublist. std::cout << ""std::numeric_limits<int>::max(): "" << LIMIT << ""\n"";. std::cout << ""Total entries in chain: "" << chain.GetEntries() << ""\n"";. std::cout << ""Total entries in entrylist: "" << elists.GetN() << ""\n"";. int treenum_1 = -1;. std::cout << ""Giving input entry "" << LIMIT << ""\n"";. auto eindex_1 = elists.GetEntryAndTree(LIMIT, treenum_1);. std::cout << ""Got tree index "" << treenum_1 << "" and entry index "" << eindex_1 << ""\n"";. int treenum_2 = -1;. std::cout << ""Giving input entry "" << OVERLIMIT << ""\n"";. auto eindex_2 = elists.GetEntryAndTree(OVERLIMIT, treenum_2);. std::cout << ""Got tree index "" << treenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:2566,usability,input,input,2566,"eenum_2 << "" and entry index "" << eindex_2 << ""\n"";. TTreeReader r{&chain, chain.GetEntryList()};. r.SetEntry(OVERLIMIT);. std::string status = (r.GetEntryStatus() == TTreeReader::EEntryStatus::kEntryBeyondEnd) ? ""kEntryBeyondEnd"" : ""not kEntryBeyondEnd"";. std::cout << ""What is the entry status? "" << status << ""\n"";. }. int main(). {. write_tree();. repro();. }. ```. And the following small diff in a couple classes to print debug statements. ```. --- a/tree/tree/src/TEntryList.cxx. +++ b/tree/tree/src/TEntryList.cxx. @@ -155,6 +155,8 @@ See comments to those functions for more details. #include ""TSystem.h"". #include ""TObjString.h"". . +#include <iostream>. +. ClassImp(TEntryList);. . ////////////////////////////////////////////////////////////////////////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3323,usability,input,input,3323,"///////////////. @@ -839,6 +841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEn",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3351,usability,input,input,3351,"841,7 @@ Long64_t TEntryList::GetEntryAndTree(Int_t index, Int_t &treenum). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which shou",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3422,usability,input,input,3422,"um). //Then, when GetEntryAndTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entr",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3450,usability,input,input,3450,"dTree(21, treenum, kTRUE) is called, first entry of the. //third sublist will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but in",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3518,usability,input,input,3518,"list will be returned. . + std::cout << ""Got input index: "" << index << ""\n"";. ```. ```. --- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3608,usability,statu,status,3608,"-- a/tree/treeplayer/src/TTreeReader.cxx. +++ b/tree/treeplayer/src/TTreeReader.cxx. @@ -18,6 +18,7 @@. #include ""TTreeReaderValue.h"". #include ""TFriendProxy.h"". . +#include <iostream>. . // clang-format off. /**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3817,usability,input,input,3817,"/**. @@ -547,6 +548,7 @@ TTreeReader::EEntryStatus TTreeReader::SetEntryBase(Long64_t entry, Bool_t local. const Long64_t loadResult = treeToCallLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/roo",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:3961,usability,input,input,3961,"lLoadOn->LoadTree(entryAfterList);. fSetEntryBaseCallingLoadTree = kFALSE;. . + std::cout << ""With entryAfterList="" << entryAfterList <<"" got loadResult="" << loadResult << ""\n"";. ```. I get the following output. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: -2147483648. Got tree index -1 and entry index -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the ",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:5007,usability,statu,status,5007,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:5289,usability,stop,stop,5289,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/issues/11026:5344,usability,behavi,behavior,5344,"dex -1. Got input index: -2147483648. With entryAfterList=1616 got loadResult=1616. What is the entry status? not kEntryBeyondEnd. ```. ## Things to notice. The total number of entries in the chain/tentrylist is larget than `std::numeric_limits<int>::max()`. With the first call to `GetEntryAndTree`, I give as input exactly the int limit, and the output is correct (index of the tree = 100, index of the entry in that tree = 47). With the next call, the input is the int limit + 1, from which one would expect the same tree and just one entry beyond the previous one, i.e. 48. Instead the result is tree index = -1 and entry index = -1. This is a bug resulting from a wrong signature in `TEntryList::GetEntryAndTree`:. https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/tree/src/TEntryList.cxx#L831. Which should accept a `Long64_t` like all other places in the class where an entry number is expected, but instead takes an `Int_t`. This results in a further bug in TTreeReader, that calls this method at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L532. When the wrong entry index / tree index is returned, the consecutive call to [`treeToCallLoadOn->LoadTree(entryAfterList)`](https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L547) will give result `-2`, like shown in the output above. This will then set the entry status to `kEntryBeyondEnd` at https://github.com/root-project/root/blob/8323e504ae187954dcb9bcdfd5df2f9a5ed2abca/tree/treeplayer/src/TTreeReader.cxx#L571-L580 . Practically, the TTreeReader thinks there are no more entries to process. This means that e.g. an RDataFrame would also stop processing entries after this value. ### Expected behavior. The TEntryList is able to give the correct tree and entry index even after `std::numeric_limits<int>::max()`. ### Setup. ROOT master. GCC 12. Fedora 36.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11026
https://github.com/root-project/root/pull/11027:56,availability,state,state,56,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:86,deployability,continu,continues,86,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:439,deployability,scale,scale,439,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:686,deployability,fail,fails,686,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:48,energy efficiency,Current,Current,48,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:439,energy efficiency,scale,scale,439,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:56,integrability,state,state,56,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:120,integrability,inject,injects,120,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:492,integrability,pub,public,492,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:540,integrability,pub,public,540,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:439,modifiability,scal,scale,439,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:439,performance,scale,scale,439,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:430,reliability,doe,does,430,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:686,reliability,fail,fails,686,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:819,safety,test,tested,819,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:120,security,inject,injects,120,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:176,security,ident,identifiers,176,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:260,security,ident,identifiers,260,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:344,security,auth,authoritative,344,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:499,security,ident,identifier,499,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11027:819,testability,test,tested,819,"[TCling] C++-use string,vector instead of std.; Current state:. - the normalized name continues to remove `std::`. - it injects using declarations for the ""most common"" stdlib identifiers. - this PR adds `std::` where ""needed"", to the normalized name, to make identifiers ""compilable"" (in dictionary source). The last point requires to have an authoritative list of ""things in the std namespace"", to prepend `std::` to them. This does not scale - any stdlib implementation might have any non-public identifier that might be needed also for public types, e.g. some libstdc++ have `std::thread::id` as type alias to `std::__thread_id`. Alternatively, this PR could implement a ""if lookup fails, try again with prepending `std::`"". This is an issue for types such as `foo<bar, baz<boo,boz>>` where either any type must be tested for std-ization separately or all possible permutations (`std::foo<bar, baz<boo,boz>>`, `foo<std::bar, baz<boo,boz>>`,`std::foo<std::bar, baz<boo,boz>>`...) must be tried.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11027
https://github.com/root-project/root/pull/11028:817,energy efficiency,load,loadResult,817,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:817,performance,load,loadResult,817,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:562,safety,input,input,562,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:590,safety,input,input,590,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:661,safety,input,input,661,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:689,safety,input,input,689,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:757,safety,input,input,757,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:50,security,sign,signature,50,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:562,usability,input,input,562,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:590,usability,input,input,590,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:661,usability,input,input,661,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:689,usability,input,input,689,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:757,usability,input,input,757,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11028:850,usability,statu,status,850,"[tree] Fix integer overflow in TEntryList; Change signature of methods in TEntryList and derived class that expect. an entry index. Usually this is stored as Long64_t, but in `GetEntry`. and `GetEntryAndTree` methods this was passed as `Int_t` leading to. integer overflows. Fixes https://github.com/root-project/root/issues/11026. With respect to the reproducer in the linked issue, this PR outputs the following. ```. $: ./repro.o. std::numeric_limits<int>::max(): 2147483647. Total entries in chain: 2168958436. Total entries in entrylist: 2168958436. Giving input entry 2147483647. Got input index: 2147483647. Got tree index 100 and entry index 47. Giving input entry 2147483648. Got input index: 2147483648. Got tree index 100 and entry index 48. Got input index: 2147483648. With entryAfterList=2147483648 got loadResult=48. What is the entry status? not kEntryBeyondEnd. ```",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11028
https://github.com/root-project/root/pull/11029:46,availability,avail,available,46,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:191,deployability,releas,release,191,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:46,reliability,availab,available,46,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:7,safety,test,test,7,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:46,safety,avail,available,46,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:46,security,availab,available,46,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/pull/11029:7,testability,test,test,7,"[cmake,test] Get rid of `lsb_release`:; It is available less and less often, and we do not actually. benefit a lot from printing the distro (stress) or we can get. the same info from /etc/os-release (cmake).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11029
https://github.com/root-project/root/issues/11031:401,energy efficiency,current,currently,401,"Port `Perp` functionality from `TVector3` into `XYZVector`; [`XYZVector`](https://root.cern.ch/doc/master/namespaceROOT_1_1Math.html#a91b80e54b44a65c90d60e5c8ff128746), while supposedly a replacement for `TVector3`, lacks some convenience functions, such as [`Perp(constTVector3& p)`](https://root.cern.ch/doc/master/classTVector3.html#aa71fadf626953be6e60b64edbae7eed0). [`DisplacementVector3D`]() currently only supports [`Perp2()`](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1DisplacementVector3D.html#adc7198c159c00240ac59b5d47f0b5a24), which does not give the perpendicular distance to an arbitrary vector, the way `Perp(constTVector3& p)` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11031
https://github.com/root-project/root/issues/11031:558,reliability,doe,does,558,"Port `Perp` functionality from `TVector3` into `XYZVector`; [`XYZVector`](https://root.cern.ch/doc/master/namespaceROOT_1_1Math.html#a91b80e54b44a65c90d60e5c8ff128746), while supposedly a replacement for `TVector3`, lacks some convenience functions, such as [`Perp(constTVector3& p)`](https://root.cern.ch/doc/master/classTVector3.html#aa71fadf626953be6e60b64edbae7eed0). [`DisplacementVector3D`]() currently only supports [`Perp2()`](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1DisplacementVector3D.html#adc7198c159c00240ac59b5d47f0b5a24), which does not give the perpendicular distance to an arbitrary vector, the way `Perp(constTVector3& p)` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11031
https://github.com/root-project/root/issues/11031:658,reliability,doe,does,658,"Port `Perp` functionality from `TVector3` into `XYZVector`; [`XYZVector`](https://root.cern.ch/doc/master/namespaceROOT_1_1Math.html#a91b80e54b44a65c90d60e5c8ff128746), while supposedly a replacement for `TVector3`, lacks some convenience functions, such as [`Perp(constTVector3& p)`](https://root.cern.ch/doc/master/classTVector3.html#aa71fadf626953be6e60b64edbae7eed0). [`DisplacementVector3D`]() currently only supports [`Perp2()`](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1DisplacementVector3D.html#adc7198c159c00240ac59b5d47f0b5a24), which does not give the perpendicular distance to an arbitrary vector, the way `Perp(constTVector3& p)` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11031
https://github.com/root-project/root/issues/11031:416,usability,support,supports,416,"Port `Perp` functionality from `TVector3` into `XYZVector`; [`XYZVector`](https://root.cern.ch/doc/master/namespaceROOT_1_1Math.html#a91b80e54b44a65c90d60e5c8ff128746), while supposedly a replacement for `TVector3`, lacks some convenience functions, such as [`Perp(constTVector3& p)`](https://root.cern.ch/doc/master/classTVector3.html#aa71fadf626953be6e60b64edbae7eed0). [`DisplacementVector3D`]() currently only supports [`Perp2()`](https://root.cern.ch/doc/master/classROOT_1_1Math_1_1DisplacementVector3D.html#adc7198c159c00240ac59b5d47f0b5a24), which does not give the perpendicular distance to an arbitrary vector, the way `Perp(constTVector3& p)` does.",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/issues/11031
https://github.com/root-project/root/pull/11033:30,availability,Operat,Operator,30,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:126,availability,Operat,Operator,126,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:250,deployability,updat,updated,250,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:79,safety,test,tests,79,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:163,safety,test,tests,163,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:172,safety,valid,validate,172,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:220,safety,test,tested,220,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:250,safety,updat,updated,250,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:172,security,validat,validate,172,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:250,security,updat,updated,250,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:74,testability,unit,unit,74,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:79,testability,test,tests,79,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:158,testability,Unit,Unit,158,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:163,testability,test,tests,163,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11033:220,testability,test,tested,220,[GSOC][TMVA][SOFIE] Cast ONNX Operator implemented with the corresponding unit tests; # This Pull request: Adds the Cast ONNX Operator with the corresponding Unit tests to validate the written code. ## Checklist:. - [ ] tested changes locally. - [ ] updated the docs (if necessary).,MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11033
https://github.com/root-project/root/pull/11037:498,deployability,updat,updated,498,"[cling-cpt] Got rid of 4 global variables and put them into fetch and compile functions [skip-ci]; # This Pull request: Reduces global variable mutation, making it easier to debug. ## Changes or fixes: Got rid of LLVM_GIT_URL, CLANG_GIT_URL, and CLING_GIT_URL and put them in their respective functions. I then got rid of the EXTRA_CMAKE_FLAGS variable and put it in the compile functions and replaced its global reference with the direct value. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in meta-issue list (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037
https://github.com/root-project/root/pull/11037:120,energy efficiency,Reduc,Reduces,120,"[cling-cpt] Got rid of 4 global variables and put them into fetch and compile functions [skip-ci]; # This Pull request: Reduces global variable mutation, making it easier to debug. ## Changes or fixes: Got rid of LLVM_GIT_URL, CLANG_GIT_URL, and CLING_GIT_URL and put them in their respective functions. I then got rid of the EXTRA_CMAKE_FLAGS variable and put it in the compile functions and replaced its global reference with the direct value. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in meta-issue list (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037
https://github.com/root-project/root/pull/11037:32,modifiability,variab,variables,32,"[cling-cpt] Got rid of 4 global variables and put them into fetch and compile functions [skip-ci]; # This Pull request: Reduces global variable mutation, making it easier to debug. ## Changes or fixes: Got rid of LLVM_GIT_URL, CLANG_GIT_URL, and CLING_GIT_URL and put them in their respective functions. I then got rid of the EXTRA_CMAKE_FLAGS variable and put it in the compile functions and replaced its global reference with the direct value. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in meta-issue list (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037
https://github.com/root-project/root/pull/11037:135,modifiability,variab,variable,135,"[cling-cpt] Got rid of 4 global variables and put them into fetch and compile functions [skip-ci]; # This Pull request: Reduces global variable mutation, making it easier to debug. ## Changes or fixes: Got rid of LLVM_GIT_URL, CLANG_GIT_URL, and CLING_GIT_URL and put them in their respective functions. I then got rid of the EXTRA_CMAKE_FLAGS variable and put it in the compile functions and replaced its global reference with the direct value. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in meta-issue list (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037
https://github.com/root-project/root/pull/11037:344,modifiability,variab,variable,344,"[cling-cpt] Got rid of 4 global variables and put them into fetch and compile functions [skip-ci]; # This Pull request: Reduces global variable mutation, making it easier to debug. ## Changes or fixes: Got rid of LLVM_GIT_URL, CLANG_GIT_URL, and CLING_GIT_URL and put them in their respective functions. I then got rid of the EXTRA_CMAKE_FLAGS variable and put it in the compile functions and replaced its global reference with the direct value. ## Checklist:. - [X] tested changes locally. - [NA] updated the docs (if necessary). This PR fixes #406 mentioned in meta-issue list (https://github.com/root-project/cling/issues/406).",MatchSource.ISSUE,root-project,root,v6-32-06,https://root.cern,https://github.com/root-project/root/pull/11037
