id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2969:140,deployability,pipelin,pipeline,140,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:140,integrability,pipelin,pipeline,140,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:149,performance,error,errors,149,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:149,safety,error,errors,149,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:103,security,hack,hack,103,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:149,usability,error,errors,149,"@RubenVanEsch Yes, and the issue there is that we're not the ones calling `randint`. We may be able to hack it. I'll have a look at how the pipeline errors out on our CI to maybe see where the call is coming from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:95,deployability,upgrad,upgrade,95,"If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:95,modifiability,upgrad,upgrade,95,"If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,availability,error,errors,65,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:161,deployability,build,buildId,161,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:179,deployability,log,logs,179,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,performance,error,errors,65,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:481,reliability,doe,doesn,481,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:10,safety,test,test,10,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,safety,error,errors,65,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:179,safety,log,logs,179,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:280,safety,test,test,280,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:403,safety,test,tests,403,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:469,safety,test,test,469,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:627,safety,test,test,627,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:638,safety,test,test,638,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:179,security,log,logs,179,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:10,testability,test,test,10,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:179,testability,log,logs,179,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:280,testability,test,test,280,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:403,testability,test,tests,403,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:469,testability,test,test,469,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:627,testability,test,test,627,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:638,testability,test,test,638,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,usability,error,errors,65,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:324,usability,minim,minimal,324,"I got the test runner to do windows and while there were _other_ errors, this one was seemingly not present: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6287&view=logs&j=4eb20215-89fc-58e4-6218-2c2fa88ddf72&t=482e4b16-75d9-5f8c-9594-aadcd098d2cb&l=3977. We have a test that is strikingly similar to the more minimal example from above: https://github.com/scverse/scanpy/blob/main/scanpy/tests/notebooks/test_pbmc3k.py minus the umap. Could you try this test (which doesn't call `umap`) and also try it with `umap` so it's exactly as our little demo and let us know what you get? We also set `resolution` in the test. This test seems to actually pass on our CI. In general there will be some back and forth here until we find someone near us with a windows machine since using CI to fix this problem isn't really feasible, but at least we can narrow the scope.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:54,reliability,doe,does,54,"@RubenVanEsch, are you able to run this in WSL? Also, does the number you pass for random seed matter?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:98,availability,state,state,98,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:168,availability,state,states,168,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:98,integrability,state,state,98,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:168,integrability,state,states,168,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:8,reliability,doe,does,8,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:104,reliability,doe,does,104,"> Also, does the number you pass for random seed matter? From @RubenVanEsch :. > EDIT: the random state does not seem to matter btw, also happens with different random states",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:64,deployability,instal,install,64,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:146,deployability,instal,installing,146,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:221,safety,test,tester,221,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:221,testability,test,tester,221,"@ivirshup @ilan-gold just got back to this, thought i could not install wsl as I am on a somewhat company restricted laptop, but turns out i can. installing it now (and probably using that from here on out). will run the tester in a bit and let you know",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:350,deployability,releas,release,350,"> ```python. > import scanpy as sc. > . > em_adata = sc.datasets.pbmc3k(). > . > sc.pp.pca(em_adata, n_comps=50). > sc.pp.neighbors(em_adata). > sc.tl.umap(em_adata). > sc.tl.leiden(em_adata,flavor='igraph',n_iterations=2,random_state=1653,directed=False). > ```. @melonora, would you mind running this on your windows machine with the latest scanpy release to see if you can reproduce it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:29,availability,error,error,29,"I can reproduce, this is the error that I get:. ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:29,performance,error,error,29,"I can reproduce, this is the error that I get:. ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:29,safety,error,error,29,"I can reproduce, this is the error that I get:. ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:29,usability,error,error,29,"I can reproduce, this is the error that I get:. ![afbeelding](https://github.com/scverse/scanpy/assets/22346363/2ea5b86b-31f8-42ba-a2f7-c536168222a7). From a first glance it seems like the default for randint is used which is `int32`. I can check whether switching to `int64` fixes the issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:45,safety,test,test,45,Do you guys still want me to try and run the test from @ilan-gold ? Or is it fine now that it is reproduced on your side as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:45,testability,test,test,45,Do you guys still want me to try and run the test from @ilan-gold ? Or is it fine now that it is reproduced on your side as well?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:359,availability,cluster,clustering,359,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:285,deployability,fail,fails,285,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:329,deployability,manag,manager,329,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:359,deployability,cluster,clustering,359,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:329,energy efficiency,manag,manager,329,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:340,performance,perform,perform,340,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:285,reliability,fail,fails,285,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:329,safety,manag,manager,329,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:321,testability,context,context,321,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:340,usability,perform,perform,340,It is reproduced. It is due to the `randint` producing a value outside the range of the default dtype `int32`. On windows 64 bit systems the default is `int32` despite the system being 64 bit. This is due to default for c long being `int32` on these systems. The part of the code that fails due to this is when using the context manager to perform the leiden clustering with igraph flavor.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:129,usability,tool,tools,129,"In particular here is the piece of code:. https://github.com/scverse/scanpy/blob/a33111f3b2caaa4ee5e33d02b6e98b143023341b/scanpy/tools/_leiden.py#L184-L185. Though the `randint` is called from within c code within `igraph` itself. @ivirshup, do you think asking for calling with dtype `int64` would be a problem until this part is fixed on the numpy side?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:15,safety,test,test,15,"Since we can’t test this without your help, could you check if passing your own RNG here makes it work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:15,testability,test,test,15,"Since we can’t test this without your help, could you check if passing your own RNG here makes it work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:38,usability,help,help,38,"Since we can’t test this without your help, could you check if passing your own RNG here makes it work?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:6,safety,test,test,6,I can test tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:6,testability,test,test,6,I can test tomorrow,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:116,safety,test,test,116,"I can reproduce this bug on my machine as well. I can supply additional information or context if needed, and I can test fixes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:87,testability,context,context,87,"I can reproduce this bug on my machine as well. I can supply additional information or context if needed, and I can test fixes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:116,testability,test,test,116,"I can reproduce this bug on my machine as well. I can supply additional information or context if needed, and I can test fixes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:253,availability,error,error,253,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:99,deployability,upgrad,upgrade,99,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:99,modifiability,upgrad,upgrade,99,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:253,performance,error,error,253,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:253,safety,error,error,253,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:253,usability,error,error,253,". > If the problem is windows, it's possible it will be solved by numpy 2.0. Not sure how easy the upgrade path to numpy 2.0 will be, however. > . > * https://numpy.org/devdocs/numpy_2_0_migration_guide.html#windows-default-integer. I can reproduce the error using Numpy 2.0.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,safety,test,test,65,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:112,safety,prevent,prevents,112,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:112,security,preven,prevents,112,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:65,testability,test,test,65,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:87,usability,confirm,confirm,87,@patrick-nicodemus What we need more than anything is someone to test out a fix and to confirm that using `wsl` prevents the problem. See https://github.com/scverse/scanpy/pull/3041. The issue is that we don't have windows machines.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:83,availability,error,error,83,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:103,deployability,contain,container,103,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:430,deployability,instal,installing,430,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:499,deployability,instal,installing,499,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:568,integrability,sub,suboptimal,568,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:419,interoperability,coordinat,coordinate,419,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:83,performance,error,error,83,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:391,performance,overhead,overhead,391,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:83,safety,error,error,83,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:83,usability,error,error,83,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:262,usability,user,users,262,"@ilan-gold If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. I also have tried it on WSL, and the problem is *not* present on WSL, so this is a workaround for Windows users. However, I am organizing a Python workshop in a few weeks, and I think it would add some additional administrative burden/overhead to the workshop to coordinate installing and setting up WSL (as we see in #3041, Ruben had trouble installing WSL and others might as well.) So, for me, using WSL is a suboptimal workaround.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:74,availability,error,error,74,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:94,deployability,contain,container,94,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:74,performance,error,error,74,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:74,safety,error,error,74,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:74,usability,error,error,74,"> If you want to try it out, I give instructions for how to reproduce the error with a Docker container for Windows in the cross-referenced issue. Yes please. I’m confused how Windows comes into play though since I thougt that Docker always runs on a Linux kernel – natively on Linux and in a VM on macOS and Windows.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:111,availability,avail,available,111,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:369,availability,error,error,369,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:90,deployability,contain,containers,90,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:389,deployability,contain,container,389,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:995,integrability,Messag,Message,995,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:995,interoperability,Messag,Message,995,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:369,performance,error,error,369,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:111,reliability,availab,available,111,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:111,safety,avail,available,111,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:369,safety,error,error,369,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:111,security,availab,available,111,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:825,security,auth,auth,825,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:52,usability,document,documented,52,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:369,usability,error,error,369,"Yes, this was my impression too. However there is a documented option. ""Switch to Windows containers"" which is available if you right click on the. Docker icon in the taskbar and this allows one to run vms using a Windows. kernel. On Fri, Sep 6, 2024, 3:36 AM Philipp A. ***@***.***> wrote:. > If you want to try it out, I give instructions for how to reproduce the. > error with a Docker container for Windows in the cross-referenced issue. >. > Yes please. I’m confused how Windows comes into play though since I thougt. > that Docker always runs on a Linux kernel – natively on Linux and in a VM. > on macOS and Windows. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/scverse/scanpy/issues/2969#issuecomment-2333436219>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AH2OS47KNFAVTYUHGAMORILZVFLRXAVCNFSM6AAAAABFM3NQROVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMZDGMZTGQZTMMRRHE>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:123,integrability,sub,subclassing,123,"Adding a link here for a comment I made in the ``igraph`` issue with a possible work-around for those interested. Required subclassing ``RandomState`` and editing the ``randint`` method which is ugly, but got it working. I've left more details there which may or may not be helpful. https://github.com/igraph/python-igraph/issues/796#issuecomment-2408716328.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/issues/2969:274,usability,help,helpful,274,"Adding a link here for a comment I made in the ``igraph`` issue with a possible work-around for those interested. Required subclassing ``RandomState`` and editing the ``randint`` method which is ugly, but got it working. I've left more details there which may or may not be helpful. https://github.com/igraph/python-igraph/issues/796#issuecomment-2408716328.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2969
https://github.com/scverse/scanpy/pull/2972:3,deployability,releas,release,3,"No release notes are needed, but milestones are needed for this to get back-ported. Also the check for the release notes is actually checking the box in the PR template.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972
https://github.com/scverse/scanpy/pull/2972:107,deployability,releas,release,107,"No release notes are needed, but milestones are needed for this to get back-ported. Also the check for the release notes is actually checking the box in the PR template.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2972
https://github.com/scverse/scanpy/issues/2973:359,availability,down,download,359,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:372,availability,cluster,cluster,372,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:472,availability,cluster,clusters,472,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:372,deployability,cluster,cluster,372,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:472,deployability,cluster,clusters,472,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:459,security,ident,identify,459,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:494,usability,help,helps,494,"Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. . Hope this helps 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:516,deployability,depend,dependencies,516,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:298,integrability,wrap,wrapper,298,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:516,integrability,depend,dependencies,516,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:8,interoperability,format,format,8,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:50,interoperability,specif,specific,50,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:298,interoperability,wrapper,wrapper,298,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:516,modifiability,depend,dependencies,516,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:516,safety,depend,dependencies,516,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:86,security,sign,significant,86,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:410,security,access,accessing,410,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:481,security,sign,significant,481,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:516,testability,depend,dependencies,516,"Has the format changed for all assays, or is this specific to visium HD? And is there significant analysis that can be done on these without taking into account extra spatial information? I would be inclined to say that the visium IO functions in scanpy should be deprecated/ replaced with a light wrapper around: `spatialdata_io.experimental.to_legacy_anndata(spatialdata_io.visium(*args, **kwargs))` or just accessing the AnnData from `spatialdata_io.visium_hd`. But if there is significant burden involved in the dependencies of `spatialdata`, then maybe we could implement something lighter here for now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:197,energy efficiency,current,currently,197,"> Has the format changed for all assays, or is this specific to visium HD? Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:10,interoperability,format,format,10,"> Has the format changed for all assays, or is this specific to visium HD? Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:52,interoperability,specif,specific,52,"> Has the format changed for all assays, or is this specific to visium HD? Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:267,security,access,accessing,267,"> Has the format changed for all assays, or is this specific to visium HD? Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:95,usability,support,support,95,"> Has the format changed for all assays, or is this specific to visium HD? Do you refer to the support for multiple annotation tables or also to other parts of the specs? Visium HD and MCMICRO are currently the only technologies making use of multiple tables. > just accessing the AnnData from spatialdata_io.visium_hd. I would favor this approach. I would call `to_legacy_anndata()` only if it is essential to have the spatial information is obsm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:372,availability,down,download,372,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:385,availability,cluster,cluster,385,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:485,availability,cluster,clusters,485,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:385,deployability,cluster,cluster,385,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:485,deployability,cluster,clusters,485,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:472,security,ident,identify,472,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:511,usability,help,helps,511,"> Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > . > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > . > Hope this helps 😊. Hi, the link seems to be invalid. Is there any alternative links?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:372,availability,down,download,372,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:385,availability,cluster,cluster,385,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:485,availability,cluster,clusters,485,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:385,deployability,cluster,cluster,385,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:485,deployability,cluster,clusters,485,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:472,security,ident,identify,472,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:509,usability,help,helps,509,"> > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > Hope this helps 😊. > . > Hi, the link seems to be invalid. Is there any alternative links? Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:376,availability,down,download,376,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:389,availability,cluster,cluster,389,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:489,availability,cluster,clusters,489,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:389,deployability,cluster,cluster,389,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:489,deployability,cluster,clusters,489,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:476,security,ident,identify,476,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:515,usability,help,helps,515,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:756,usability,help,help,756,"> > > Hi, we implemented a reader for Visium HD data in `spatialdata-io`; an example notebook showing its usage can be found here: https://github.com/scverse/spatialdata-notebooks/blob/visium_hd/notebooks/examples/technology_visium_hd.ipynb. > > > You can use `scanpy` directly on the `AnnData` objects that are parsed. For instance, in the last part of the notebook where we download the cluster information, you could instead use `scanpy` to preprocess/qc the data and then identify the clusters. > > > Hope this helps 😊. > > . > > . > > Hi, the link seems to be invalid. Is there any alternative links? > . > Would you please try this link? https://github.com/scverse/spatialdata-notebooks/blob/main/notebooks/examples/technology_visium_hd.ipynb. Great help. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:6,energy efficiency,load,load,6,Can I load it if it's not in `zarr` format.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:36,interoperability,format,format,36,Can I load it if it's not in `zarr` format.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:6,performance,load,load,6,Can I load it if it's not in `zarr` format.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:59,energy efficiency,load,loads,59,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:98,interoperability,format,format,98,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:121,interoperability,format,format,121,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:334,interoperability,format,format,334,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:202,modifiability,extens,extensions,202,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:649,modifiability,pac,package,649,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:59,performance,load,loads,59,"Not only yes, but actually `spatialdata_io.visium_hd` only loads data that is **not** in the Zarr format, but the native format from SpaceRanger 3.x (which includes some Zarr files, but many other file extensions). The `SpatialData` object returned by `spatialdata_io.visium_hd` can then be saved to `.zarr` following the SpatialData format (described in this [design doc](https://github.com/scverse/spatialdata/blob/main/docs/design_doc.md) and [this page](https://github.com/scverse/spatialdata-notebooks/tree/main/notebooks/developers_resources/storage_format)), and read again using `spatialdata.read_zarr` (so, no need for the `spatialdata_io` package anymore). I hope this answers your question 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:101,availability,error,error,101,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1317,availability,sli,slice,1317,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1485,availability,sli,slice,1485,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1515,availability,Down,Downloads,1515,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:225,interoperability,format,format,225,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:487,modifiability,pac,packages,487,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1013,modifiability,pac,packages,1013,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:101,performance,error,error,101,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1317,reliability,sli,slice,1317,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1485,reliability,sli,slice,1485,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:101,safety,error,error,101,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:187,security,ident,identifiers,187,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:323,testability,Trace,Traceback,323,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:101,usability,error,error,101,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/issues/2973:1500,usability,User,Users,1500,"Hi I cannot seem to read in my visium HD raw data with the spatialdata-io. Heres what I used and the error I keep receiving. I have tried setting dataset_id to none, """" and some possible identifiers. . I have a non zarr data format. . ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[54], line 1. ----> 1 sdata = visium_hd(path_read). File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:95, in visium_hd(path, dataset_id, filtered_counts_file, bin_size, bins_as_squares, fullres_image_file, load_all_images, imread_kwargs, image_models_kwargs, anndata_kwargs). 92 images: dict[str, Any] = {}. 94 if dataset_id is None:. ---> 95 dataset_id = _infer_dataset_id(path). 96 filename_prefix = f""{dataset_id}_"". 98 def load_image(path: Path, suffix: str, scale_factors: list[int] | None = None) -> None:. File /Volumes/Ankitha/Conda/miniconda3/envs/myenv/lib/python3.12/site-packages/spatialdata_io/readers/visium_hd.py:361, in _infer_dataset_id(path). 359 files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and f.endswith(suffix)]. 360 if len(files) == 0 or len(files) > 1:. --> 361 raise ValueError(. 362 f""Cannot infer `dataset_id` from the feature slice file in {path}, please pass `dataset_id` as an argument."". 363 ). 364 return files[0].replace(suffix, """"). ValueError: Cannot infer `dataset_id` from the feature slice file in /Users/DarthRNA/Downloads/1299_1_XS_VHD_v2_outs, please pass `dataset_id` as an argument.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2973
https://github.com/scverse/scanpy/pull/2976:19,security,triag,triage,19,"From discussion at triage/ sprint planning:. * We're not sure we want to support windows that much. * We'll leave this untouched for now, and probably won't merge until we also have an official stance on support level for windows",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976
https://github.com/scverse/scanpy/pull/2976:34,testability,plan,planning,34,"From discussion at triage/ sprint planning:. * We're not sure we want to support windows that much. * We'll leave this untouched for now, and probably won't merge until we also have an official stance on support level for windows",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976
https://github.com/scverse/scanpy/pull/2976:73,usability,support,support,73,"From discussion at triage/ sprint planning:. * We're not sure we want to support windows that much. * We'll leave this untouched for now, and probably won't merge until we also have an official stance on support level for windows",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976
https://github.com/scverse/scanpy/pull/2976:204,usability,support,support,204,"From discussion at triage/ sprint planning:. * We're not sure we want to support windows that much. * We'll leave this untouched for now, and probably won't merge until we also have an official stance on support level for windows",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2976
https://github.com/scverse/scanpy/issues/2978:86,deployability,version,versioning,86,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:86,integrability,version,versioning,86,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:86,modifiability,version,versioning,86,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:5,reliability,doe,does,5,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:69,testability,understand,understanding,69,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:149,usability,help,help,149,"This does not happen with e.g. `anndata==0.8.0`. I don't have a good understanding of versioning systems in Python, so apologies I cannot be of more help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:57,availability,reboot,reboot,57,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:89,availability,error,error,89,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:30,deployability,instal,install,30,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:89,performance,error,error,89,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:89,safety,error,error,89,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:89,usability,error,error,89,"I might also have a corrupted install of anndata, let me reboot my system and see if the error persists.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:133,deployability,version,version,133,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python. from importlib.metadata import version as v. v(""anndata""). ```. and. ```python. import anndata. anndata.__version__. ```. ? Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:300,deployability,instal,install,300,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python. from importlib.metadata import version as v. v(""anndata""). ```. and. ```python. import anndata. anndata.__version__. ```. ? Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:133,integrability,version,version,133,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python. from importlib.metadata import version as v. v(""anndata""). ```. and. ```python. import anndata. anndata.__version__. ```. ? Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:68,interoperability,share,share,68,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python. from importlib.metadata import version as v. v(""anndata""). ```. and. ```python. import anndata. anndata.__version__. ```. ? Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:133,modifiability,version,version,133,"Huh, I can't reproduce but can look into this a bit more. Could you share the results of:. ```python. from importlib.metadata import version as v. v(""anndata""). ```. and. ```python. import anndata. anndata.__version__. ```. ? Also, anything extra you can tell us about your environment? E.g. did you install with pip or conda? `uv`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:36,deployability,version,version,36,"```. from importlib.metadata import version as v. v(""anndata""). ```. returns Python `None`. ```anndata.__version__```. returns `'0.10.6'`. I had `anndata==0.8.0` in my conda environment, and then I did `pip install anndata -U` to get `0.10.6`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:207,deployability,instal,install,207,"```. from importlib.metadata import version as v. v(""anndata""). ```. returns Python `None`. ```anndata.__version__```. returns `'0.10.6'`. I had `anndata==0.8.0` in my conda environment, and then I did `pip install anndata -U` to get `0.10.6`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:36,integrability,version,version,36,"```. from importlib.metadata import version as v. v(""anndata""). ```. returns Python `None`. ```anndata.__version__```. returns `'0.10.6'`. I had `anndata==0.8.0` in my conda environment, and then I did `pip install anndata -U` to get `0.10.6`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:36,modifiability,version,version,36,"```. from importlib.metadata import version as v. v(""anndata""). ```. returns Python `None`. ```anndata.__version__```. returns `'0.10.6'`. I had `anndata==0.8.0` in my conda environment, and then I did `pip install anndata -U` to get `0.10.6`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:144,modifiability,pac,packages,144,"I'll close the issue for now, if it's not reproducible on your machine. It might be that I have a complicated conda env with `rapids` and other packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:98,safety,compl,complicated,98,"I'll close the issue for now, if it's not reproducible on your machine. It might be that I have a complicated conda env with `rapids` and other packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:98,security,compl,complicated,98,"I'll close the issue for now, if it's not reproducible on your machine. It might be that I have a complicated conda env with `rapids` and other packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:5,usability,close,close,5,"I'll close the issue for now, if it's not reproducible on your machine. It might be that I have a complicated conda env with `rapids` and other packages",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:109,availability,sli,slightly,109,"Ah, no, it's fine. It's good to know if this happens for people. It would be good if our code still works in slightly wonky environments, and I've definitely had environments where versions can be reported incorrectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:181,deployability,version,versions,181,"Ah, no, it's fine. It's good to know if this happens for people. It would be good if our code still works in slightly wonky environments, and I've definitely had environments where versions can be reported incorrectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:181,integrability,version,versions,181,"Ah, no, it's fine. It's good to know if this happens for people. It would be good if our code still works in slightly wonky environments, and I've definitely had environments where versions can be reported incorrectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:181,modifiability,version,versions,181,"Ah, no, it's fine. It's good to know if this happens for people. It would be good if our code still works in slightly wonky environments, and I've definitely had environments where versions can be reported incorrectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:109,reliability,sli,slightly,109,"Ah, no, it's fine. It's good to know if this happens for people. It would be good if our code still works in slightly wonky environments, and I've definitely had environments where versions can be reported incorrectly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:14,deployability,instal,install,14,Was the first install also with `pip`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:20,deployability,contain,container,20,"I am using a Docker container, but from the settings it seems like the first `anndata` install was with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:87,deployability,instal,install,87,"I am using a Docker container, but from the settings it seems like the first `anndata` install was with conda.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:156,deployability,instal,installs,156,"Ah, yeah that can cause problems. I'm actually a little surprised you've gotten as far as ingest, so maybe the situation has improved. Do you have multiple installs of anndata if you `conda list | grep anndata`?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:306,availability,error,errors,306,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:33,deployability,contain,container,33,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:163,deployability,instal,install,163,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:181,deployability,upgrad,upgrade,181,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:181,modifiability,upgrad,upgrade,181,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:306,performance,error,errors,306,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:306,safety,error,errors,306,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:306,usability,error,errors,306,"Right after booting up my Docker container, this is the result of `conda list | grep anndata`:. `anndata 0.8.0 pyhd8ed1ab_1 conda-forge`. Then, after running `pip install anndata --upgrade`, and then again `conda list | grep anndata`:. `anndata 0.10.6 pypi_0 pypi`. At this point, `pkg_version('anndata')` errors out as described.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:983,availability,Down,Downloading,983,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1055,availability,Down,Downloading,1055," on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this s",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1187,availability,Down,Downloading,1187,"create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:80,deployability,instal,install,80,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:730,deployability,Version,Version,730,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:824,deployability,instal,install,824,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1246,deployability,Instal,Installing,1246," ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is bro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1283,deployability,api,api-compat,1283,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1350,deployability,instal,installation,1350,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1461,deployability,instal,installed,1461,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1492,deployability,api,api-compat-,1492,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1994,deployability,Version,Version,1994,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:730,integrability,Version,Version,730,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1283,integrability,api,api-compat,1283,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1492,integrability,api,api-compat-,1492,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1994,integrability,Version,Version,1994,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1283,interoperability,api,api-compat,1283,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1492,interoperability,api,api-compat-,1492,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:427,modifiability,pac,packaged,427,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:730,modifiability,Version,Version,730,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:945,modifiability,pac,packages,945,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1267,modifiability,pac,packages,1267,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1700,modifiability,pac,packaged,1700,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1994,modifiability,Version,Version,1994,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:2228,modifiability,pac,package,2228,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:203,safety,test,test-,203,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:313,safety,test,test-,313,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:326,safety,test,test-,326,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:766,safety,test,test-,766,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:915,safety,test,test-,915,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1509,safety,test,test-,1509,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1619,safety,test,test-,1619,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:203,testability,test,test-,203,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:313,testability,test,test-,313,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:326,testability,test,test-,326,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:766,testability,test,test-,766,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:915,testability,test,test-,915,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1509,testability,test,test-,1509,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1619,testability,test,test-,1619,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:593,usability,Interact,Interactive,593,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:626,usability,help,help,626,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:887,usability,User,Users,887,"Interestingly, I can't seem to reproduce this even with `pip` on-top of a conda install:. <details>. <summary> me trying </summary>. ```python. isaac@Mimir:~/tmp/genomic-features-docs. $ mamba create -n test-2978 ""anndata==0.9.0"" ipython scanpy. [ ... ]. isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1866,usability,Interact,Interactive,1866,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:1899,usability,help,help,1899,"isaac@Mimir:~/tmp/genomic-features-docs. $ conda activate test-2978 . (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. from scanpy._compat imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. [ ... ]. In [3]: from scanpy._compat import pkg_version. In [4]: pkg_version(""anndata""). Out[4]: <Version('0.9.0')>. In [5]: quit(). (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ pip install -U anndata. Requirement already satisfied: anndata in /Users/isaac/miniforge3/envs/test-2978/lib/python3.12/site-packages (0.9.0). Collecting anndata. Downloading anndata-0.10.6-py3-none-any.whl.metadata (6.6 kB). [ ... ]. Downloading anndata-0.10.6-py3-none-any.whl (122 kB). ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 122.1/122.1 kB 2.1 MB/s eta 0:00:00. Downloading array_api_compat-1.6-py3-none-any.whl (36 kB). Installing collected packages: array-api-compat, anndata. Attempting uninstall: anndata. Found existing installation: anndata 0.9.0. Uninstalling anndata-0.9.0:. Successfully uninstalled anndata-0.9.0. Successfully installed anndata-0.10.6 array-api-compat-1.6. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ conda list | grep anndata. anndata 0.10.6 pypi_0 pypi. (test-2978) isaac@Mimir:~/tmp/genomic-features-docs. $ ipython. imPython 3.12.2 | packaged by conda-forge | (main, Feb 16 2024, 21:00:12) [Clang 16.0.6 ]. Type 'copyright', 'credits' or 'license' for more information. IPython 8.22.2 -- An enhanced Interactive Python. Type '?' for help. In [1]: from scanpy._compat import pkg_version. In [2]: pkg_version(""anndata""). Out[2]: <Version('0.10.6')>. ```. </details>. Interesting to see that this seems to work now! I do think the recommended solution here is ""don't do this"", but I'm considering just using `anndata.__version__` here since that will work when the package metadata is broken.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:0,safety,Compl,Completely,0,"Completely agree, thanks for looking into this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2978:0,security,Compl,Completely,0,"Completely agree, thanks for looking into this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2978
https://github.com/scverse/scanpy/issues/2981:34,availability,avail,available,34,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:98,deployability,instal,installed,98,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:123,deployability,upgrad,upgrading,123,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:123,modifiability,upgrad,upgrading,123,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:34,reliability,availab,available,34,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:34,safety,avail,available,34,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2981:34,security,availab,available,34,"Hi @hl324,. That argument is only available in scanpy 1.10, while you appear to have scanpy 1.9.8 installed. Could you try upgrading scanpy?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2981
https://github.com/scverse/scanpy/issues/2982:136,availability,error,errors,136,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:31,deployability,version,version,31,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:110,deployability,version,version,110,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:31,integrability,version,version,31,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:110,integrability,version,version,110,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:31,modifiability,version,version,31,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:110,modifiability,version,version,110,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:136,performance,error,errors,136,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:85,reliability,doe,doesn,85,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:136,safety,error,errors,136,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:136,usability,error,errors,136,"> Hello, I'd like to ask which version of scanpy you're using? The code you provided doesn't match the latest version, which is causing errors when I try to use it. Hi, I'm using 1.9.6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:39,availability,error,error,39,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:39,performance,error,error,39,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:39,safety,error,error,39,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:39,usability,error,error,39,"Thank you very much ,I've resolved the error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2982:31,deployability,releas,releases,31,Going to implemented in future releases,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2982
https://github.com/scverse/scanpy/issues/2986:44,usability,usab,usability,44,Would be a nice use case for working on the usability of benchmarks (related to #2977),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2986
https://github.com/scverse/scanpy/pull/2992:96,availability,redund,redundancy,96,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:495,availability,robust,robust,495,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:96,deployability,redundan,redundancy,96,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:249,deployability,loader,loader,249,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:88,energy efficiency,reduc,reduced,88,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:249,energy efficiency,load,loader,249,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:599,energy efficiency,current,currently,599,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:314,integrability,sub,subdirectory,314,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:249,performance,load,loader,249,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:96,reliability,redundan,redundancy,96,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:495,reliability,robust,robust,495,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:96,safety,redund,redundancy,96,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:259,safety,hot,hotfix,259,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:495,safety,robust,robust,495,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:214,testability,understand,understandably,214,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:369,usability,user,users,369,"We ran some data through spaceranger 3.0.1 locally, and in doing so found that 10X have reduced redundancy in the `spatial` folder of the binned outputs by moving the tissue images to a new, central location. This understandably breaks the existing loader. A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument `spaceranger_image_path` to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:282,availability,robust,robust,282,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:388,energy efficiency,current,currently,388,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:103,integrability,sub,subdirectory,103,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:282,reliability,robust,robust,282,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:48,safety,hot,hotfix,48,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:282,safety,robust,robust,282,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:620,safety,test,test,620,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:620,testability,test,test,620,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:158,usability,user,users,158,"hi @ktpolanski ,thank you for the heads up. > A hotfix is to copy the images back into the appropriate subdirectory, but that's not a feasible expectation on users. I added an optional argument spaceranger_image_path to point to the new folder if need be, which should hopefully be robust with regard to any sort of further restructuring 10X may choose to do in the future. > The code is currently included in [bin2cell](https://github.com/Teichlab/bin2cell) in case anybody needs it or just wants to take it out for a spin, but I think it belongs in a more central location. @LucaMarconato do we have any datasets that test for spaceranger 3.0.1 ? .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/pull/2992:34,security,ident,identified,34,Last week together with Wouter we identified some good candidate datasets (some of them recommended by 10x). I believe it's 3.0.0 not 3.0.1 though. The list is in the top part of my comment here https://github.com/scverse/spatialdata/issues/700#issuecomment-2326790050,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2992
https://github.com/scverse/scanpy/issues/2993:14,reliability,doe,does,14,"@flying-sheep does anndata need to have a pytest minimum bound of `8.1`? It seems to run fine for me with `8.0.2`, and scanpy is having problems with `8.1.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:49,usability,minim,minimum,49,"@flying-sheep does anndata need to have a pytest minimum bound of `8.1`? It seems to run fine for me with `8.0.2`, and scanpy is having problems with `8.1.1`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:26,deployability,instal,install,26,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:240,deployability,modul,modules,240,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:264,deployability,modul,modules,264,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:306,deployability,modul,module,306,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:846,deployability,contain,contain,846,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:943,deployability,modul,module,943,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:958,deployability,modul,modules,958,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:240,modifiability,modul,modules,240,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:264,modifiability,modul,modules,264,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:306,modifiability,modul,module,306,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:873,modifiability,pac,packages,873,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:943,modifiability,modul,module,943,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:958,modifiability,modul,modules,958,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:176,safety,test,testing,176,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:240,safety,modul,modules,240,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:264,safety,modul,modules,264,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:280,safety,test,testing,280,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:306,safety,modul,module,306,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:321,safety,test,testing,321,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:943,safety,modul,module,943,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:958,safety,modul,modules,958,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:974,safety,test,testing,974,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:176,testability,test,testing,176,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:280,testability,test,testing,280,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:321,testability,test,testing,321,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:974,testability,test,testing,974,"What happens is . 1. `pip install -e` adds the repo directory to `sys.path`, since we don‘t use a `src` directory. 2. something imports the `data` directory instead of `scanpy.testing._helpers.data` and stores it in the wrong place in `sys.modules`:. ```. >>> sys.modules[""scanpy.testing._helpers.data""]. <module 'scanpy.testing._helpers.data' (namespace) from ['/home/phil/Dev/Python/Single Cell/scanpy/data']>. ```. I assume that some of the attempts to fix our doctest woes in Pytest 8.1 led to this bug being introduced in Pytest 8.1. But I’d like to figure out what exactly causes that bug before we do anything. PS: Of course things like this are exactly why we switched anndata to a `src` layout: that way `src` can be in `sys.path` instead of a kitchen sink directory, and `import <something>` will only see directories that are meant to contain exclusively python packages. Pytest shouldn’t `import data` and then store the resulting module as `sys.modules['scanpy.testing._helpers.data']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:68,reliability,doe,doesn,68,"@flying-sheep do you want to use this issue to investigate why this doesn't work with pytest 8.1, or track that in a new issue for unpinning it? If you want to track it here, feel free to edit the title",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:176,deployability,modul,module,176,"Still no clue: https://github.com/pytest-dev/pytest/issues/12194#issuecomment-2045446960. I haven’t been able to create a minimal reproducer yet. The problem is that the wrong module gets returned by a `_frozen_importlib_external.PathFinder`, so basically a blackbox.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:176,modifiability,modul,module,176,"Still no clue: https://github.com/pytest-dev/pytest/issues/12194#issuecomment-2045446960. I haven’t been able to create a minimal reproducer yet. The problem is that the wrong module gets returned by a `_frozen_importlib_external.PathFinder`, so basically a blackbox.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:176,safety,modul,module,176,"Still no clue: https://github.com/pytest-dev/pytest/issues/12194#issuecomment-2045446960. I haven’t been able to create a minimal reproducer yet. The problem is that the wrong module gets returned by a `_frozen_importlib_external.PathFinder`, so basically a blackbox.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:122,usability,minim,minimal,122,"Still no clue: https://github.com/pytest-dev/pytest/issues/12194#issuecomment-2045446960. I haven’t been able to create a minimal reproducer yet. The problem is that the wrong module gets returned by a `_frozen_importlib_external.PathFinder`, so basically a blackbox.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:68,deployability,releas,release,68,"This is fixed in pytest-dev/pytest#12169. Let’s wait for the pytest release, and then bump the min pytest version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:106,deployability,version,version,106,"This is fixed in pytest-dev/pytest#12169. Let’s wait for the pytest release, and then bump the min pytest version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:106,integrability,version,version,106,"This is fixed in pytest-dev/pytest#12169. Let’s wait for the pytest release, and then bump the min pytest version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:106,modifiability,version,version,106,"This is fixed in pytest-dev/pytest#12169. Let’s wait for the pytest release, and then bump the min pytest version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:24,deployability,releas,releases,24,Does pytest track their releases somewhere public? Curious what the timeline is here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:43,integrability,pub,public,43,Does pytest track their releases somewhere public? Curious what the timeline is here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:68,performance,time,timeline,68,Does pytest track their releases somewhere public? Curious what the timeline is here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:0,reliability,Doe,Does,0,Does pytest track their releases somewhere public? Curious what the timeline is here,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:48,deployability,releas,releases,48,"I mean like milestones or projects for upcoming releases. It look like the change that fixes the issue got marked as an improvement, so we'd be waiting on 8.2.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:15,deployability,releas,release,15,There’s an 8.2 release planning issue now: https://github.com/pytest-dev/pytest/issues/12213,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/2993:23,testability,plan,planning,23,There’s an 8.2 release planning issue now: https://github.com/pytest-dev/pytest/issues/12213,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2993
https://github.com/scverse/scanpy/issues/3004:32,availability,error,errors,32,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:114,deployability,continu,continue,114,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:86,energy efficiency,current,currently,86,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:32,performance,error,errors,32,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:32,safety,error,errors,32,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:24,usability,help,helpful,24,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:32,usability,error,errors,32,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3004:57,usability,support,support,57,"We will start to return helpful errors for when we don't support something, and allow currently passing things to continue as such.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3004
https://github.com/scverse/scanpy/issues/3005:232,availability,error,error,232,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:232,performance,error,error,232,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:232,safety,error,error,232,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:57,usability,help,help,57,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:232,usability,error,error,232,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:249,usability,behavi,behaviour,249,"Hey, thanks for the request. To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. I think in your case this would be e.g. ```py. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). adata.obs[""louvain""] = adata.obs[""louvain""].cat.set_categories(new_categories=[""0"", ""1"", ""2"", ""3"", ""4"", ""5"", ""6"", ""7"", ""8"", ""9"", ""10"", ""11""]). sc.pl.violin(adata, keys='n_counts', groupby='louvain'). ```. Yielding. ```. ValueError: The palette dictionary is missing keys: {'11'}. ```. Is that the issue you are facing?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:35,deployability,fail,fails,35,"I do not know why `set_categories` fails to add the new ones for you. Perhaps you need to added `ordered=True`. Notice that in my example I use a different method of adding additional categories which works:. ```. ord = ['1','2','3', 'Whatever', 'Whatnot', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. Then try to plot any violin plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:35,reliability,fail,fails,35,"I do not know why `set_categories` fails to add the new ones for you. Perhaps you need to added `ordered=True`. Notice that in my example I use a different method of adding additional categories which works:. ```. ord = ['1','2','3', 'Whatever', 'Whatnot', 'Huh?', 'What?']. adata.obs['cell_type'] = pd.Categorical(values=adata.obs.cell_type, categories=ord, ordered=True). ```. Then try to plot any violin plot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:205,availability,error,error,205,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:433,availability,operat,operation,433,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:499,deployability,fail,failing,499,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:321,interoperability,specif,specific,321,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:205,performance,error,error,205,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:457,performance,perform,perform,457,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:499,reliability,fail,failing,499,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:205,safety,error,error,205,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:30,usability,help,help,30,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:205,usability,error,error,205,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:222,usability,behavi,behaviour,222,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:304,usability,clear,clear,304,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3005:457,usability,perform,perform,457,"> To be able to reproduce and help, it is a big aid for us if you can supply a code sample that we can run: that is, with some dummy data (the datasets scanpy readily supplies are great for that), and the error/unexpected behaviour you get. Can you show such an example, with data? It is not immediately clear to me what specific you are trying to add or construct; I'm not sure whether basically the dataframe gets destroyed by the operation you intend to perform, or whether it is the violin plot failing (if the dataframe is crooked, it would be this to be fixed).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3005
https://github.com/scverse/scanpy/issues/3011:6,interoperability,specif,specific,6,Which specific functions were you thinking about?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:58,deployability,scale,scale,58,"at least `_get_mean_var`, some stuff in `hvg_seurat_v3`, `scale` and `normalize_total`. I'll do one PR for each function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:58,energy efficiency,scale,scale,58,"at least `_get_mean_var`, some stuff in `hvg_seurat_v3`, `scale` and `normalize_total`. I'll do one PR for each function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:58,modifiability,scal,scale,58,"at least `_get_mean_var`, some stuff in `hvg_seurat_v3`, `scale` and `normalize_total`. I'll do one PR for each function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3011:58,performance,scale,scale,58,"at least `_get_mean_var`, some stuff in `hvg_seurat_v3`, `scale` and `normalize_total`. I'll do one PR for each function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3011
https://github.com/scverse/scanpy/issues/3013:9,deployability,deploy,deploying,9,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:142,deployability,manag,manageable,142,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:58,energy efficiency,CPU,CPU,58,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:142,energy efficiency,manag,manageable,142,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:58,performance,CPU,CPU,58,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:142,safety,manag,manageable,142,"Actually deploying this is probably blocked by correcting CPU affinities on the benchmarking machine, but writing the code for this should be manageable otherwise.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:28,safety,test,tests,28,"We now have the big dataset tests, so this might be easy-ish to do",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:28,testability,test,tests,28,"We now have the big dataset tests, so this might be easy-ish to do",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:342,availability,cluster,cluster,342,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:399,availability,cluster,cluster,399,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:342,deployability,cluster,cluster,342,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:390,deployability,api,api,390,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:399,deployability,cluster,cluster,399,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:596,deployability,instal,install,596,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:390,integrability,api,api,390,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:359,interoperability,distribut,distributed,359,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:390,interoperability,api,api,390,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:74,performance,perform,performance,74,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:63,testability,understand,understand,63,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/issues/3013:74,usability,perform,performance,74,"Goal:. Add `dask` use-cases to the scanpy benchmarks so we can understand performance changes. . Nice links:. 1. Example benchmark: https://github.com/scverse/scanpy/blob/main/benchmarks/benchmarks/preprocessing_counts.py. 2. Project we use for benchmarking: https://asv.readthedocs.io/projects/asv-runner/en/latest/index.html. 3. Dask local cluster: https://distributed.dask.org/en/stable/api.html#cluster. 4. Using scanpy and dask: https://scanpy.readthedocs.io/en/stable/tutorials/experimental/dask.html. NOTE: this `read_elem_as_dask` function in the notebook is with anndata 0.11 i.e., `pip install --pre anndata`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3013
https://github.com/scverse/scanpy/pull/3015:29,energy efficiency,core,cores,29,"Some small benchmarks for 32 cores with `CSR.shape=(196943, 20867)`:. | axis |old|new|. |------|-----|------|. |minor|804 ms|96 ms|. |major|520 ms|40 ms|",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015
https://github.com/scverse/scanpy/pull/3015:241,performance,tune,tuned,241,"I tentatively added a benchmark that runs just on `_get_mean_var`. Locally I don’t see any difference though, what’s wrong? Too small data? Numba not set up with correct number of threads? /edit: also I think the machine is not sufficiently tuned. The original run (before I added the `mean_var` benchmarks) said “No changes in benchmarks.”",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3015
https://github.com/scverse/scanpy/pull/3017:17,deployability,Version,Version,17,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:99,deployability,Version,Version,99,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:17,integrability,Version,Version,17,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:99,integrability,Version,Version,99,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:17,modifiability,Version,Version,17,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:99,modifiability,Version,Version,99,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:32,performance,memor,memory,32,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:83,performance,time,time,83,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:114,performance,memor,memory,114,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:166,performance,time,time,166,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:32,usability,memor,memory,32,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:114,usability,memor,memory,114,"~500k Cells. New Version:. peak memory: 16117.61 MiB, increment: 7709.86 MiB. Wall time: 11 s. Old Version:. peak memory: 40093.42 MiB, increment: 31646.50 MiB. Wall time: 30.9 s.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:96,deployability,scale,scalene,96,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:96,energy efficiency,scale,scalene,96,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:96,modifiability,scal,scalene,96,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:57,performance,memor,memory,57,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:96,performance,scale,scalene,96,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:106,safety,Test,Tests,106,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:106,testability,Test,Tests,106,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:57,usability,memor,memory,57,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:64,usability,efficien,efficient,64,"Indeed, ~3-7x faster for me & of course quite a bit more memory efficient (quickly checked with scalene). Tests keep working (for `seurat_v3`/`seurat_v3_paper` somewhat tight numeric comparison with Seurat results), nice.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:32,integrability,batch,batch,32,It is the whole matrix for each batch. It's just called batch_counts because I needed to make sure the format is csr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:103,interoperability,format,format,103,It is the whole matrix for each batch. It's just called batch_counts because I needed to make sure the format is csr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:32,performance,batch,batch,32,It is the whole matrix for each batch. It's just called batch_counts because I needed to make sure the format is csr,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:34,deployability,fail,fail,34,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:34,reliability,fail,fail,34,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:28,safety,test,tests,28,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3017:28,testability,test,tests,28,I don't know what makes the tests fail with dask in utils,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3017
https://github.com/scverse/scanpy/pull/3024:83,energy efficiency,current,currently,83,@flying-sheep Can we unmerge this. @ivirshup found some weird memory peaks that we currently can't explain,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024
https://github.com/scverse/scanpy/pull/3024:62,performance,memor,memory,62,@flying-sheep Can we unmerge this. @ivirshup found some weird memory peaks that we currently can't explain,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024
https://github.com/scverse/scanpy/pull/3024:62,usability,memor,memory,62,@flying-sheep Can we unmerge this. @ivirshup found some weird memory peaks that we currently can't explain,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3024
https://github.com/scverse/scanpy/issues/3026:39,deployability,updat,update,39,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:56,deployability,version,version,56,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:56,integrability,version,version,56,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:56,modifiability,version,version,56,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:39,safety,updat,update,39,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:39,security,updat,update,39,I think this is not a bug. You have to update to latest version of scanpy,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:78,deployability,version,versions,78,@bingy007 please report back if you can reproduce this with the latest scanpy versions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:78,integrability,version,versions,78,@bingy007 please report back if you can reproduce this with the latest scanpy versions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:78,modifiability,version,versions,78,@bingy007 please report back if you can reproduce this with the latest scanpy versions.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,deployability,updat,update,16,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:34,deployability,version,version,34,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:34,integrability,version,version,34,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:34,modifiability,version,version,34,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,safety,updat,update,16,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3026:16,security,updat,update,16,It works when I update the scanpy version from 1.9.8 to 1.10.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3026
https://github.com/scverse/scanpy/issues/3027:254,integrability,sub,subset,254,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:424,integrability,sub,subset,424,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:722,integrability,sub,subset,722,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:811,integrability,sub,subset,811,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:934,integrability,sub,subsetting,934,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:970,integrability,sub,subsetting,970,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:559,modifiability,variab,variable,559,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3027:68,usability,help,help,68,"Hey, thanks a lot for spotting & the nice reproducible example! Big help. From my first look into it, it seems this is a bug indeed;. **Bug appearing when**. - `batch_key` is not `None` and. - `flavor` is `“seurat”` or `“cell_ranger”` and. - then using `subset=True`. Other cases are not suffering from this it seems (e.g. `flavor=""seurat_v3""`, or when `batch_key=None`). **Issue**. It appears in the cases describe above, `subset=True` will cause the first `n_top_genes` many genes of `adata.var` to be used as selection: not the actual `n_top_genes` highly variable genes. Fix is on the way: I'll follow up here. **Your Example**. Reveals that `sc.pp.highly_variable_genes(ad_sub, n_top_genes = 1000, batch_key = ""Age"", subset = True)` suffers from this. . **Circumvent bug**. For now, I recommend not using `subset=True` if the cases above hold for you:. Rather, use . `adata_subset = adata[:, adata.var[""highly_variable""]]`. when subsetting: which is basically the ""subsetting afterwards"" strategy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3027
https://github.com/scverse/scanpy/issues/3028:244,availability,state,state,244,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:818,availability,error,error,818,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:942,availability,cluster,clustering,942,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1093,availability,cluster,clustering,1093,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1295,availability,cluster,clustering,1295,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:593,deployability,modul,modularity,593,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:862,deployability,api,api,862,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:904,deployability,Updat,Update,904,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:942,deployability,cluster,clustering,942,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1093,deployability,cluster,clustering,1093,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1295,deployability,cluster,clustering,1295,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:172,energy efficiency,Optim,Optimizers,172,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1056,energy efficiency,load,loads,1056,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1156,energy efficiency,power,powershell,1156,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:244,integrability,state,state,244,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:593,integrability,modular,modularity,593,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:862,integrability,api,api,862,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:214,interoperability,specif,specify,214,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:862,interoperability,api,api,862,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:593,modifiability,modul,modularity,593,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:172,performance,Optimiz,Optimizers,172,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:818,performance,error,error,818,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1056,performance,load,loads,1056,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:709,reliability,doe,doesn,709,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:593,safety,modul,modularity,593,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:818,safety,error,error,818,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:904,safety,Updat,Update,904,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:904,security,Updat,Update,904,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:593,testability,modula,modularity,593,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1035,testability,simpl,simple,1035,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:818,usability,error,error,818,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:1035,usability,simpl,simple,1035,"I'm getting this too. This could be a problem with numpy's random: . https://github.com/DLR-RM/stable-baselines3/issues/1579 . https://github.com/SimonBlanke/Gradient-Free-Optimizers/issues/11. I'm seeing if I can specify explicitly the random state or seed. Found where the problem happens:. _leiden.py. Line 185 . `part = g.community_leiden(**clustering_args)`. calls the following. community.py. Line 442. ```. membership, quality = GraphBase.community_leiden(. graph,. edge_weights=weights,. node_weights=node_weights,. resolution=resolution,. normalize_resolution=(objective_function == ""modularity""),. beta=beta,. initial_membership=initial_membership,. n_iterations=n_iterations,. ). ```. The debugger doesn't step into the `Graphbase.community_leiden` function any further, but this is where the loop with the error occurs. https://igraph.org/python/doc/api/igraph.Graph.html#community_leiden. **Update:**. Funnily enough, the Leiden clustering still executes correctly (took about 1 hour for me). How I did it was to create a simple .py file that loads the h5ad, just runs the leiden clustering, then writes a new h5ad, then ends. Ran that from a powershell window and just let it throw the warnings (which do not break the code execution). What I found is that I cannot run the leiden clustering in a notebook because the output gets overwhelmed and hangs VSCode.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:484,deployability,modul,modules,484,"Hm, that’s probably the doing of [`sklearn.utils.check_random_state`][]:. https://github.com/scverse/scanpy/blob/c3cfa74b1316d780568411175316cd9f139efb22/scanpy/_utils/__init__.py#L71-L72. @ilan-gold seems like using the legacy RandomState class wasn’t ideal. The new [`Generator`](https://numpy.org/doc/stable/reference/random/generator.html) actually emits 64 bit ints by default and I bet has other advantages. [`sklearn.utils.check_random_state`]: https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:484,modifiability,modul,modules,484,"Hm, that’s probably the doing of [`sklearn.utils.check_random_state`][]:. https://github.com/scverse/scanpy/blob/c3cfa74b1316d780568411175316cd9f139efb22/scanpy/_utils/__init__.py#L71-L72. @ilan-gold seems like using the legacy RandomState class wasn’t ideal. The new [`Generator`](https://numpy.org/doc/stable/reference/random/generator.html) actually emits 64 bit ints by default and I bet has other advantages. [`sklearn.utils.check_random_state`]: https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:484,safety,modul,modules,484,"Hm, that’s probably the doing of [`sklearn.utils.check_random_state`][]:. https://github.com/scverse/scanpy/blob/c3cfa74b1316d780568411175316cd9f139efb22/scanpy/_utils/__init__.py#L71-L72. @ilan-gold seems like using the legacy RandomState class wasn’t ideal. The new [`Generator`](https://numpy.org/doc/stable/reference/random/generator.html) actually emits 64 bit ints by default and I bet has other advantages. [`sklearn.utils.check_random_state`]: https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:467,usability,learn,learn,467,"Hm, that’s probably the doing of [`sklearn.utils.check_random_state`][]:. https://github.com/scverse/scanpy/blob/c3cfa74b1316d780568411175316cd9f139efb22/scanpy/_utils/__init__.py#L71-L72. @ilan-gold seems like using the legacy RandomState class wasn’t ideal. The new [`Generator`](https://numpy.org/doc/stable/reference/random/generator.html) actually emits 64 bit ints by default and I bet has other advantages. [`sklearn.utils.check_random_state`]: https://scikit-learn.org/stable/modules/generated/sklearn.utils.check_random_state.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:100,deployability,instal,install,100,@hl324 @glycoaddict can you try the fix here? https://github.com/scverse/scanpy/pull/3041. ```. pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng'. ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:132,availability,ERROR,ERROR,132,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:35,deployability,instal,install,35,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:132,performance,ERROR,ERROR,132,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:132,safety,ERROR,ERROR,132,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:132,usability,ERROR,ERROR,132,"@flying-sheep I tried running `pip install 'scanpy @ git+https://github.com/scverse/scanpy@modern-rng' ` in anaconda prompt and got ERROR: Invalid requirement: ""'scanpy"".",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:83,modifiability,paramet,parameter,83,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:254,safety,test,test,254,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:254,testability,test,test,254,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:171,usability,confirm,confirm,171,"Seems like some shell shenanigans. For some reason you passed `'scanpy` as a first parameter instead of the whole thing as a string. In any case, I either need someone to confirm that the fix works, or better, a reproducible example that we can derive a test case from.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3028:45,integrability,sub,subscribe,45,"A I missed #2969. duplicate of #2969, please subscribe to that one",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3028
https://github.com/scverse/scanpy/issues/3029:30,deployability,version,versions,30,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:30,integrability,version,versions,30,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:30,modifiability,version,versions,30,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:10,performance,time,time,10,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:67,performance,time,time,67,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:22,usability,minim,minimum,22,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:57,usability,help,help,57,"@ivirshup time to set minimum versions for scanpy? I can help this time, you don’t have to go through this alone again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,deployability,upgrad,upgrade,9,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414. - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:122,deployability,upgrad,upgrade,122,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414. - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,modifiability,upgrad,upgrade,9,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414. - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:122,modifiability,upgrad,upgrade,122,- Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): https://github.com/scverse/scanpy/pull/2414. - or upgrade Matplotlib to 3.8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:11,deployability,upgrad,upgrade,11,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414). > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:157,deployability,upgrad,upgrade,157,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414). > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:217,deployability,instal,install,217,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414). > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:11,modifiability,upgrad,upgrade,11,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414). > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:157,modifiability,upgrad,upgrade,157,> * Either upgrade Scanpy to 1.10 (this PR has the fix for your problem): [matplotlib 3.7 compat #2414](https://github.com/scverse/scanpy/pull/2414). > * or upgrade Matplotlib to 3.8. My Anaconda prompts that I can't install Scanpy above 1.10 or Matplotlib above 3.8.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,availability,avail,available,9,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:206,interoperability,format,format,206,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:387,interoperability,format,formatting-on-github,387,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:426,interoperability,format,formatting-syntax,426,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,reliability,availab,available,9,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,safety,avail,available,9,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:9,security,availab,available,9,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:54,usability,help,help,54,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:82,usability,command,command,82,"Both are available on conda forge. I might be able to help if you show me. 1. the command and environment file you used. 2. the output (in English: you can use e.g. `env LANG=C conda ...` for that). Please format everything as a code block and don’t just paste it into the comment box, [see here](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax#quoting-code)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:280,availability,error,error,280,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:335,availability,error,error,335,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:238,deployability,instal,install,238,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:321,deployability,fail,fails,321,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:383,deployability,version,version,383,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:383,integrability,version,version,383,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:191,interoperability,compatib,compatible,191,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:359,interoperability,incompatib,incompatible,359,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:178,modifiability,pac,packages,178,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:383,modifiability,version,version,383,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:280,performance,error,error,280,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:335,performance,error,error,335,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:321,reliability,fail,fails,321,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:280,safety,error,error,280,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:335,safety,error,error,335,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:13,security,auth,authors,13,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:280,usability,error,error,280,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:335,usability,error,error,335,"Dear scverse authors (@flying-sheep, @LucaMarconato et al.), because of issues like these, maybe think about a sophisticated staging environment a la Bioconductor to ensure that packages are compatible with each other. If you do a `conda install scanpy` that finishes without any error, it cannot be that `import scanpy` fails with an error resulting from an incompatible matplotlib version.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:125,deployability,patch,patches-feedstock,125,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:163,deployability,patch,patches,163,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:179,deployability,depend,dependency,179,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:179,integrability,depend,dependency,179,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:179,modifiability,depend,dependency,179,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:18,reliability,doe,doesn,18,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:125,safety,patch,patches-feedstock,125,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:163,safety,patch,patches,163,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:179,safety,depend,dependency,179,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:125,security,patch,patches-feedstock,125,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:163,security,patch,patches,163,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:179,testability,depend,dependency,179,"What you describe doesn‘t need to happen, and you can fix this! 1. go to https://github.com/conda-forge/conda-forge-repodata-patches-feedstock/. 2. make a PR that patches conda’s dependency data to include this constraint. 3. the problem is gone",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:108,availability,error,error,108,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:42,deployability,version,versions,42,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:175,deployability,version,version,175,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:273,deployability,automat,automated,273,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:42,integrability,version,versions,42,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:175,integrability,version,version,175,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:137,interoperability,specif,specific,137,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:183,interoperability,mismatch,mismatches,183,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:42,modifiability,version,versions,42,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:175,modifiability,version,version,175,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:226,modifiability,pac,packages,226,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:108,performance,error,error,108,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:108,safety,error,error,108,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:197,safety,compl,complex,197,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:197,security,compl,complex,197,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:273,testability,automat,automated,273,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:108,usability,error,error,108,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:205,usability,interact,interacting,205,"For me, it was a different combination of versions, I guess Scanpy 1.9.8 and matplotlib 3.8 that caused the error. It's not about fixing specific instances but the problem of version mismatches of complex interacting software packages in general. And this has to run in an automated fashion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:92,deployability,automat,automated,92,"@frederikziebell thanks for the feedback, we will discuss this in the next core meeting. An automated cross-package CI could be a solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:75,energy efficiency,core,core,75,"@frederikziebell thanks for the feedback, we will discuss this in the next core meeting. An automated cross-package CI could be a solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:108,modifiability,pac,package,108,"@frederikziebell thanks for the feedback, we will discuss this in the next core meeting. An automated cross-package CI could be a solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:92,testability,automat,automated,92,"@frederikziebell thanks for the feedback, we will discuss this in the next core meeting. An automated cross-package CI could be a solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/issues/3029:32,usability,feedback,feedback,32,"@frederikziebell thanks for the feedback, we will discuss this in the next core meeting. An automated cross-package CI could be a solution.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3029
https://github.com/scverse/scanpy/pull/3031:86,performance,time,time,86,"@flying-sheep Not sure. Now that you mention it, the rapids benchmark also takes more time than I'd expect as well...The functions themselves are quite fast.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3031
https://github.com/scverse/scanpy/pull/3032:79,deployability,version,version,79,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:229,deployability,log,logfoldchanges,229,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:1203,deployability,log,logfoldchanges,1203,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:79,integrability,version,version,79,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:79,modifiability,version,version,79,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:229,safety,log,logfoldchanges,229,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:1203,safety,log,logfoldchanges,1203,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:229,security,log,logfoldchanges,229,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:1203,security,log,logfoldchanges,1203,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:229,testability,log,logfoldchanges,229,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:1203,testability,log,logfoldchanges,1203,"has the order of the markers column changed in this PR? . i got a local scanpy version 1.10.1 output with the expected order. ```. markers = sc.get.rank_genes_groups_df(mdata[""atac""], group=None). >>> markers. group names scores logfoldchanges pvals pvals_adj. 0 0 chr21-45639191-45644849 8.696832 1.327774 3.412781e-18 1.838448e-13. 1 0 chrX-316242-321327 6.274838 0.534321 3.499977e-10 3.770841e-06. 2 0 chr12-119988038-119991086 6.187730 0.806758 6.103680e-10 5.978221e-06. 3 0 chr6-111086859-111088937 6.162030 2.258481 7.181815e-10 6.448013e-06. 4 0 chr11-66311251-66319124 6.112362 0.588367 9.816710e-10 7.675946e-06. ... ... ... ... ... ... ... 1077385 9 chr10-132415335-132424369 -2.942694 -3.170910 3.253696e-03 5.058441e-01. 1077386 9 chr10-126040813-126043736 -3.092387 -29.032339 1.985538e-03 3.968830e-01. 1077387 9 chr22-44023051-44027851 -3.237911 -28.983782 1.204083e-03 3.101063e-01. 1077388 9 chr9-127395571-127399337 -3.403331 -1.821466 6.656958e-04 2.238189e-01. 1077389 9 chr3-4975833-4984808 -3.997460 -1.672931 6.402590e-05 6.457136e-02. ```. but pulling the latest merged branch has the old order of scanpy<1.7.0 with flipped score and names columns - ( group, **scores,names,** logfoldchanges,pvals,pvals_adj) ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:43,usability,behavi,behavior,43,I very much doubt that this PR changed any behavior. It only touched the documentation. This PR isn't in 1.10.1 in any case,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3032:73,usability,document,documentation,73,I very much doubt that this PR changed any behavior. It only touched the documentation. This PR isn't in 1.10.1 in any case,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3032
https://github.com/scverse/scanpy/pull/3041:136,availability,slo,slowdown,136,"@RubenVanEsch could you look at this as well for your [issue](https://github.com/scverse/scanpy/issues/2969)? I am not so sure if a 15% slowdown is acceptable given the fact that the answer to solving this could just be ""use WSL,"" which we never got a response on because we go sidetracked. Could @RubenVanEsch or someone else confirm or not that the original problem is reproducible on WSL?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:136,reliability,slo,slowdown,136,"@RubenVanEsch could you look at this as well for your [issue](https://github.com/scverse/scanpy/issues/2969)? I am not so sure if a 15% slowdown is acceptable given the fact that the answer to solving this could just be ""use WSL,"" which we never got a response on because we go sidetracked. Could @RubenVanEsch or someone else confirm or not that the original problem is reproducible on WSL?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:327,usability,confirm,confirm,327,"@RubenVanEsch could you look at this as well for your [issue](https://github.com/scverse/scanpy/issues/2969)? I am not so sure if a 15% slowdown is acceptable given the fact that the answer to solving this could just be ""use WSL,"" which we never got a response on because we go sidetracked. Could @RubenVanEsch or someone else confirm or not that the original problem is reproducible on WSL?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:45,reliability,doe,doesn,45,Also @flying-sheep coming back to this - why doesn't this break tests? The underlying number generation mechanism is the same somehow? Or similar enough?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:64,safety,test,tests,64,Also @flying-sheep coming back to this - why doesn't this break tests? The underlying number generation mechanism is the same somehow? Or similar enough?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:64,testability,test,tests,64,Also @flying-sheep coming back to this - why doesn't this break tests? The underlying number generation mechanism is the same somehow? Or similar enough?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:28,deployability,instal,install,28,"@ilan-gold turns out i cant install WSL on my laptop after all, so unfortunately i cant check this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:143,usability,help,help,143,"The other way round: If using WSL would be a viable workaround, we don’t need this. So if you can’t use WSL, it’s even more important that you help us by checking if this PR fixes things for you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:112,availability,error,error,112,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:54,deployability,instal,installed,54,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:491,deployability,version,version,491,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:491,integrability,version,version,491,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:491,modifiability,version,version,491,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:112,performance,error,error,112,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:112,safety,error,error,112,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:124,safety,Except,Exception,124,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:168,testability,Trace,Traceback,168,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:112,usability,error,error,112,"Hi, I cloned this repo, switched to `modern-rng`, and installed it with `pip`. I was able to reproduce the same error. ```. Exception ignored in: <class 'ValueError'>. Traceback (most recent call last):. File ""numpy\random\_generator.pyx"", line 622, in numpy.random._generator.Generator.integers. File ""numpy\random\_bounded_integers.pyx"", line 2881, in numpy.random._bounded_integers._rand_int32"". ValueError: high is out of bounds for int32. ```. I am using numpy 1.26, which is the numpy version required by this branch.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:92,availability,cluster,clustering,92,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:35,deployability,modul,module,35,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:92,deployability,cluster,clustering,92,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:35,modifiability,modul,module,35,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:4,safety,except,exception,4,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:35,safety,modul,module,35,"The exception is raised from the C module in the igraph library which actually computes the clustering algorithm, GraphBase.community_leiden. So it may be a bug in igraph, or the incorrect arguments are being passed to igraph. Here is some sample code to reproduce. ```. import numpy as np. import anndata as ad. import scanpy as sc. rng = np.random.default_rng(). counts = rng.integers(low=-1000,high=100,size=(100,1000)). counts = np.maximum(counts , 0). adata = ad.AnnData(counts). sc.tl.pca(adata). sc.pp.neighbors(adata). sc.tl.leiden(adata,flavor='igraph',n_iterations=2). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3041:193,usability,close,closed,193,"Hi Patrick, we’re quite busy with the scverse conference right now, so don’t be distraught if we can’t investigate this more right away. I’ll link to your reproducers here from the issue, as a closed PR is a place few people ever look, and we’ll come back to this in a week or so.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3041
https://github.com/scverse/scanpy/pull/3042:44,safety,test,tests,44,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:77,security,ident,identical,77,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:6,testability,simpl,simple,6,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:44,testability,test,tests,44,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:6,usability,simpl,simple,6,"Looks simple enough! Please deduplicate the tests though, they have too many identical lines.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:25,safety,test,tests,25,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:103,safety,test,tests,103,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:140,safety,test,test,140,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:178,safety,test,test,178,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:58,security,ident,identical,58,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:25,testability,test,tests,25,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:103,testability,test,tests,103,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:140,testability,test,test,140,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:178,testability,test,test,178,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:158,usability,prefer,prefer,158,"> Please deduplicate the tests though, they have too many identical lines. To do so did across-setting tests with for loop on top of former test... Would you prefer one separate test with that for loop for the across-settings check?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:420,availability,consist,consistent,420,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:714,availability,consist,consistent,714,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:978,availability,consist,consistent,978,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:96,integrability,sub,subset,96,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:435,integrability,sub,subset,435,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:729,integrability,sub,subset,729,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:1013,integrability,sub,subset,1013,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:331,interoperability,specif,specific,331,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:210,modifiability,paramet,parametrize,210,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:279,performance,time,time,279,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:36,reliability,doe,doesnt,36,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:3,safety,test,test,3,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:378,safety,test,test,378,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:1137,security,hardcod,hardcode,1137,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:3,testability,test,test,3,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:378,testability,test,test,378,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:592,testability,assert,assert,592,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:873,testability,assert,assert,873,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:1026,testability,assert,assert,1026,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:420,usability,consist,consistent,420,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:714,usability,consist,consistent,714,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:978,usability,consist,consistent,978,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:1216,usability,prefer,preference,1216,"To test in the future that this bug doesnt happen, the 4 combinations of inplace=True/False and subset=True/False need to be compared for their selected `var_names` - if these arguments were be in `pytest.mark.parametrize`, the different produced anndatas don't live at the same time and can't be compared... Could. - extract this specific section into a new, dedicated smaller test. ```py. # check that the results are consistent for subset True/False: inplace True. adata_post_subset = adatas[""subset_False_inplace_True""][. :, adatas[""subset_False_inplace_True""].var[""highly_variable""]. ]. assert adata_post_subset.var_names.equals(. adatas[""subset_True_inplace_True""].var_names. ). # check that the results are consistent for subset True/False: inplace False. df_post_subset = dfs[""subset_False_inplace_False""][. dfs[""subset_False_inplace_False""][""highly_variable""]. ]. assert df_post_subset.index.equals(dfs[""subset_True_inplace_False""].index). # check that the results are consistent for inplace True/False: subset True. assert adatas[""subset_True_inplace_True""].var_names.equals(. dfs[""subset_True_inplace_False""].index. ). ```. - hardcode the known-to-be-selected features and check against them. what's your preference here?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:137,integrability,sub,subset,137,"Ah, silly me, this makes sense. Since some entries of the dicts are never used, I just removed them and replaced the string with a bool (subset=True/False). This makes it all quite a bit more compact. Also please remember `itertools`: If we’re not writing numba code, it’s always preferable to use it as opposed to nesting for loops.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:213,safety,reme,remember,213,"Ah, silly me, this makes sense. Since some entries of the dicts are never used, I just removed them and replaced the string with a bool (subset=True/False). This makes it all quite a bit more compact. Also please remember `itertools`: If we’re not writing numba code, it’s always preferable to use it as opposed to nesting for loops.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:280,usability,prefer,preferable,280,"Ah, silly me, this makes sense. Since some entries of the dicts are never used, I just removed them and replaced the string with a bool (subset=True/False). This makes it all quite a bit more compact. Also please remember `itertools`: If we’re not writing numba code, it’s always preferable to use it as opposed to nesting for loops.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:21,deployability,fail,failing,21,Timeout and Scrublet failing in Python3.12?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:0,performance,Time,Timeout,0,Timeout and Scrublet failing in Python3.12?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:21,reliability,fail,failing,21,Timeout and Scrublet failing in Python3.12?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:0,safety,Timeout,Timeout,0,Timeout and Scrublet failing in Python3.12?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:110,interoperability,specif,specific,110,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:61,modifiability,paramet,parametrize,61,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:32,safety,detect,detected,32,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:119,safety,test,test,119,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:138,safety,avoid,avoid,138,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:32,security,detect,detected,32,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:0,testability,coverag,coverage,0,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:119,testability,test,test,119,"coverage decreased, I think not detected because some pytest.parametrize were removed? I can also add the new specific test separately do avoid this, else it looks good to me",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:117,deployability,updat,updated,117,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:63,modifiability,paramet,parametrize,63,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:186,reliability,doe,doesn,186,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:34,safety,detect,detected,34,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:117,safety,updat,updated,117,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:34,security,detect,detected,34,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:117,security,updat,updated,117,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3042:2,testability,coverag,coverage,2,"> coverage decreased, I think not detected because some pytest.parametrize were removed? I think codecov just hadn’t updated its comment yet when you saw that. What you say can’t be, it doesn’t matter how a line was hit: If a line is run, it’ll be reported as hit, if your changes would have caused it to no longer be it, it would have been reported as a miss.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3042
https://github.com/scverse/scanpy/pull/3044:9,reliability,doe,doesn,9,scrublet doesn't seem to be part of the benchmarks at the moment,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:448,deployability,log,logs,448,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:567,deployability,PATCH,PATCH,567,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:590,deployability,api,api,590,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:849,deployability,PATCH,PATCH,849,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:872,deployability,api,api,872,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:590,integrability,api,api,590,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:872,integrability,api,api,872,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:1105,integrability,queue,queue,1105,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:590,interoperability,api,api,590,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:872,interoperability,api,api,872,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:1105,performance,queue,queue,1105,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:1111,performance,time,time,1111,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:448,safety,log,logs,448,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:567,safety,PATCH,PATCH,567,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:849,safety,PATCH,PATCH,849,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:448,security,log,logs,448,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:567,security,PATCH,PATCH,567,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:849,security,PATCH,PATCH,849,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3044:448,testability,log,logs,448,"With #3056 merged, this now says. > before | after | ratio | benchmark. > --- | --- | --- | ---. > 448±100ms | 381±100ms | ~0.85 | `preprocessing_counts.time_scrublet('pbmc68k_reduced')`. but ASV seems to think that’s not enough to report. Also unclear why it’s reported as taking 26 minutes by github:. > <img width=""252"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/291575/6117cece-a145-4b46-85a4-dd86a61819ef"">. I see in the server logs. > - May 14 10:15:57 scvbench benchmark[1462905]: 2024-05-14T10:15:57.547945Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. > - […running benchmarks]. > - May 14 10:27:18 scvbench benchmark[1462905]: 2024-05-14T10:27:18.793352Z DEBUG handle_event:HTTP{http.method=PATCH http.url=https://api.github.com/repos/scverse/scanpy/check-runs/24942322156 otel.name=""HTTP"" otel.kind=""client""}: octocrab: requesting. which means that between setting the check run to “running” and to “done”, 11m21s passed. Maybe GitHub counts the queue time?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3044
https://github.com/scverse/scanpy/pull/3047:588,integrability,transform,transformed,588,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:677,integrability,transform,transformed,677,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:96,interoperability,coordinat,coordinates,96,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:588,interoperability,transform,transformed,588,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:677,interoperability,transform,transformed,677,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:299,modifiability,deco,decomposition,299,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:214,reliability,doe,doesn,214,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:116,safety,test,tests,116,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:649,safety,test,testing,649,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:116,testability,test,tests,116,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:649,testability,test,testing,649,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:150,usability,learn,learn,150,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3047:163,usability,learn,learn,163,"Hmm, seems like `PCA` with `svd_solver='arpack'` works differently in sklearn 1.5 and flips the coordinates in some tests:. https://github.com/scikit-learn/scikit-learn/issues/28826. E.g. this used to work, now it doesn’t. ```py. from __future__ import annotations. import numpy as np. from sklearn.decomposition import PCA. data = np.asarray([[-1, 2, 0], [3, 4, 0], [1, 2, 0]]).T. expected = np.array(. [[-1.579575e-15, 1.490712], [-2.44949, -0.745356], [2.44949, -0.745356]],. dtype=np.float32,. ). pca = PCA(n_components=2, svd_solver=""arpack"", random_state=np.random.RandomState(0)). transformed = pca.fit_transform(data).astype(np.float32). np.testing.assert_almost_equal(transformed, expected, decimal=5). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3047
https://github.com/scverse/scanpy/pull/3048:70,integrability,sub,subset,70,"@flying-sheep What do you think here? If the plan looks good for this subset of functions, I'd expand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:45,testability,plan,plan,45,"@flying-sheep What do you think here? If the plan looks good for this subset of functions, I'd expand it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:24,availability,error,error,24,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:30,integrability,messag,messages,30,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:30,interoperability,messag,messages,30,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:24,performance,error,error,24,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:24,safety,error,error,24,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:79,security,control,control,79,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:79,testability,control,control,79,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:24,usability,error,error,24,"I like the idea! Better error messages, and getting our modalities a bit under control is a great goal as well!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:259,availability,error,error,259,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:284,integrability,messag,message,284,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:284,interoperability,messag,message,284,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:197,modifiability,layer,layers,197,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:259,performance,error,error,259,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:259,safety,error,error,259,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:259,usability,error,error,259,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:276,usability,help,helpful,276,"Looking at this again, now that I have gone through everything, I think we actually need to check types directly and shouldn't rely on `isbacked` because it is possible to do something like `adata.layers['foo'] = sparse_dataset(g_layer)` and this should also error our with a helpful message.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:19,usability,support,supported,19,"If that’s actually supported, we need to rethink `isbacked` anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:129,reliability,doe,does,129,"> If that’s actually supported. If what is actually supported? `sparse_dataset` is exported from `experimental` and in any case, does being more exhaustive hurt? I think we have been telling people to use `sparse_dataset` if it suits them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:21,usability,support,supported,21,"> If that’s actually supported. If what is actually supported? `sparse_dataset` is exported from `experimental` and in any case, does being more exhaustive hurt? I think we have been telling people to use `sparse_dataset` if it suits them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:52,usability,support,supported,52,"> If that’s actually supported. If what is actually supported? `sparse_dataset` is exported from `experimental` and in any case, does being more exhaustive hurt? I think we have been telling people to use `sparse_dataset` if it suits them.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:89,deployability,build,buildId,89,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:107,deployability,log,logs,107,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:314,deployability,releas,release,314,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:412,deployability,fail,failing,412,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:219,modifiability,pac,package,219,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:412,reliability,fail,failing,412,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:107,safety,log,logs,107,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:424,safety,test,test,424,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:107,security,log,logs,107,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:107,testability,log,logs,107,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:424,testability,test,test,424,"1. How do we xfail stuff from `dev`? https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=108 It looks like the UMAP package via `pynndescent` is using something that has been removed (`np.infty`) in an upcoming release of numpy. 2. Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:39,availability,down,downloading,39,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:263,availability,down,downloading,263,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:440,availability,down,downloading,440,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:132,deployability,build,buildId,132,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:150,deployability,log,logs,150,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:338,deployability,build,buildId,338,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:356,deployability,log,logs,356,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:150,safety,log,logs,150,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:356,safety,log,logs,356,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:150,security,log,logs,150,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:356,security,log,logs,356,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:150,testability,log,logs,150,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:356,testability,log,logs,356,"So it looks like we definitely started downloading the rc for numpy relecently: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6661&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=22c10d56-3e3b-5f98-5bc6-b33384a21306 (from last week or something, downloading 1.26.4) vs https://dev.azure.com/scverse/scanpy/_build/results?buildId=6692&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=efb91c47-e839-5730-ecc5-cc752bc791b5 (downloading the 2.0 rc)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:248,deployability,releas,release,248,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:554,deployability,fail,failing,554,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:380,modifiability,variab,variable,380,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:407,modifiability,variab,variable,407,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:554,reliability,fail,failing,554,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:355,safety,test,tests,355,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:566,safety,test,test,566,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:355,testability,test,tests,355,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:566,testability,test,test,566,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:695,usability,indicat,indication,695,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:798,usability,visual,visual,798,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:805,usability,indicat,indication,805,"> How do we xfail stuff from dev? [`pytest.mark.xfail`](https://docs.pytest.org/en/6.2.x/reference.html#pytest-mark-xfail) takes a condition:. ```py. xfail_if_dev_tests = pytest.mark.xfail(. os.environ.get(""DEPENDENCIES_VERSION"", ""latest"") == ""pre-release"",. reason=""..."",. ). @xfail_if_dev_tests. def test_xzy(): ... ```. You probably need to change the tests so it makes the CI variable visible as an env variable, I’m not an Azure expert so I don’t know if it already is. > Codecov, I think, is outright wrong aklthough that might have to do with the failing dev test. Yeah, maybe, let’s see once everything passes. I’m also OK with lowering the percentage, I just set it to 75% to have some indication if codecov is broken or working. (Before it would report 20% for a PR and there would be no visual indication that that’s a problem).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:151,deployability,version,version,151,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:212,deployability,build,buildId,212,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:230,deployability,log,logs,230,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:376,deployability,build,buildId,376,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:394,deployability,log,logs,394,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:151,integrability,version,version,151,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:151,modifiability,version,version,151,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:6,safety,test,tests,6,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:31,safety,test,tests,31,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:97,safety,test,tests,97,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:230,safety,log,logs,230,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:394,safety,log,logs,394,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:230,security,log,logs,230,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:394,security,log,logs,394,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:6,testability,test,tests,6,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:31,testability,test,tests,31,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:97,testability,test,tests,97,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:230,testability,log,logs,230,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/pull/3048:394,testability,log,logs,394,"Flaky tests, it seems, `scanpy/tests/test_scrublet.py::test_scrublet_data` under dev and `scanpy/tests/test_utils.py::test_is_constant_dask` under min version: https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0&l=2230 and https://dev.azure.com/scverse/scanpy/_build/results?buildId=6733&view=logs&j=cb4d9293-b492-5d67-02b0-e6a595893958&t=99aeec2e-a40e-57fc-1ab3-27c1a626c3e0. Will try re-running",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3048
https://github.com/scverse/scanpy/issues/3049:17,interoperability,specif,specify,17,"You just need to specify `key=` to `rank_genes_groups_dotplot`, as described in the **Examples** section of the [documentation of `filter_rank_genes_groups`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html):. > ```py. > sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). > # visualize results using dotplot. > sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). > ```. I don’t know if we can make it clearer. If you have any suggestions, or if I misinterpreted what you want, please leave a comment!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:113,usability,document,documentation,113,"You just need to specify `key=` to `rank_genes_groups_dotplot`, as described in the **Examples** section of the [documentation of `filter_rank_genes_groups`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html):. > ```py. > sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). > # visualize results using dotplot. > sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). > ```. I don’t know if we can make it clearer. If you have any suggestions, or if I misinterpreted what you want, please leave a comment!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:332,usability,visual,visualize,332,"You just need to specify `key=` to `rank_genes_groups_dotplot`, as described in the **Examples** section of the [documentation of `filter_rank_genes_groups`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html):. > ```py. > sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). > # visualize results using dotplot. > sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). > ```. I don’t know if we can make it clearer. If you have any suggestions, or if I misinterpreted what you want, please leave a comment!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:479,usability,clear,clearer,479,"You just need to specify `key=` to `rank_genes_groups_dotplot`, as described in the **Examples** section of the [documentation of `filter_rank_genes_groups`](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.filter_rank_genes_groups.html):. > ```py. > sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'). > # visualize results using dotplot. > sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'). > ```. I don’t know if we can make it clearer. If you have any suggestions, or if I misinterpreted what you want, please leave a comment!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:3,availability,error,error,3,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:41,deployability,log,logfoldchanges,41,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:175,deployability,log,logfoldchanges,175,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:3,performance,error,error,3,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:3,safety,error,error,3,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:41,safety,log,logfoldchanges,41,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:175,safety,log,logfoldchanges,175,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:41,security,log,logfoldchanges,41,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:175,security,log,logfoldchanges,175,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:41,testability,log,logfoldchanges,41,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:175,testability,log,logfoldchanges,175,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:3,usability,error,error,3,"An error was raised when values_to_plot=""logfoldchanges"" was provided. ```python. sc.pl.rank_genes_groups_dotplot(. adata,. n_genes=5,. groupby='leiden_0.1',. values_to_plot=""logfoldchanges"",. cmap='bwr',. vmax=20,. vmin=-20,. key='leiden_0.1_marker_filtered',. show=False. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:23,availability,error,error,23,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:76,availability,error,error,76,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:13,interoperability,share,share,13,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:23,performance,error,error,23,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:76,performance,error,error,76,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:23,safety,error,error,23,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:76,safety,error,error,76,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:82,testability,trace,traceback,82,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:23,usability,error,error,23,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:39,usability,help,help,39,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:76,usability,error,error,76,"If you don’t share the error, we can’t help you. Could you include the full error traceback?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2683,availability,error,error,2683,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:283,deployability,log,logfoldchanges,283,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2131,deployability,log,logfoldchanges,2131,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2678,deployability,log,logg,2678,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2614,energy efficiency,Current,Currently,2614,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2889,energy efficiency,Current,Currently,2889,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2484,integrability,messag,message,2484,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2689,integrability,messag,message,2689,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2724,integrability,messag,message,2724,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2484,interoperability,messag,message,2484,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2689,interoperability,messag,message,2689,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2724,interoperability,messag,message,2724,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:471,modifiability,pac,packages,471,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:586,modifiability,pac,packages,586,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:1531,modifiability,pac,packages,1531,"software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_gro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:1646,modifiability,pac,packages,1646,"enes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 163",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2221,modifiability,pac,packages,2221,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2337,modifiability,pac,packages,2337,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2683,performance,error,error,2683,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:283,safety,log,logfoldchanges,283,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2131,safety,log,logfoldchanges,2131,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2678,safety,log,logg,2678,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2683,safety,error,error,2683,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:283,security,log,logfoldchanges,283,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2131,security,log,logfoldchanges,2131,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2678,security,log,logg,2678,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:13,testability,trace,traceback,13,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:118,testability,Trace,Traceback,118,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:283,testability,log,logfoldchanges,283,"Below is the traceback:. ```. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[10], line 1. ----> 1 sc.pl.rank_genes_groups_dotplot(. 2 adata,. 3 n_genes=5,. 4 groupby='leiden_0.1',. 5 values_to_plot=""logfoldchanges"",. 6 cmap='bwr',. 7 vmax=20,. 8 vmin=-20,. 9 key='leiden_0.1_marker_filtered',. 10 show=False. 11 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:874](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=873), in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, values_to_plot, var_names, gene_symbols, min_logfoldchange, key, show, save, return_fig, **kwds). 741 @_doc_params(. 742 params=doc_rank_genes_groups_plot_args,. 743 vals_to_plot=doc_rank_genes_groups_values_to_plot,. (...). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2131,testability,log,logfoldchanges,2131,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2678,testability,log,logg,2678,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3049:2683,usability,error,error,2683,".). 768 **kwds,. 769 ):. 770 """"""\. 771 Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). 772 . (...). 872 tl.rank_genes_groups. 873 """""". --> 874 return _rank_genes_groups_plot(. 875 adata,. 876 plot_type='dotplot',. 877 groups=groups,. 878 n_genes=n_genes,. 879 groupby=groupby,. 880 values_to_plot=values_to_plot,. 881 var_names=var_names,. 882 gene_symbols=gene_symbols,. 883 key=key,. 884 min_logfoldchange=min_logfoldchange,. 885 show=show,. 886 save=save,. 887 return_fig=return_fig,. 888 **kwds,. 889 ). File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:531](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=530), in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, values_to_plot, var_names, min_logfoldchange, key, show, save, return_fig, gene_symbols, **kwds). 529 values_df = None. 530 if values_to_plot is not None:. --> 531 values_df = _get_values_to_plot(. 532 adata,. 533 values_to_plot,. 534 var_names_list,. 535 key=key,. 536 gene_symbols=gene_symbols,. 537 ). 538 title = values_to_plot. 539 if values_to_plot == 'logfoldchanges':. File [/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py:1636](/mnt/data1/liz/software/miniconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_tools/__init__.py#line=1635), in _get_values_to_plot(adata, values_to_plot, gene_names, groups, key, gene_symbols). 1629 message = (. 1630 ""Please run `sc.tl.rank_genes_groups` with "". 1631 ""'n_genes=adata.shape[1]' to save all gene "". 1632 f""scores. Currently, only {df.shape[0]} "". 1633 ""are found"". 1634 ). 1635 logg.error(message). -> 1636 raise ValueError(message). 1637 df['group'] = group. 1638 df_list.append(df). ValueError: Please run `sc.tl.rank_genes_groups` with 'n_genes=adata.shape[1]' to save all gene scores. Currently, only 2238 are found. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3049
https://github.com/scverse/scanpy/issues/3051:14,deployability,automat,automating,14,idea for semi-automating 1.: we could have a representation (ideally the new fancy HTML one) created and attached by CI,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:14,testability,automat,automating,14,idea for semi-automating 1.: we could have a representation (ideally the new fancy HTML one) created and attached by CI,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:133,deployability,scale,scale,133,"I think pbmc68k_reduced was processed something like. ```py. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata). sc.pp.scale(adata). ```. still no idea what’s in “raw” as it’s clearly not counts …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:133,energy efficiency,scale,scale,133,"I think pbmc68k_reduced was processed something like. ```py. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata). sc.pp.scale(adata). ```. still no idea what’s in “raw” as it’s clearly not counts …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:133,modifiability,scal,scale,133,"I think pbmc68k_reduced was processed something like. ```py. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata). sc.pp.scale(adata). ```. still no idea what’s in “raw” as it’s clearly not counts …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:133,performance,scale,scale,133,"I think pbmc68k_reduced was processed something like. ```py. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata). sc.pp.scale(adata). ```. still no idea what’s in “raw” as it’s clearly not counts …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3051:190,usability,clear,clearly,190,"I think pbmc68k_reduced was processed something like. ```py. sc.pp.normalize_total(adata, target_sum=1e6). sc.pp.log1p(adata). sc.pp.scale(adata). ```. still no idea what’s in “raw” as it’s clearly not counts …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3051
https://github.com/scverse/scanpy/issues/3052:394,usability,support,supported,394,## [CodSpeed](https://codspeed.io/). Seems very promising:. - [Unlimited use from open source repos](https://codspeed.io/pricing). - Switch from asv to [`pytest-benchmark` / `pytest-codspeed`](https://docs.codspeed.io/benchmarks/python). - We can use our benchmark machine together with [codspeed-runner](https://github.com/CodSpeedHQ/runner) instead of a GitHub runner. Runner seems to not be supported on Rocky though: https://github.com/CodSpeedHQ/runner/issues/21,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3052
https://github.com/scverse/scanpy/issues/3054:1045,deployability,api,api,1045," describe what issues you encounter trying to use scanpy on the data you want to use it on? E.g. naively, I’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just ta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1253,deployability,api,api,1253,"’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just take them out again:. ```py. eigenvecs, eigenvals = adata.obsm['X_diffmap'], adata.uns['diffmap_evals']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:174,integrability,wrap,wrap,174,"I’m not categorically against it, but could you describe what issues you encounter trying to use scanpy on the data you want to use it on? E.g. naively, I’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). E",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1045,integrability,api,api,1045," describe what issues you encounter trying to use scanpy on the data you want to use it on? E.g. naively, I’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just ta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1253,integrability,api,api,1253,"’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just take them out again:. ```py. eigenvecs, eigenvals = adata.obsm['X_diffmap'], adata.uns['diffmap_evals']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1045,interoperability,api,api,1045," describe what issues you encounter trying to use scanpy on the data you want to use it on? E.g. naively, I’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just ta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1253,interoperability,api,api,1253,"’d think you’d just wrap your matrix in an AnnData object, then run `diffmap`:. ```pycon. >>> import scanpy as sc. >>> adata = sc.AnnData(my_matrix) # shape: (n_observations, n_variables). >>> sc.tl.diffmap(adata). ValueError: You need to run `pp.neighbors` first to compute a neighborhood graph. ```. Then you just follow that advice and `repr` the object after to see what’s in there:. ```pycon. >>> sc.pp.neighbors(adata). >>> sc.tl.diffmap(adata). >>> adata. AnnData object ... uns: diffmap_evals. obsm: X_diffmap. ```. Alternatively you read the docs: The [`diffmap` docs](https://scanpy.readthedocs.io/en/stable/generated/scanpy.tl.diffmap.html) point out both how to use `neighbors` …. > The width (“sigma”) of the connectivity kernel is implicitly determined by the number of neighbors used to compute the single-cell graph in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To reproduce the original implementation using a Gaussian kernel, use `method=='gauss'` in [`neighbors()`](https://scanpy.readthedocs.io/en/stable/api/generated/scanpy.pp.neighbors.html#scanpy.pp.neighbors). To use an exponential kernel, use the default `method=='umap'`. Differences between these options shouldn’t usually be dramatic. … and where the results are pushed:. > … Sets the following fields:. > . > `adata.obsm['X_diffmap']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Diffusion map representation of data, which is the right eigen basis of the transition matrix with eigenvectors as columns. >. > `adata.uns['diffmap_evals']` : [`numpy.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray) (dtype `float`). > . > > Array of size (number of eigen vectors). Eigenvalues of transition matrix. so you just take them out again:. ```py. eigenvecs, eigenvals = adata.obsm['X_diffmap'], adata.uns['diffmap_evals']. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:218,deployability,API,API,218,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:476,deployability,stack,stackoverflow,476,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:558,deployability,observ,observations-into-an-existing-spac,558,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1033,deployability,api,api,1033,through on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1390,deployability,build,build,1390,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1425,deployability,stack,stackoverflow,1425,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1167,energy efficiency,model,model,1167,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:218,integrability,API,API,218,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:321,integrability,transform,transform,321,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:526,integrability,transform,transform-method-to-project-new-observations-into-an-existing-spac,526,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1033,integrability,api,api,1033,through on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1069,integrability,transform,transformers,1069,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1367,integrability,transform,transformer,1367,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:218,interoperability,API,API,218,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:275,interoperability,compatib,compatible,275,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:321,interoperability,transform,transform,321,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:526,interoperability,transform,transform-method-to-project-new-observations-into-an-existing-spac,526,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:711,interoperability,coordinat,coordinates,711,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1033,interoperability,api,api,1033,through on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are ,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1069,interoperability,transform,transformers,1069,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1367,interoperability,transform,transformer,1367,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:654,modifiability,extens,extensions,654,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1665,modifiability,pac,package,1665,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:85,security,access,access,85,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:185,security,access,access,185,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1144,security,access,access,1144,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1167,security,model,model,1167,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:558,testability,observ,observations-into-an-existing-spac,558,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:31,usability,walkthrough,walkthrough,31,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:150,usability,navigat,navigate,150,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:206,usability,Learn,Learn,206,Thanks for the explanation and walkthrough on where everything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this softwar,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1062,usability,custom,custom,1062,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1543,usability,help,help,1543,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/issues/3054:1646,usability,prefer,preferred,1646,verything is located and how to access it! This is actually very useful. This makes it easier to navigate the addata object. Having access to the Scikit-Learn style API would be useful for incorporating with other sklearn compatible methods. The biggest thing is the .transform method to project new samples into the diffusion space. I've been trying to figure out how to implement this on my own but I hit a snag: https://stackoverflow.com/questions/78486471/how-to-add-a-transform-method-to-project-new-observations-into-an-existing-spac. pyDiffMap has an implementation for [Nystroem out-of-sample extensions used to calculate the values of the diffusion coordinates at each given point.](https://github.com/DiffusionMapsAcademics/pyDiffMap/blob/22adc99faa83708e9ac05224015fa02c3a7f3c91/src/pydiffmap/diffusion_map.py#L294). The backend implementations of the algorithms are different so I'm not sure if I can just port this method over. It would also be great if said sklearn-api would have an option for custom transformers. It looks like this was already implemented but having direct access to a standalone model object w/ this capability would be incredibly useful! Nothing like this exists for DiffusionMaps right now. I'm trying to implement it myself but I also hit a snag when trying to generalize the transformer objects to build connectivity graphs: https://stackoverflow.com/questions/78486997/how-to-reproduce-kneighbors-graphinclude-self-true-using-kneighborstransfor. Any help on this front would be amazing especially if I could just use It directly w/ scanpy as this is my preferred analysis package (I actually started to deprecate my own software suite https://github.com/jolespin/soothsayer because scanpy worked so well). . I work quite a bit in both the microbial ecology realm and single cell transcriptomics using scanpy for both. I'm trying to make a push for the microbial ecology community to start using this software as the problems being solved are very very similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3054
https://github.com/scverse/scanpy/pull/3060:2126,availability,down,download,2126,"scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────╯. ```. > What was stopping this before? […] why wouldn't we want to download the data everytime? someone implementing the caching, so nothing much really",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:56,deployability,log,log,56,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:2180,performance,cach,caching,2180,"scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────╯. ```. > What was stopping this before? […] why wouldn't we want to download the data everytime? someone implementing the caching, so nothing much really",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:56,safety,log,log,56,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:143,safety,test,test,143,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:159,safety,test,tests,159,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:172,safety,test,tests,172,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:56,security,log,log,56,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:56,testability,log,log,56,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:143,testability,test,test,143,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:159,testability,test,tests,159,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:172,testability,test,tests,172,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:9,usability,document,documenting,9,"> Are we documenting here which of these have counts vs log vs normalized? yeah, I’d like to do that! It’s really not bad. ```console. ❯ hatch test --internet-tests scanpy/tests/test_datasets.py::test_doc_shape scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴──────────────────────────────────────────────────────────────────────",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3060:2076,usability,stop,stopping,2076,"scanpy/datasets/. [...]. ❯ du -a .pytest_cache/d/scanpy-data/ | reject directories files apparent. ╭───┬──────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼──────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data │ 199.6 MB │. ╰───┴──────────────────────────────────────────────────────────────────────┴──────────╯. ❯ du -a .pytest_cache/d/scanpy-data/* | reject directories files apparent. ╭───┬────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┬──────────╮. │ # │ path │ physical │. ├───┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┼──────────┤. │ 0 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/E-MTAB-4888 │ 71.1 MB │. │ 1 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/Targeted_Visium_Human_Glioblastoma_Pan_Cancer │ 19.7 MB │. │ 2 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/V1_Breast_Cancer_Block_A_Section_1 │ 48.3 MB │. │ 3 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/burczynski06 │ 16.3 MB │. │ 4 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/moignard15 │ 3.4 MB │. │ 5 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/paul15 │ 10.3 MB │. │ 6 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_processed.h5ad │ 24.7 MB │. │ 7 │ /home/phil/Dev/Python/Single Cell/scanpy/.pytest_cache/d/scanpy-data/pbmc3k_raw.h5ad │ 5.9 MB │. ╰───┴────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┴──────────╯. ```. > What was stopping this before? […] why wouldn't we want to download the data everytime? someone implementing the caching, so nothing much really",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3060
https://github.com/scverse/scanpy/pull/3061:48,availability,down,down,48,"For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:24,performance,time,time,24,"For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:50,availability,down,down,50,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:793,availability,error,error,793,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:928,availability,error,error,928,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:444,deployability,log,logic,444,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:695,interoperability,specif,specified,695,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:826,interoperability,specif,specified,826,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:259,modifiability,paramet,parameter,259,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:320,modifiability,pac,packages,320,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:26,performance,time,time,26,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:793,performance,error,error,793,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:928,performance,error,error,928,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:444,safety,log,logic,444,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:793,safety,error,error,793,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:928,safety,error,error,928,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:444,security,log,logic,444,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:444,testability,log,logic,444,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:953,testability,Assert,AssertionError,953,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:352,usability,prefer,preferred,352,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:793,usability,error,error,793,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:928,usability,error,error,928,"> For the above code, the time spent in tSNE went down from 2252 secs to 210 secs due to this PR. What’s the comparison to MulticoreTSNE? ## Defaults. It would probably make sense to use a `flavor: Literal['auto', 'sklearn', 'intelex', 'multicore'] = 'auto'` parameter here, where `auto` would try to import the speedup packages one-by-one and use the preferred one. `use_fast_tsne` could be deprecated and made to default to `None`, with this logic (too bad we can’t use `match` yet). ```py. if use_fast_tsne is not None:. warnings.warn(""..."", FutureWarning). match (use_fast_tsne, flavor):. case (None, 'auto'): ... # try importing 'intelex', fall back to 'sklearn'. case (None, _): ... # use specified flavor. case (True, 'auto'): ... # use 'multicore'. case (True, 'sklearn'): ... # throw error. case (True, _): ... # use specified flavor. case (False, 'auto' | 'sklearn'): ... # Use 'sklearn'. case (False, _): ... # Throw error. case _: ... raise AssertionError(). ```. In the future, we can change `'auto'` to try both intelex and MulticoreTSNE. @ilan-gold what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:228,availability,state,state,228,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:59,deployability,patch,patched,59,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:67,deployability,version,version,67,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:165,deployability,patch,patched,165,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:326,deployability,depend,dependency,326,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:372,deployability,version,version,372,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:67,integrability,version,version,67,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:228,integrability,state,state,228,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:326,integrability,depend,dependency,326,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:372,integrability,version,version,372,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:67,modifiability,version,version,67,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:326,modifiability,depend,dependency,326,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:372,modifiability,version,version,372,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:44,reliability,Doe,Does,44,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:380,reliability,doe,does,380,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:59,safety,patch,patched,59,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:165,safety,patch,patched,165,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:326,safety,depend,dependency,326,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:59,security,patch,patched,59,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:165,security,patch,patched,165,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:326,testability,depend,dependency,326,"This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:230,availability,state,state,230,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:61,deployability,patch,patched,61,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:69,deployability,version,version,69,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:167,deployability,patch,patched,167,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:328,deployability,depend,dependency,328,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:374,deployability,version,version,374,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:69,integrability,version,version,69,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:230,integrability,state,state,230,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:328,integrability,depend,dependency,328,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:374,integrability,version,version,374,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:69,modifiability,version,version,69,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:328,modifiability,depend,dependency,328,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:374,modifiability,version,version,374,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:46,reliability,Doe,Does,46,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:382,reliability,doe,does,382,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:61,safety,patch,patched,61,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:167,safety,patch,patched,167,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:328,safety,depend,dependency,328,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:61,security,patch,patched,61,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:167,security,patch,patched,167,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:328,testability,depend,dependency,328,"> This seems reasonable to me @flying-sheep . Does using the patched version change results over the unpatched @ashish615 i.e., for a given random seed, unpatched and patched are the same? If the two are the same for a given seed/state, then I think what @flying-sheep is proposing could be done separately (even if we make the dependency optional IMO). However, if the new version does change results, we will need the handling that @flying-sheep describes. @ilan-gold , I didn't check that. I will check that and let you guys know.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:12,energy efficiency,optim,optimizations,12,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:206,energy efficiency,Core,Core,206,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:211,energy efficiency,CPU,CPUs,211,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:12,performance,optimiz,optimizations,12,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:181,performance,Parallel,Parallelization,181,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:211,performance,CPU,CPUs,211,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:171,usability,Efficien,Efficient,171,"These t-SNE optimizations are mentioned in the following paper. Adding it here for reference. https://arxiv.org/abs/2212.11506. Accelerating Barnes-Hut t-SNE Algorithm by Efficient Parallelization on Multi-Core CPUs. N Chaudhary, A Pivovar, P Yakovlev, A Gorshkov… - arXiv preprint arXiv:2212.11506, 2022",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:68,deployability,observ,observed,68,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:111,deployability,patch,patch,111,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:270,deployability,patch,patched,270,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:292,deployability,version,versions,292,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:613,deployability,log,logging,613,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:670,deployability,modul,modules,670,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:542,energy efficiency,optim,optimized,542,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:292,integrability,version,versions,292,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:292,modifiability,version,versions,292,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:670,modifiability,modul,modules,670,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:542,performance,optimiz,optimized,542,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:111,safety,patch,patch,111,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:270,safety,patch,patched,270,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:613,safety,log,logging,613,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:670,safety,modul,modules,670,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:111,security,patch,patch,111,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:270,security,patch,patched,270,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:613,security,log,logging,613,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:68,testability,observ,observed,68,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:613,testability,log,logging,613,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:653,usability,learn,learn,653,"Hi @flying-sheep @ilan-gold ,. Based on our previous discussion, we observed that applying and then removing a patch while fixing the seed causes the t-SNE output to change. In our experiment, we used 1.3 million data points to run t-SNE and compared the results of the patched and unpatched versions by examining the KL Divergence from both runs. The results are summarized in the table below. . In the above code use **USE_FIRST_N_CELLS** to set number of records and use sc.tl.tsne(adata, n_pcs=tsne_n_pcs, **use_fast_tsne=False**) to run optimized run with latest commit. You can get KL divergence numbers by logging [kl_divergence_](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html). ![image](https://github.com/scverse/scanpy/assets/1059402/ffef81b0-b0bf-461e-8ad3-b7ce9ba4c361).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:91,energy efficiency,optim,optimized,91,"As can be seen with the KL divergence values in the above table, while the output of Intel optimized t-SNE is different, it is equivalent in quality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:91,performance,optimiz,optimized,91,"As can be seen with the KL divergence values in the above table, while the output of Intel optimized t-SNE is different, it is equivalent in quality.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:58,reliability,doe,does,58,@sanchit-misra @ashish615 one thing that we thought - why does this need to be in `scanpy`? Can't users turn this on/off outside `scanpy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:98,usability,user,users,98,@sanchit-misra @ashish615 one thing that we thought - why does this need to be in `scanpy`? Can't users turn this on/off outside `scanpy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:233,deployability,continu,continued,233,"Notwithstanding the above question, since your method produces different results than the default, we will need to adopt the conventions outlined: https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668. This will ensure continued reproducibility with defaults.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:341,availability,avail,available,341,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:498,deployability,updat,updating,498,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:158,energy efficiency,optim,optimization,158,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:158,performance,optimiz,optimization,158,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:341,reliability,availab,available,341,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:341,safety,avail,available,341,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:498,safety,updat,updating,498,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:341,security,availab,available,341,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:498,security,updat,updating,498,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:203,usability,user,users,203,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/pull/3061:309,usability,user,users,309,"Hi @ilan-gold,. Regarding your thought in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2134651481), we can enable or disable Intel optimization from outside the code. However, users might not be aware of how to use this feature. Instead, if we add it to scanpy directly, all scanpy users will know the same option available. If we agree with the option discussed in this [comment](https://github.com/scverse/scanpy/pull/3061#issuecomment-2114783668 ), I can proceed with updating the t-SNE file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3061
https://github.com/scverse/scanpy/issues/3062:98,deployability,build,building,98,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:286,deployability,depend,dependency,286,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:510,deployability,depend,dependencies,510,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:139,energy efficiency,current,currently,139,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:689,energy efficiency,cloud,cloudpickle,689,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:286,integrability,depend,dependency,286,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:510,integrability,depend,dependencies,510,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:286,modifiability,depend,dependency,286,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:510,modifiability,depend,dependencies,510,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:806,modifiability,deco,decorator,806,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1313,modifiability,pac,packaging,1313,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:286,safety,depend,dependency,286,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:510,safety,depend,dependencies,510,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:882,safety,except,exceptiongroup,882,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:286,testability,depend,dependency,286,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:510,testability,depend,dependencies,510,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:54,usability,document,documentation,54,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:111,usability,document,documentation,111,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1690,usability,learn,learn,1690,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:1820,usability,tool,toolz,1820,"Hi, thanks for the report! Note that the plots in the documentation are generated on the fly when building the documentation. The plot you currently see on https://scanpy.readthedocs.io/en/stable/generated/scanpy.pl.dotplot.html has therefore been created with scanpy 1.10.1. Must be a dependency issue, I’ll try to reproduce with the environment you provided. /edit: I can reproduce it with that environment:. <details><summary>environment.yml</summary>. ```yaml. name: scanpy-3062. channels:. - conda-forge. dependencies:. - ipykernel. - python==3.10.10. - anndata==0.10.7. - scanpy==1.10.1. - IPython==8.13.2. - pillow==10.0.0. - astunparse==1.6.3. - backcall==0.2.0. - cffi==1.15.1. - cloudpickle==2.2.1. - colorama==0.4.4. - cycler==0.10.0. - cytoolz==0.12.0. - dask==2023.10.1. #- dateutil==2.8.2. - decorator==5.1.1. - defusedxml==0.7.1. - dill==0.3.6. - entrypoints==0.4. - exceptiongroup==1.1.1. - executing==1.2.0. - fasteners==0.17.3. - gmpy2==2.1.2. - h5py==3.8.0. #- icu==2.11. - python-igraph==0.11.2. - jedi==0.19.1. - jinja2==3.1.2. - joblib==1.2.0. - kiwisolver==1.4.4. - leidenalg==0.10.2. - llvmlite==0.42.0. - lz4==4.3.2. - markupsafe==2.1.2. - matplotlib==3.8.3. - mpmath==1.3.0. #- msgpack==1.0.5. - natsort==8.3.1. - numba==0.59.1. - numcodecs==0.11.0. - numexpr==2.7.3. - numpy==1.26.4. - packaging==23.1. - pandas==1.5.3. - parso==0.8.3. - pexpect==4.8.0. - pickleshare==0.7.5. - plotly==5.14.1. - prompt_toolkit==3.0.38. - psutil==5.9.5. - ptyprocess==0.7.0. - pure_eval==0.2.2. - pyarrow==10.0.1. - pydot==1.4.2. - pygments==2.15.1. - pyparsing==3.0.9. - pytz==2023.3.post1. - scipy==1.13.0. #- session_info==1.0.0. #- setuptools==67.7.2. - six==1.16.0. - scikit-learn==1.2.2. - stack_data==0.6.2. - sympy==1.11.1. - tblib==1.7.0. - texttable==1.6.7. - threadpoolctl==3.1.0. #- tlz==0.12.0. - toolz==0.11.2. #- pytorch==2.1.1. - tqdm==4.65.0. - traitlets==5.9.0. - wcwidth==0.2.6. #- yaml==5.4.1. - zarr==2.14.2. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:65,deployability,updat,updating,65,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:359,deployability,depend,dependencies,359,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:359,integrability,depend,dependencies,359,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:359,modifiability,depend,dependencies,359,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:89,reliability,doe,does,89,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:65,safety,updat,updating,65,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:359,safety,depend,dependencies,359,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:65,security,updat,updating,65,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:359,testability,depend,dependencies,359,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:516,testability,understand,understanding,516,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:52,usability,confirm,confirm,52,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:148,usability,clear,clear,148,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:263,usability,behavi,behaviour,263,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3062:781,usability,behavi,behaviour,781,"Thanks for the quick response, @flying-sheep! I can confirm that updating _pandas-2.2.2_ does fix this. I totally missed this possibility; it's not clear to me why the dots would change ordering, but the totals wouldn't (maybe _scanpy_ relies on default _pandas_ behaviour that changed between 1.x and 2.x?). That said, _pandas-2.x_ unfortunately breaks some dependencies in our environment, so I'll either pin _scanpy_ or use your workaround. Regarding the ordering and issue title change. Maybe a nit, but it's my understanding that the default ordering is alphabetical (which makese perfect sense as a default!). If this is correct, then I'd suggest that the wrong ordering is not the totals, but the categories themselves. Given this, the workaround that gives me the expected behaviour would be `dp.categories_order = dp.dot_color_df.index.sort_values()`:. <img width=""439"" alt=""image"" src=""https://github.com/scverse/scanpy/assets/5192495/6f7622f5-14b5-4ea5-a44f-288c4507c4f0"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3062
https://github.com/scverse/scanpy/issues/3063:31,performance,time,time,31,I don't think I would have the time in the near future,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:176,availability,cluster,clusterX,176,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:176,deployability,cluster,clusterX,176,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:306,energy efficiency,reduc,reduce,306,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:226,integrability,filter,filter,226,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:90,security,control,control,90,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/issues/3063:90,testability,control,control,90,"It would also be nice to add some stats for vars. Let's say we have aggregated cells from control and stim samples. . For example, the percentage of cells expressing gene A in clusterX for every group sample would allow us to filter genes expressed in so few cells but with relatively high counts. It will reduce the false positives in pseudobulk differential gene expression analysis caused by these genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3063
https://github.com/scverse/scanpy/pull/3069:174,usability,undo,undo,174,"hmm, we could just make the upload conditional to the file existing and merge this into `main`. Then we can debug things as soon as the problem occurs somewhere, and finally undo this PR when commiting the actual fix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:44,deployability,fail,failed,44,"TODO: creation of zarr store conditional on failed test, and then do the upload conditional on file existence",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:44,reliability,fail,failed,44,"TODO: creation of zarr store conditional on failed test, and then do the upload conditional on file existence",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:51,safety,test,test,51,"TODO: creation of zarr store conditional on failed test, and then do the upload conditional on file existence",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/pull/3069:51,testability,test,test,51,"TODO: creation of zarr store conditional on failed test, and then do the upload conditional on file existence",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3069
https://github.com/scverse/scanpy/issues/3073:78,performance,time,time,78,"@AlejandraRodelaRo I am not so familiar with `raw` as it somewhat predates my time on the project. I will say, though, that I don't think there is a copy made of the object when you assign it to raw, so the change makes sense (even if the `raw` name indicates otherwise). And looking at the code, when you assign to `raw` using an already made `AnnData` object, there is no copy made (from what I can tell). Whether or not this is a bug or feature is sort of out of my knowledge base. . cc @flying-sheep",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:250,usability,indicat,indicates,250,"@AlejandraRodelaRo I am not so familiar with `raw` as it somewhat predates my time on the project. I will say, though, that I don't think there is a copy made of the object when you assign it to raw, so the change makes sense (even if the `raw` name indicates otherwise). And looking at the code, when you assign to `raw` using an already made `AnnData` object, there is no copy made (from what I can tell). Whether or not this is a bug or feature is sort of out of my knowledge base. . cc @flying-sheep",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:45,availability,echo,echo,45,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:179,deployability,contain,contains,179,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:468,deployability,version,version,468,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:468,integrability,version,version,468,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:468,modifiability,version,version,468,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:436,usability,help,helpful,436,"Hi all, @flying-sheep @falexwolf . Wanted to echo Alejandro and highlight this is a critical bug, since nearly every function carries a use_raw flag, and the assumption that .raw contains counts is used explicitly or implicitly in numerous scanpy functions. We just realized that a massive dataset we've been processing for ~6 weeks also has no reads in the .raw despite saving it prior to log1p/normalize functions. I am not sure it's helpful, but we see this bug in version scanpy 1.9.8, but in an old dataset/environment with scanpy 1.6.0, .raw correctly preserved counts.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:437,modifiability,layer,layers,437,"My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:620,deployability,API,API,620,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:620,integrability,API,API,620,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1069,integrability,transform,transformations,1069,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:620,interoperability,API,API,620,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1069,interoperability,transform,transformations,1069,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1348,interoperability,convers,conversation,1348,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:811,modifiability,layer,layer,811,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1099,modifiability,layer,layer,1099,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1156,modifiability,layer,layers,1156,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1462,modifiability,pac,package,1462,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1251,reliability,pra,practice,1251,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:492,usability,tool,tools,492,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:999,usability,help,helpful,999,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:1484,usability,tool,tool,1484,"> My opinion would be that you need to write `adata.raw = adata.copy()` if you want a copy to be made, since almost all assignments do not create a copy of the assigned object in anndata. But we should look into whether this is a change that was made deliberately or not. That makes python-sense. This is absolutely a change in convention though, see:. 1. The [original scanpy tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/pbmc3k.html). 2. The [scVI tutorial](https://docs.scvi-tools.org/en/0.6.8/tutorials/scanpy.html) (where they discuss needing to retain counts in raw). 3. Most notably in the [anndata API](https://anndata.readthedocs.io/en/latest/generated/anndata.AnnData.raw.html). In addition, both sc.pl.umap and sc.pl.paga_path() come to mind as functions that default to using the .raw layer. > If we don't change it, we could maybe warn if we're mutating `adata.X` and `adata.raw.X` also refers to the same thing? I think that's a good idea. In general, it would be _very_ helpful to preserve in the anndata structure some record of the major transformations to .X (or any layer). > Overall, I would recommend that you use `adata.layers[""counts""] = adata.X.copy()` instead of using `.raw` at all though. This seems like good practice and the workaround we'll apply for now. I do wonder if some change was made after [this conversation](https://github.com/scverse/scanpy/issues/1798) which you were a part of. Thank you by the way, this package is an amazing tool.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:201,security,modif,modifying,201,"Hello, thank you for your helpful answers. . Could someone please elaborate on when to use .copy() and when it is not needed? . In the original scanpy tutorial I see it in ocasions but not always when modifying adata. . For example: . ![image](https://github.com/scverse/scanpy/assets/64482157/d08f9fee-ac0b-4edd-8fe8-a6405ed0b31b).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:26,usability,help,helpful,26,"Hello, thank you for your helpful answers. . Could someone please elaborate on when to use .copy() and when it is not needed? . In the original scanpy tutorial I see it in ocasions but not always when modifying adata. . For example: . ![image](https://github.com/scverse/scanpy/assets/64482157/d08f9fee-ac0b-4edd-8fe8-a6405ed0b31b).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:71,availability,sli,slices,71,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:121,availability,sli,slicing,121,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:415,availability,sli,slicing,415,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:456,availability,operat,operation,456,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:71,reliability,sli,slices,71,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:121,reliability,sli,slicing,121,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:415,reliability,sli,slicing,415,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:21,security,modif,modify,21,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:137,security,modif,modification,137,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:250,testability,assert,assert,250,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:338,testability,assert,assert,338,"It’s needed when you modify the `AnnData` object afterwards. The above slices it twice, and only then copies it, because slicing isn’t a modification. So what’s happening is:. ```py. adata_orig = AnnData(...). adata_sliced_view = adata_orig[..., :]. assert adata_sliced_view.is_view. adata_sliced_copy = adata_sliced_view[..., :].copy(). assert not adata_sliced_copy.is_view. do_modify(adata_sliced_copy). ```. The slicing could also have been done in one operation. ```py. adata = adata_orig[(adata.obs[""n_genes_by_count""] < 2500) & (adata.obs[""pct_counts_mt""] < 5), :].copy(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:140,integrability,filter,filtering,140,"So, does that mean that every time we apply some kind of filtration (adata = adata[ condition]) we should use .copy()? . For instance, when filtering the highly variable genes (see the image extracted from the scanpy legacy workflow)? . ![image](https://github.com/scverse/scanpy/assets/64482157/e929e440-c093-4571-b0c3-43febd052128).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:161,modifiability,variab,variable,161,"So, does that mean that every time we apply some kind of filtration (adata = adata[ condition]) we should use .copy()? . For instance, when filtering the highly variable genes (see the image extracted from the scanpy legacy workflow)? . ![image](https://github.com/scverse/scanpy/assets/64482157/e929e440-c093-4571-b0c3-43febd052128).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:30,performance,time,time,30,"So, does that mean that every time we apply some kind of filtration (adata = adata[ condition]) we should use .copy()? . For instance, when filtering the highly variable genes (see the image extracted from the scanpy legacy workflow)? . ![image](https://github.com/scverse/scanpy/assets/64482157/e929e440-c093-4571-b0c3-43febd052128).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:4,reliability,doe,does,4,"So, does that mean that every time we apply some kind of filtration (adata = adata[ condition]) we should use .copy()? . For instance, when filtering the highly variable genes (see the image extracted from the scanpy legacy workflow)? . ![image](https://github.com/scverse/scanpy/assets/64482157/e929e440-c093-4571-b0c3-43febd052128).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:224,usability,workflow,workflow,224,"So, does that mean that every time we apply some kind of filtration (adata = adata[ condition]) we should use .copy()? . For instance, when filtering the highly variable genes (see the image extracted from the scanpy legacy workflow)? . ![image](https://github.com/scverse/scanpy/assets/64482157/e929e440-c093-4571-b0c3-43febd052128).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:31,performance,memor,memory,31,"Yeah, that way, you’ll free up memory too, as the full dataset is no longer referenced",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:31,usability,memor,memory,31,"Yeah, that way, you’ll free up memory too, as the full dataset is no longer referenced",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:6,deployability,updat,updated,6,"OK, I updated the docs so the `.copy()` is in there!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:6,safety,updat,updated,6,"OK, I updated the docs so the `.copy()` is in there!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3073:6,security,updat,updated,6,"OK, I updated the docs so the `.copy()` is in there!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3073
https://github.com/scverse/scanpy/issues/3077:13,integrability,filter,filter,13,"You can just filter the `AnnData` object itself, right? `sc.pl.*(adata[:, adata.var['p_adjusted'] < 0.05], ...)`. Please comment if I’m missing something and we can reopen this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3077
https://github.com/scverse/scanpy/issues/3077:49,interoperability,Specif,Specifically,49,"But the figures come from an uns layer of adata. Specifically, I want to plot the result coming from the rank_genes_group method of scanpy. So do I need to add a var column to do like you did above?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3077
https://github.com/scverse/scanpy/issues/3077:33,modifiability,layer,layer,33,"But the figures come from an uns layer of adata. Specifically, I want to plot the result coming from the rank_genes_group method of scanpy. So do I need to add a var column to do like you did above?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3077
https://github.com/scverse/scanpy/pull/3084:106,integrability,topic,topic,106,ignoring flaky tests:. - #3068 . - https://scverse.zulipchat.com/#narrow/stream/393966-scanpy-anndata-dev/topic/Dask.20minimum.20version.20issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:15,safety,test,tests,15,ignoring flaky tests:. - #3068 . - https://scverse.zulipchat.com/#narrow/stream/393966-scanpy-anndata-dev/topic/Dask.20minimum.20version.20issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/pull/3084:15,testability,test,tests,15,ignoring flaky tests:. - #3068 . - https://scverse.zulipchat.com/#narrow/stream/393966-scanpy-anndata-dev/topic/Dask.20minimum.20version.20issue,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3084
https://github.com/scverse/scanpy/issues/3085:123,reliability,doe,doesn,123,"SpaceRanger 2 support has been added in 1.10.0 via #2424. If you see what you see, `path / ""spatial/tissue_positions.csv""` doesn’t exist, otherwise it would have been found.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3085:14,usability,support,support,14,"SpaceRanger 2 support has been added in 1.10.0 via #2424. If you see what you see, `path / ""spatial/tissue_positions.csv""` doesn’t exist, otherwise it would have been found.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3085
https://github.com/scverse/scanpy/issues/3086:98,reliability,doe,doesn,98,Please create a fully reproducible example. I can’t help if I don’t have an `AnnData` object that doesn’t behave like yours.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:52,usability,help,help,52,Please create a fully reproducible example. I can’t help if I don’t have an `AnnData` object that doesn’t behave like yours.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:369,availability,error,error,369,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:920,availability,down,download,920,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:329,integrability,Sub,Subject,329,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:689,integrability,Messag,Message,689,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:689,interoperability,Messag,Message,689,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:194,performance,Time,Time,194,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:369,performance,error,error,369,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:537,reliability,doe,doesn,537,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:369,safety,error,error,369,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:301,security,Auth,Author,301,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:669,security,auth,authored,669,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:369,usability,error,error,369,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:493,usability,help,help,493,"Dear professor&nbsp;Philipp A. Thank you of your patience. I've attached my Anndata and codes in the attachment. Kind regards. . Original Email. . . Sender:""Philipp A.""< ***@***.*** &gt;;. Sent Time:2024/6/7 19:28. To:""scverse/scanpy""< ***@***.*** &gt;;. Cc recipient:""FessenSimon""< ***@***.*** &gt;;""Author""< ***@***.*** &gt;;. Subject:Re: [scverse/scanpy] unexpected error in sc.pl.dpt_timeseries anddpt_groups_pseudotime (Issue #3086). . Please create a fully reproducible example. I can’t help if I don’t have an AnnData object that doesn’t behave like yours. . —. Reply to this email directly, view it on GitHub, or unsubscribe. You are receiving this because you authored the thread.Message ID: ***@***.***&gt;. . 	. 	 		 			从QQ邮箱发来的超大附件 	. 	 		 				 					 						 							 						 					. 					 						 							repro.zip 							 (321.0MB, 2024年7月8日 16:26) 						 						 							进入下载页面 							：https://wx.mail.qq.com/ftn/download?func=3&k=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&key=ca9c3c356e51f263f8ef48353a6462397a35692138646239104c1e410b56560c535b4b025c050314505550571501005a034e055008575700575252015d546b3947061647574a1850457756363f313de49719e585e08cd2a2c51d8b742d5c&code=5cf58db9&from=",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:7,reliability,doe,doesn,7,"Hi, it doesn’t seem like we can open that attachment. Could you please attach this directly from the GitHub UI instead of using QQ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3086:108,usability,UI,UI,108,"Hi, it doesn’t seem like we can open that attachment. Could you please attach this directly from the GitHub UI instead of using QQ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3086
https://github.com/scverse/scanpy/issues/3095:212,deployability,scale,scale,212,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:642,deployability,scale,scale,642,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:212,energy efficiency,scale,scale,212,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:642,energy efficiency,scale,scale,642,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:447,integrability,sub,subsequent,447,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:519,integrability,filter,filtering,519,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:190,modifiability,scal,scaling,190,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:212,modifiability,scal,scale,212,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:311,modifiability,variab,variable-genes,311,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:642,modifiability,scal,scale,642,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:751,modifiability,scal,scaling,751,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:212,performance,scale,scale,212,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:642,performance,scale,scale,642,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:326,safety,detect,detection,326,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:398,safety,detect,detected,398,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:326,security,detect,detection,326,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:398,security,detect,detected,398,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:473,usability,tool,tools,473,"Please ask questions on https://discourse.scverse.org/. See the Note in the 2017 tutorial:. > [!NOTE]. > . > If you don’t proceed below with correcting the data with `sc.pp.regress_out` and scaling it via `sc.pp.scale`, you can also get away without using `.raw` at all. > . > The result of the previous highly-variable-genes detection is stored as an annotation in `.var.highly_variable` and auto-detected by PCA and hence, `sc.pp.neighbors` and subsequent manifold/graph tools. In that case, the step actually do the filtering below is unnecessary, too. Since data sizes these days are big enough that a sparse .X is all but necessary (`pp.scale` densifies data), and methods exist that work with unscaled expression values and therefore don‘t need scaling, people tend to not do it these days.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:69,deployability,contain,contain,69,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:125,deployability,scale,scale,125,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:125,energy efficiency,scale,scale,125,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:125,modifiability,scal,scale,125,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:125,performance,scale,scale,125,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/issues/3095:139,performance,time,time,139,"but we still need to deal with many old singcell data, which may bot contain that many cells or not tat big enough, so can I scale all the time, no matter it is big or small",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3095
https://github.com/scverse/scanpy/pull/3099:101,performance,perform,performing,101,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:183,performance,memor,memory,183,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:190,security,access,access,190,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:101,usability,perform,performing,101,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:183,usability,memor,memory,183,"@ashish615 after doing some benchmarking myself I found out that your solution for `axis=1` is under performing compared to `axis=0` for larger arrays. I think that is because of the memory access pattern you choose. I rewrote the function with that in mind. I'll again make a PR to you, because for some reason you disallow us from making changes to your PR.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3099:128,usability,experien,experience,128,The function should also work for 1 thread. numba.get_num_threads() is fine it works well with the sparse arrays. But I have no experience with it inside of dask.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3099
https://github.com/scverse/scanpy/pull/3100:80,interoperability,conflict,conflicts,80,"Hi, I don’t have push permissions to IntelLabs/scanpy, so I can’t fix the merge conflicts. But you can easily do it yourself. ```bash. # make sure you are doing this from the command line, not e.g. VS Code. git fetch origin main:main. git merge main. git push. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:22,safety,permiss,permissions,22,"Hi, I don’t have push permissions to IntelLabs/scanpy, so I can’t fix the merge conflicts. But you can easily do it yourself. ```bash. # make sure you are doing this from the command line, not e.g. VS Code. git fetch origin main:main. git merge main. git push. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:175,usability,command,command,175,"Hi, I don’t have push permissions to IntelLabs/scanpy, so I can’t fix the merge conflicts. But you can easily do it yourself. ```bash. # make sure you are doing this from the command line, not e.g. VS Code. git fetch origin main:main. git merge main. git push. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:53,deployability,instal,install,53,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:445,deployability,releas,release,445,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:8,interoperability,format,formatting,8,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:299,safety,test,tests,299,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:338,safety,test,tests,338,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:299,testability,test,tests,299,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:338,testability,test,tests,338,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:96,usability,guid,guide,96,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:239,usability,close,closed,239,"to make formatting easier, you should do `pre-commit install` like mentioned in the contributor guide: https://scanpy.readthedocs.io/en/stable/dev/getting-set-up.html#pre-commit. Please also fill out the checklist:. - if there is an issue closed by this, please link it. - you can check the box for tests, since this function already has tests. I added the `benchmark` label so we see that it actually makes things faster. - what’s missing is a release note entry: just edit `1.10.2.md` and add a line there please",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:32,deployability,build,build,32,"Hm, the warning making the docs build fail doesn’t seem to be related. I’ll check if it is after all and merge this tomorrow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:38,deployability,fail,fail,38,"Hm, the warning making the docs build fail doesn’t seem to be related. I’ll check if it is after all and merge this tomorrow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:38,reliability,fail,fail,38,"Hm, the warning making the docs build fail doesn’t seem to be related. I’ll check if it is after all and merge this tomorrow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/pull/3100:43,reliability,doe,doesn,43,"Hm, the warning making the docs build fail doesn’t seem to be related. I’ll check if it is after all and merge this tomorrow",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3100
https://github.com/scverse/scanpy/issues/3102:28,availability,error,error,28,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:28,performance,error,error,28,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:28,safety,error,error,28,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:28,usability,error,error,28,So there is both a plot and error output? That would explain why not all is shown …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:48,availability,error,error,48,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:48,performance,error,error,48,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:48,safety,error,error,48,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:48,usability,error,error,48,@flying-sheep That is correct. There is both an error and the output of the figure without colors in the legend,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:84,deployability,version,versions,84,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:84,integrability,version,versions,84,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:84,modifiability,version,versions,84,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:100,modifiability,pac,packages,100,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:115,safety,test,tested,115,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:115,testability,test,tested,115,"I forgot to mention, additionally the same code executes with no problem with older versions of the packages. I've tested it on anndata = 0.8.0 and scanpy 1.9.3 and it executes fine.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:73,deployability,version,version,73,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:145,deployability,API,API,145,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:180,deployability,api,api,180,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:73,integrability,version,version,73,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:145,integrability,API,API,145,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:180,integrability,api,api,180,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:347,integrability,wrap,wrapper,347,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:145,interoperability,API,API,145,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:180,interoperability,api,api,180,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:347,interoperability,wrapper,wrapper,347,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:73,modifiability,version,version,73,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:89,testability,understand,understand,89,"Hi @flying-sheep! is there a fix for this issue? (besides pinning scanpy version) . as i understand it, matplotlib went back to legend_handles ([API](https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.9.0.html#:~:text=Legend.legendHandles%20was%20undocumented%20and%20has%20been%20renamed%20to%20legend_handles.)) and now the legacy wrapper is breaking.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:41,deployability,releas,release,41,"The fix was done in #2999, but we didn’t release 1.10.2 yet. Does installing scanpy from git work for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:66,deployability,instal,installing,66,"The fix was done in #2999, but we didn’t release 1.10.2 yet. Does installing scanpy from git work for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3102:61,reliability,Doe,Does,61,"The fix was done in #2999, but we didn’t release 1.10.2 yet. Does installing scanpy from git work for you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3102
https://github.com/scverse/scanpy/issues/3103:21,availability,error,error,21,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:21,performance,error,error,21,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:21,safety,error,error,21,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:21,usability,error,error,21,I have an exact same error as well. By dropping one of the samples the issue was gone. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:44,deployability,updat,updates,44,"Duplicate of #2236, please follow there for updates",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:44,safety,updat,updates,44,"Duplicate of #2236, please follow there for updates",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3103:44,security,updat,updates,44,"Duplicate of #2236, please follow there for updates",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3103
https://github.com/scverse/scanpy/issues/3106:137,modifiability,variab,variables,137,"All of this is correct, I think you didn’t take into account that shuffling `var` means shuffling `var.index` and therefore renaming the variables. You should do this instead:. ```py. rna_ann = rna_ann[:, (-rna_ann.var['nCount']).argsort()]. ```. it reorders both `.X` and `.var`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3106
https://github.com/scverse/scanpy/pull/3110:47,usability,help,helpful,47,Thanks for keeping them coming in! It would be helpful if you documented a bit why your newly introduced branch is faster with comments.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:62,usability,document,documented,62,Thanks for keeping them coming in! It would be helpful if you documented a bit why your newly introduced branch is faster with comments.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:10,performance,time,time,10,"ooh, this time the benchmark shows really nicely how much faster it is! > **Ratio**: 0.01 **Benchmark**: preprocessing_log.time_regress_out('pbmc68k_reduced')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:312,deployability,fail,fails,312,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:159,modifiability,variab,variables,159,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:12,performance,time,time,12,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:337,performance,time,time,337,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:312,reliability,fail,fails,312,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:141,testability,regress,regress,141,"> ooh, this time the benchmark shows really nicely how much faster it is! Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:45,usability,close,closer,45,It looks really good. I would love to have a closer look next week,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:320,deployability,fail,fails,320,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:167,modifiability,variab,variables,167,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:14,performance,time,time,14,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:345,performance,time,time,345,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:320,reliability,fail,fails,320,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:402,safety,test,test,402,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:149,testability,regress,regress,149,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:402,testability,test,test,402,"> > ooh, this time the benchmark shows really nicely how much faster it is! > . > Looks like preprocessing_log.time_regress_out('pbmc68k_reduced') , regress out those variables that is not inside it. It should regress_out ['n_counts', 'percent_mito'] instead of [""total_counts"", ""pct_counts_mt""]. For the both commit it fails so report the same time. @flying-sheep , can you look at the this benchmark test?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:62,deployability,fail,fail,62,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:82,modifiability,variab,variables,82,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:62,reliability,fail,fail,62,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:97,reliability,doe,doesn,97,"Hi, everything is OK with the benchmarks, `regress_out` would fail if called with variables that doesn’t exist. The reason these are named differently is here: https://github.com/scverse/scanpy/blob/ad657edfb52e9957b9a93b3a16fc8a87852f3f09/benchmarks/benchmarks/_utils.py#L27-L31. I did that to be able to run benchmarks benchmarks on multiple data sets with the same code.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:155,performance,perform,performance,155,The `to_dense` function only works for csr matrices. I think we need another kernel that handles `csc` or just `.T` the resulting array if csc. I also get performance warnings about the matmul in the numba_kernel. I'll investigate this further.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:155,usability,perform,performance,155,The `to_dense` function only works for csr matrices. I think we need another kernel that handles `csc` or just `.T` the resulting array if csc. I also get performance warnings about the matmul in the numba_kernel. I'll investigate this further.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:53,performance,cach,cache,53,"This will work for csc matrix. ```bash . @numba.njit(cache=True, parallel=True). def to_dense_csc(. shape: tuple[int, int],. indptr: NDArray[np.integer],. indices: NDArray[np.integer],. data: NDArray[DT],. ) -> NDArray[DT]:. """"""\. Numba kernel for np.toarray() function. """""". X = np.empty(shape, dtype=data.dtype). for c in numba.prange(shape[1]):. X[:,c] = 0. for i in range(indptr[c], indptr[c + 1]):. X[indices[i],c] = data[i]. return X. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:65,performance,parallel,parallel,65,"This will work for csc matrix. ```bash . @numba.njit(cache=True, parallel=True). def to_dense_csc(. shape: tuple[int, int],. indptr: NDArray[np.integer],. indices: NDArray[np.integer],. data: NDArray[DT],. ) -> NDArray[DT]:. """"""\. Numba kernel for np.toarray() function. """""". X = np.empty(shape, dtype=data.dtype). for c in numba.prange(shape[1]):. X[:,c] = 0. for i in range(indptr[c], indptr[c + 1]):. X[indices[i],c] = data[i]. return X. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:330,reliability,pra,prange,330,"This will work for csc matrix. ```bash . @numba.njit(cache=True, parallel=True). def to_dense_csc(. shape: tuple[int, int],. indptr: NDArray[np.integer],. indices: NDArray[np.integer],. data: NDArray[DT],. ) -> NDArray[DT]:. """"""\. Numba kernel for np.toarray() function. """""". X = np.empty(shape, dtype=data.dtype). for c in numba.prange(shape[1]):. X[:,c] = 0. for i in range(indptr[c], indptr[c + 1]):. X[indices[i],c] = data[i]. return X. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:41,availability,slo,slower,41,That kernel technically works but is way slower than the default scipy operation due to inefficient memory layout.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:71,availability,operat,operation,71,That kernel technically works but is way slower than the default scipy operation due to inefficient memory layout.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:100,performance,memor,memory,100,That kernel technically works but is way slower than the default scipy operation due to inefficient memory layout.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:41,reliability,slo,slower,41,That kernel technically works but is way slower than the default scipy operation due to inefficient memory layout.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/pull/3110:100,usability,memor,memory,100,That kernel technically works but is way slower than the default scipy operation due to inefficient memory layout.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3110
https://github.com/scverse/scanpy/issues/3113:116,deployability,api,api,116,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:116,integrability,api,api,116,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:116,interoperability,api,api,116,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:49,reliability,Doe,Does,49,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:153,reliability,doe,doesn,153,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:22,usability,experien,experience,22,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:171,usability,support,support,171,"Hi, I don’t have much experience with that data. Does squidpy work better? https://squidpy.readthedocs.io/en/stable/api/squidpy.read.visium.html. scanpy doesn’t have much support for spatial analysis, squidpy is built for it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:30,availability,error,error,30,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:124,availability,error,error,124,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:772,interoperability,format,formatted,772,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:615,modifiability,pac,packages,615,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:30,performance,error,error,30,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:124,performance,error,error,124,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:30,safety,error,error,30,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:124,safety,error,error,124,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:454,security,ident,identifiers,454,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:218,testability,Trace,Traceback,218,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:30,usability,error,error,30,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:124,usability,error,error,124,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/issues/3113:547,usability,Person,Personal,547,"Hi, I tried that and got this error. I think it's because it's recognizing both antibody data and gene data and throwing an error. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[7], line 13. 11 key = get_second_to_last_split(path). 12 print(key). ---> 13 adata = sq.read.visium(path, count_file='filtered_feature_bc_matrix.h5', load_images=True). 15 # Create unique cell identifiers. 16 adata.obs_names = f'sample_{key}_' + adata.obs_names. File /bgfs/alee/LO_LAB/Personal/Alexander_Chang/alc376/envs/popari_env/lib/python3.12/site-packages/squidpy/read/_read.py:67, in visium(path, counts_file, library_id, load_images, source_image_path, **kwargs). 34 """""". 35 Read *10x Genomics* Visium formatted dataset. 36 . (...). 64 - :attr:`anndata.AnnData.uns` ``['spatial']['{library_id}']['metadata']`` - various metadata. 65 """""" # noqa: E501. 66 path = Path(path). ---> 67 adata, library_id = _read_counts(path, count_file=counts_file, library_id=library_id, **kwargs). 69 if not load_images:. 70 return adata. TypeError: squidpy.read._utils._read_counts() got multiple values for keyword argument 'count_file'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3113
https://github.com/scverse/scanpy/pull/3115:44,reliability,doe,does,44,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:62,reliability,doe,doesn,62,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:17,safety,test,tests,17,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:17,testability,test,tests,17,> Skip seurat v3 tests with numpy 2 . Sorry does this mean it doesn't work with numpy 2?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:105,availability,error,error,105,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:74,deployability,releas,release,74,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,deployability,depend,dependencies,234,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:299,deployability,releas,release,299,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:314,deployability,version,versions,314,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:289,energy efficiency,current,currently,289,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,integrability,depend,dependencies,234,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:314,integrability,version,versions,314,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:327,interoperability,incompatib,incompatible,327,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:188,modifiability,pac,packages,188,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:224,modifiability,pac,packages,224,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,modifiability,depend,dependencies,234,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:314,modifiability,version,versions,314,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:105,performance,error,error,105,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:3,reliability,doe,doesn,3,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:174,reliability,doe,doesn,174,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:105,safety,error,error,105,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,safety,depend,dependencies,234,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:234,testability,depend,dependencies,234,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:105,usability,error,error,105,"It doesn’t. We could also. 1. wait to merge this until `skmisc` has a new release or. 2. throw a special error when people try to use seurat v3 with numpy 2. Sadly(?) Python doesn’t allow packages to add constraint to other packages’ dependencies, else we could tell the resolver that all currently release skmisc versions are incompatible with numpy 2",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:44,deployability,releas,release,44,"> wait to merge this until skmisc has a new release. Are we in a rush? We are upper bounding right now anyway on the current release, no? I would just wait.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:125,deployability,releas,release,125,"> wait to merge this until skmisc has a new release. Are we in a rush? We are upper bounding right now anyway on the current release, no? I would just wait.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:117,energy efficiency,current,current,117,"> wait to merge this until skmisc has a new release. Are we in a rush? We are upper bounding right now anyway on the current release, no? I would just wait.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:45,deployability,releas,release,45,We discussed outside @flying-sheep - we will release with the bound then and just wait here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:0,deployability,releas,release,0,"release done, we can wait here …",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/pull/3115:22,deployability,releas,release,22,Looks like there is a release out for the `scikit-misc`: https://github.com/has2k1/scikit-misc/compare/v0.4.0...main. Hopefully this fixes it,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3115
https://github.com/scverse/scanpy/issues/3116:115,availability,down,down,115,"hard to say what could cause that, there are a lot of changes between the two envs. but we might be able to pin it down with that, thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:471,deployability,depend,dependency,471,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:366,energy efficiency,core,core,366,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:471,integrability,depend,dependency,471,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:72,modifiability,pac,packages,72,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:471,modifiability,depend,dependency,471,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:153,safety,compl,complicated,153,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:471,safety,depend,dependency,471,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:153,security,compl,complicated,153,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:471,testability,depend,dependency,471,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:221,usability,stop,stopped,221,@flying-sheep . Thank you so much for your reply! Indeed quite a lot of packages are different between the two environments. . I'm sorry for making this complicated. . The env on my desktop (where the `scrublet` function stopped) is actually newer and at first I thought that would not create huge problems (I recently switched to mamba instead of conda on my Intel-core desktop. . I didn't use the yml from my M2-chip laptop to re-create the environment because of some dependency problems between the Intel/M2 computers).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:155,deployability,version,versions,155,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:291,deployability,version,versions,291,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:155,integrability,version,versions,155,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:291,integrability,version,versions,291,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:155,modifiability,version,versions,155,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:291,modifiability,version,versions,291,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:28,safety,compl,complicated,28,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:28,security,compl,complicated,28,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/issues/3116:228,usability,stop,stopped,228,"> I'm sorry for making this complicated. Not at all, giving us environment files to work with is a big improvement over e.g. typing “scanpy 1.9” into the “versions” box haha! > The env on my desktop (where the scrublet function stopped) is actually newer. yeah, I saw that, all around newer versions of things, which makes this issue especially interesting.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3116
https://github.com/scverse/scanpy/pull/3122:93,deployability,releas,release,93,"please check if my edits made some part worse in your opinion. if you want, you can add some release notes for this :D",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3122
https://github.com/scverse/scanpy/issues/3135:134,deployability,pipelin,pipelines,134,@Intron7 code for below link may work for only csr matrix. . https://github.com/IntelLabs/Open-Omics-Acceleration-Framework/blob/main/pipelines/single-cell-RNA-seq-analysis/notebooks/fastpp.py#L499-L522,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3135
https://github.com/scverse/scanpy/issues/3135:134,integrability,pipelin,pipelines,134,@Intron7 code for below link may work for only csr matrix. . https://github.com/IntelLabs/Open-Omics-Acceleration-Framework/blob/main/pipelines/single-cell-RNA-seq-analysis/notebooks/fastpp.py#L499-L522,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3135
https://github.com/scverse/scanpy/issues/3137:105,energy efficiency,Current,Current,105,Most interesting things would be (from Severin's conversations) would be autocorrelation (via NN graph). Current workflow is to just use squidpy by it would be simple to add/port from squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:49,interoperability,convers,conversations,49,Most interesting things would be (from Severin's conversations) would be autocorrelation (via NN graph). Current workflow is to just use squidpy by it would be simple to add/port from squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:160,testability,simpl,simple,160,Most interesting things would be (from Severin's conversations) would be autocorrelation (via NN graph). Current workflow is to just use squidpy by it would be simple to add/port from squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:113,usability,workflow,workflow,113,Most interesting things would be (from Severin's conversations) would be autocorrelation (via NN graph). Current workflow is to just use squidpy by it would be simple to add/port from squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3137:160,usability,simpl,simple,160,Most interesting things would be (from Severin's conversations) would be autocorrelation (via NN graph). Current workflow is to just use squidpy by it would be simple to add/port from squidpy.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3137
https://github.com/scverse/scanpy/issues/3139:230,deployability,upgrad,upgrade,230,"Umap currently (0.5.4) suppresses that warning, so I guess it’s ok: https://github.com/lmcinnes/umap/blame/master/umap/spectral.py#L532-L536. that was fixed in https://github.com/lmcinnes/umap/pull/1031. You probably just need to upgrade umap to 0.5.4 to no longer see that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:5,energy efficiency,current,currently,5,"Umap currently (0.5.4) suppresses that warning, so I guess it’s ok: https://github.com/lmcinnes/umap/blame/master/umap/spectral.py#L532-L536. that was fixed in https://github.com/lmcinnes/umap/pull/1031. You probably just need to upgrade umap to 0.5.4 to no longer see that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3139:230,modifiability,upgrad,upgrade,230,"Umap currently (0.5.4) suppresses that warning, so I guess it’s ok: https://github.com/lmcinnes/umap/blame/master/umap/spectral.py#L532-L536. that was fixed in https://github.com/lmcinnes/umap/pull/1031. You probably just need to upgrade umap to 0.5.4 to no longer see that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3139
https://github.com/scverse/scanpy/issues/3140:203,availability,cluster,clustering-,203,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:113,deployability,updat,updated,113,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:203,deployability,cluster,clustering-,203,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:122,energy efficiency,current,current,122,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:113,safety,updat,updated,113,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:113,security,updat,updated,113,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3140:246,security,rotat,rotation,246,"I am closing the issue because it was my mistake: I ran the script that I saved several years ago instead of the updated, current one at https://scanpy.readthedocs.io/en/stable/_sources/tutorials/basics/clustering-2017.ipynb. (where the argument rotation is omitted)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3140
https://github.com/scverse/scanpy/issues/3141:139,availability,error,error,139,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:99,deployability,instal,installed,99,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:121,deployability,upgrad,upgrading,121,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:121,modifiability,upgrad,upgrading,121,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:139,performance,error,error,139,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:139,safety,error,error,139,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3141:139,usability,error,error,139,"Should be fixed in scipy 1.11.3: https://github.com/scipy/scipy/issues/18716. You only have 1.10.1 installed. Please try upgrading. If the error persists, feel free to follow up!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3141
https://github.com/scverse/scanpy/issues/3144:37,deployability,Stack,Stackoverflow,37,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:360,deployability,version,version,360,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:599,deployability,instal,install,599,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:360,integrability,version,version,360,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:326,modifiability,pac,package,326,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:360,modifiability,version,version,360,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:29,usability,help,help,29,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3144:734,usability,help,help,734,"I think you could get better help on Stackoverflow or https://discuss.scverse.org/. If `pip` reports “Requirement already satisfied” but scanpy can’t import it, then the environment you run `pip` on is not the same you run scanpy in (or the environment is broken and something caused the metadata to be there while the actual package isn’t). If you run `pip --version`, it should tell you its location. That location will probably be different from `/opt/miniconda3/envs/scanpyenvt/`, so you need to make sure you use the correct pip, either by doing. ```py. /opt/miniconda3/envs/scanpyenvt/bin/pip install ... ```. or by activating it. As said, if you have questions, please go to one of the forums that have a lot of people who can help you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3144
https://github.com/scverse/scanpy/issues/3149:161,security,access,accessing,161,"You can use `mp = rank_genes_groups_matrixplot(..., show=False, return_fig=True)` and then use `mp.get_axes()` to get a dict of axes you can manipulate, e.g. by accessing the xtickmarks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3149
https://github.com/scverse/scanpy/issues/3157:321,reliability,doe,does,321,"@eroell Can you give some context here? The issue is the following lines:. https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L383-L418. Basically, `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` can produce a negative value (it does not consider nans at all since it first calls `x = x[~np.isnan(x)]`). So the last line `np.nan_to_num(dispersion_norm) >= disp_cut_off` produces more genes than you'd expect because `nans` become 0, but you're comparing to a negative value that was calculated without considering said nan-to-0's. So what is the fix here? Converting nans to minus infinity? Converting nans to 0 before getting the nth highest?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:26,testability,context,context,26,"@eroell Can you give some context here? The issue is the following lines:. https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L383-L418. Basically, `disp_cut_off = _nth_highest(dispersion_norm, n_top_genes)` can produce a negative value (it does not consider nans at all since it first calls `x = x[~np.isnan(x)]`). So the last line `np.nan_to_num(dispersion_norm) >= disp_cut_off` produces more genes than you'd expect because `nans` become 0, but you're comparing to a negative value that was calculated without considering said nan-to-0's. So what is the fix here? Converting nans to minus infinity? Converting nans to 0 before getting the nth highest?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:357,deployability,contain,contains,357,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:318,interoperability,specif,specify,318,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:397,modifiability,paramet,parametrize,397,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:186,performance,time,time,186,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:240,reliability,doe,doesn,240,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:208,safety,test,test,208,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:346,safety,input,input,346,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:485,safety,Test,Test,485,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:18,testability,simpl,simply,18,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:208,testability,test,test,208,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:485,testability,Test,Test,485,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:611,testability,assert,assert,611,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:708,testability,assert,assert,708,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:18,usability,simpl,simply,18,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:346,usability,input,input,346,"yeah, a fix could simply be. ```diff. -return np.nan_to_num(dispersion_norm) >= disp_cut_off. +return np.nan_to_num(dispersion_norm, nan=-np.inf) >= disp_cut_off. ```. but I have a hard time coming up with a test. Doing something like this doesn’t work, as it crashes earlier,. with something like “ValueError: cannot specify integer `bins` when input data contains infinity”. ```py. @pytest.mark.parametrize(""flavor"", [""seurat"", ""cell_ranger""]). def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:16,availability,slo,slow,16,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:450,deployability,contain,contains,450,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:608,deployability,fail,fails,608,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:637,deployability,version,version,637,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:637,integrability,version,version,637,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:413,interoperability,specif,specify,413,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:637,modifiability,version,version,637,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:16,reliability,slo,slow,16,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:608,reliability,fail,fails,608,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:384,safety,test,test,384,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:439,safety,input,input,439,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:483,safety,test,test,483,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:578,safety,test,test,578,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:691,safety,Test,Test,691,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:384,testability,test,test,384,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:483,testability,test,test,483,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:578,testability,test,test,578,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:691,testability,Test,Test,691,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:829,testability,assert,assert,829,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:994,testability,assert,assert,994,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:439,usability,input,input,439,"Sorry for being slow here - not sure how I got the mention as this part of hvg I have not contributed to in the past but happy to give my 5 cents to this. > This occurs on these two datasets:. I think you only linked one? Which is enough as I assume it is only the constant-gene case which is causing this issue, which is indeed present just as you showed in this dataset. **Making a test**. > ValueError: cannot specify integer bins when input data contains infinity”. I think this test is missing `sc.pp.normalize_total` and `sc.pp.log1p` for `flavor=""seurat”`. The following test passes with the fix, and fails with the unfixed prior version. ```py. def test_no_filter_genes(flavor):. """"""Test that even with 0 columns in the data, n_top_genes is respected."""""". adata = sc.datasets.pbmc3k(). means, _ = _get_mean_var(adata.X). assert (means == 0).any(). sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). assert adata.var[""highly_variable""].sum() == 10000. test_no_filter_genes(""seurat""). ```. Happy to make this PR. Below second comment on follow up issue...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:816,availability,down,downloaded,816,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:977,deployability,scale,scale,977,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1078,deployability,patch,patchwork,1078,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1278,deployability,Log,LogNormalize,1278,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1293,deployability,scale,scale,1293,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:977,energy efficiency,scale,scale,977,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1293,energy efficiency,scale,scale,1293,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:977,modifiability,scal,scale,977,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1293,modifiability,scal,scale,1293,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1412,modifiability,Variab,VariableFeatures,1412,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1528,modifiability,variab,variable,1528,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:977,performance,scale,scale,977,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1293,performance,scale,scale,1293,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:24,safety,detect,detect,24,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1078,safety,patch,patchwork,1078,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1278,safety,Log,LogNormalize,1278,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:24,security,detect,detect,24,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1078,security,patch,patchwork,1078,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1278,security,Log,LogNormalize,1278,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:1278,testability,Log,LogNormalize,1278,"The data also allows to detect a next issue: When multiple genes have the same value of `disp_cut_off`. Can be found if here e.g. dont do `sc.pp.normalize_total`:. ```py. import scanpy as as. adata = sc.datasets.pbmc3k(). # sc.pp.normalize_total(adata, target_sum=10000). sc.pp.log1p(adata). sc.pp.highly_variable_genes(adata, flavor=flavor, n_top_genes=10000). adata.var[""highly_variable""].sum(). ```. ```. 10367. ```. Which is due to many genes having the value selected for the `disp_cut_off` here, having . ...`x[n-2]` = `x[n-1 ]` = `x[n]` = `x[n+1] `= `x[n+2]`... https://github.com/scverse/scanpy/blob/b918a23eb77462837df90d7b3a30a573989d4d48/src/scanpy/preprocessing/_highly_variable_genes.py#L408-L418. I tried to check how Seurat is proceeding in such a case, expecting to see how it breaks the ties. (data downloaded from [here](https://cf.10xgenomics.com/samples/cell/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz)). Here I'm actually not sure how to turn off the `scale.factor` argument? Its set to 10'000 by default. ```R. library(dplyr). library(Seurat). library(patchwork). pbmc.data <- Read10X(data.dir = ""filtered_gene_bc_matrices/hg19/""). pbmc <- CreateSeuratObject(counts = pbmc.data, project = ""pbmc3k""). pbmc <- NormalizeData(pbmc, normalization.method = ""LogNormalize"", scale.factor=10000). pbmc <- FindVariableFeatures(pbmc, selection.method = ""mean.var.plot"", nfeatures = 10000). length(VariableFeatures(pbmc)). ```. ```. 2292. ```. However, it turns out Seurat seems to restrict to the genes which are variable in the sense of passing the set mean threshold and normalized dispersion thresholds. These thresholds are ignored in scanpy if the number of genes is given. So not really an insight of how to break ties in this case. Would suggest to make a new issue, which the potential project on comparing the frameworks could address.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:46,deployability,fail,fails,46,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:75,deployability,version,version,75,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:75,integrability,version,version,75,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:289,interoperability,specif,specified,289,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:75,modifiability,version,version,75,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:46,reliability,fail,fails,46,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:16,safety,test,test,16,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:454,security,ident,identical,454,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:479,security,ident,identical,479,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3157:16,testability,test,test,16,"> The following test passes with the fix, and fails with the unfixed prior version. Ah, with `normalize_total`, it works with `seurat`, thank you! > When multiple genes have the same value of `disp_cut_off`. I think when the n-th highest value is tied with others, returning more than the specified number makes total sense. As done by [`scipy.stats.rankdata`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rankdata.html), the rank of identical data points is identical. So the “values up to the 4th-highest” of the array `[6,5,3,3,3,1,0]` are `[6,5,3,3,3]`, not `[6,5,3,3]`. It makes no sense to include fewer than all of the 3s here.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3157
https://github.com/scverse/scanpy/issues/3159:193,integrability,filter,filtering,193,> I will also try to implement these changes. that’s always very welcome! Some tips:. 1. generally we use fractions instead of percentages. 2. which of these features can be implemented by pre-filtering genes? we’ll probably prefer doing the filtering separately if this applies for any.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3159
https://github.com/scverse/scanpy/issues/3159:242,integrability,filter,filtering,242,> I will also try to implement these changes. that’s always very welcome! Some tips:. 1. generally we use fractions instead of percentages. 2. which of these features can be implemented by pre-filtering genes? we’ll probably prefer doing the filtering separately if this applies for any.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3159
https://github.com/scverse/scanpy/issues/3159:79,usability,tip,tips,79,> I will also try to implement these changes. that’s always very welcome! Some tips:. 1. generally we use fractions instead of percentages. 2. which of these features can be implemented by pre-filtering genes? we’ll probably prefer doing the filtering separately if this applies for any.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3159
https://github.com/scverse/scanpy/issues/3159:225,usability,prefer,prefer,225,> I will also try to implement these changes. that’s always very welcome! Some tips:. 1. generally we use fractions instead of percentages. 2. which of these features can be implemented by pre-filtering genes? we’ll probably prefer doing the filtering separately if this applies for any.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3159
https://github.com/scverse/scanpy/issues/3160:1056,availability,mask,mask,1056,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:1132,availability,mask,mask,1132,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:0,deployability,updat,update,0,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:9,deployability,manag,managed,9,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:68,deployability,log,logic,68,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:9,energy efficiency,manag,managed,9,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:0,safety,updat,update,0,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:9,safety,manag,managed,9,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:68,safety,log,logic,68,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:1518,safety,input,input,1518,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:0,security,updat,update,0,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:68,security,log,logic,68,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:68,testability,log,logic,68,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:1459,usability,support,supports,1459,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/issues/3160:1518,usability,input,input,1518,"update:. managed to get a confidence thresholding with this type of logic:. ```py. def _knn_classify(self, labels):. # ensure it's categorical. cat_array: pd.Series = self._adata_ref.obs[labels].astype(""category""). values = []. confidences = []. for inds in self._indices:. mode_value = cat_array.iloc[inds].mode()[0]. mode_count = (cat_array.iloc[inds] == mode_value).sum(). confidence = mode_count / len(inds). values.append(mode_value). confidences.append(confidence). . # Create a DataFrame for better readability. classification_df = pd.DataFrame({. ""Mode Values"": values,. ""Confidences"": confidences. }). print(classification_df). return pd.Categorical(values=values, categories=cat_array.cat.categories), np.array(confidences). def map_labels(self, labels, method, confidence_threshold: float = 0.5):. """"""\. Map labels of `adata` to `adata_new`. This function infers `labels` for `adata_new.obs`. from existing labels in `adata.obs`. `method` can be only 'knn'. """""". if method == ""knn"":. classified_labels, confidences = self._knn_classify(labels). mask = confidences >= confidence_threshold. . filtered_labels = [. label if mask[idx] else np.nan . for idx, label in enumerate(classified_labels). ]. . classified_labels = pd.Categorical(. filtered_labels,. categories=classified_labels.categories. ). . self._adata_new.obs[labels] = classified_labels. self._adata_new.obs[labels + '_confidence'] = confidences. else:. raise NotImplementedError(""Ingest supports knn labeling for now.""). ```. . would love to get input on whether or not this makes sense.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3160
https://github.com/scverse/scanpy/pull/3162:102,safety,compl,complicated,102,Sorry what is the provenance of this fix? Why isn't the fix something in AnnData? This seems somewhat complicated,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:102,security,compl,complicated,102,Sorry what is the provenance of this fix? Why isn't the fix something in AnnData? This seems somewhat complicated,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:138,interoperability,specif,specific,138,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:12,modifiability,concern,concerned,12,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:56,reliability,doe,doesn,56,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:157,reliability,doe,doesn,157,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:32,safety,compl,complexity,32,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:207,safety,test,test,207,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:256,safety,test,test,256,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:32,security,compl,complexity,32,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:12,testability,concern,concerned,12,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:207,testability,test,test,207,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:256,testability,test,test,256,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:316,testability,simpl,simply,316,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:165,usability,support,support,165,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:261,usability,help,helpers,261,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:316,usability,simpl,simply,316,"Yeah, I was concerned about the complexity. But AnnData doesn’t do anything wrong, it just uses chunks in both directions, which that one specific algorithm doesn’t support. But I think in general we should test for 2D chunks, that’s why I think AnnData’s test helpers work as intended. Any idea how to do this more simply?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:445,deployability,fail,fail,445,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:183,modifiability,paramet,parameters,183,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:445,reliability,fail,fail,445,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:168,safety,compl,complexity,168,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:168,security,compl,complexity,168,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:204,testability,simpl,simplify,204,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:204,usability,simpl,simplify,204,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:505,usability,prefer,prefer,505,"I’m not sure why it came up now, I saw changes to the chunking in https://github.com/scverse/anndata/pull/1550 and assumed that introduced it, but maybe not. regarding complexity and parameters, we could simplify things by doing. ```py. def maybe_rechunk_1d(a: NDArray | DaskArray | ...) -> NDArray | DaskArray | ...:. if isinstance(a, DaskArray):. return a.rechunk((a.chunksize[0], -1)). return a. ```. and using that in all the functions that fail (after running things through `array_type`). Would you prefer that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:146,deployability,version,versions,146,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:233,deployability,API,API,233,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:146,integrability,version,versions,146,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:233,integrability,API,API,233,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:233,interoperability,API,API,233,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:146,modifiability,version,versions,146,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:176,modifiability,paramet,parameter,176,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:124,safety,test,test,124,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:2,testability,simpl,simplified,2,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:124,testability,test,test,124,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:2,usability,simpl,simplified,2,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3162:88,usability,help,helper,88,"I simplified this quite a bit. I decided against blocking this on an upstream `anndata` helper for multiple reasons:. 1. we test on older anndata versions that won’t have that parameter immediately. 2. needs some designing, e.g. the API should be able to do “use `ceil(shape[0] / 2)` as chunk size for dim 0, and `-1` (=full size) for dim 1”. 3. it would make no sense for the non-dask array types, should we still add it for them?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3162
https://github.com/scverse/scanpy/pull/3167:212,deployability,releas,released,212,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:342,deployability,instal,installing,342,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:366,deployability,version,version,366,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:562,deployability,fail,failing,562,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:647,deployability,releas,released,647,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:366,integrability,version,version,366,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:423,interoperability,compatib,compatibility,423,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:366,modifiability,version,version,366,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:562,reliability,fail,failing,562,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:804,reliability,doe,does,804,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:505,safety,test,tests,505,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:680,safety,test,test,680,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:505,testability,test,tests,505,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:680,testability,test,test,680,"Hi, that certainly seems like an improvement! I took the liberty to split out two bugs: #3168 and #3169. We had a similar fix #2875, which is hidden behind a `ctrl_as_ref` flag. I think since that fix is not yet released, we should rename the flag and unify both fixes behind it. Could you please. 1. check if issue #3169 is already fixed by installing scanpy’s git version and setting `ctrl_as_ref=True`. 2. Our backwards compatibility means that changes to the scoring need to be optional. This is why `tests/test_score_genes.py::test_score_with_reference` is failing here, and that’s what `ctrl_as_ref` is for. 	So since that option is not yet released and in order to fix the test, we should probably change that option to incorporate both improvements. We can rename it to reflect the two things it does.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:25,deployability,instal,installed,25,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:48,deployability,version,version,48,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:48,integrability,version,version,48,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:257,interoperability,specif,specific,257,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:48,modifiability,version,version,48,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:107,reliability,doe,does,107,"Hi, . Thank you! 1. I've installed scanpy's git version and set ctrl_as_ref=True with the same results, it does not fix https://github.com/scverse/scanpy/issues/3169. 2. I am not entirely sure what you mean here, would you mind elaborating? This bug fix is specific to the way score_genes() ranks the genes into bins & when there's a lot of zero expression in cells, I'm a bit unsure how this connects to ctrl_as_ref and what you would like me to do. . Thanks again",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:328,availability,consist,consistent,328,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:881,availability,degrad,degraded,881,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:64,deployability,fail,failing,64,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:237,deployability,version,versions,237,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:237,integrability,version,versions,237,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:396,integrability,event,eventually,396,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:495,integrability,Event,Eventually,495,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:237,modifiability,version,versions,237,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:1180,modifiability,layer,layer,1180,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:1186,modifiability,layer,layer,1186,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:64,reliability,fail,failing,64,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:881,reliability,degrad,degraded,881,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:50,safety,test,test,50,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:98,safety,test,test,98,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:104,safety,test,tests,104,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:276,safety,test,test,276,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:726,safety,test,test,726,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:950,safety,test,test,950,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:1021,safety,test,test,1021,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:50,testability,test,test,50,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:98,testability,test,test,98,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:104,testability,test,tests,104,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:276,testability,test,test,276,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:726,testability,test,test,726,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:950,testability,test,test,950,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:1021,testability,test,test,1021,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:1349,testability,assert,assert,1349,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:328,usability,consist,consistent,328,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:530,usability,behavi,behavior,530,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:898,usability,behavi,behavior,898,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:920,usability,behavi,behavior,920,"Sure, I’ll happily elaborate! As you can see, our test suite is failing. That’s because we have a test `tests/test_score_genes.py::test_score_with_reference` which checks if the scores emitted by the functions are exactly equal to older versions of the function. We have that test because we’d like people to be able to rely on consistent calculations. Now of course we’d also like to fix things eventually, so we’d implement your fix behind an option (so people have to opt-in to the changes). Eventually, we’d switch to the new behavior (likely scanpy 2.0). That’s why I propose to rename the `ctrl_as_ref` option and use it to gate both the change it already affects as well as your change. ----. Another thing: We need to test that this works as intended. Can you create a reproducer with built-in datasets (or synthetic data that you create using `numpy`) that would show the degraded binning behavior with the old behavior? We could then add a test like this:. ```py. def test_score_genes():. adata = TODO # create test data here. gene_list = TODO. gene_pool = TODO. gene_list, gene_pool, get_subset = _check_score_genes_args(. adata, gene_list, gene_pool, use_raw=use_raw, layer=layer. ). bins = list(_score_genes_bins(. gene_list,. gene_pool,. ctrl_as_ref=False, # needs to be renamed. ctrl_size=50,. n_bins=25,. get_subset=get_subset,. )). assert 0 not in map(len, bins). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:120,reliability,diagno,diagnostic,120,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:131,safety,test,tests,131,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:120,testability,diagno,diagnostic,120,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:131,testability,test,tests,131,"Hi! Here is the source code with data [Nestorowa et al., 2016](https://doi.org/10.1182/blood-2016-05-716480) with added diagnostic tests to produce these results. https://github.com/gmvaccaro/scanpy.tl.score_genes_fix/blob/main/score_genes_diagnostics_tests2.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:6,energy efficiency,adapt,adapted,6,"Hm, I adapted your reproducer to use scanpy 1.10.3’s code and it doesn’t seem to be an issue: https://gist.github.com/flying-sheep/b2ae449ab70a9358e07a82f284de5dca#file-score_genes_diagnostics_tests2-ipynb. I’m going to assume that this is fixed in 1.10.3. If you can reproduce it with 1.10.3, we can reopen it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:6,integrability,adapt,adapted,6,"Hm, I adapted your reproducer to use scanpy 1.10.3’s code and it doesn’t seem to be an issue: https://gist.github.com/flying-sheep/b2ae449ab70a9358e07a82f284de5dca#file-score_genes_diagnostics_tests2-ipynb. I’m going to assume that this is fixed in 1.10.3. If you can reproduce it with 1.10.3, we can reopen it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:6,interoperability,adapt,adapted,6,"Hm, I adapted your reproducer to use scanpy 1.10.3’s code and it doesn’t seem to be an issue: https://gist.github.com/flying-sheep/b2ae449ab70a9358e07a82f284de5dca#file-score_genes_diagnostics_tests2-ipynb. I’m going to assume that this is fixed in 1.10.3. If you can reproduce it with 1.10.3, we can reopen it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:6,modifiability,adapt,adapted,6,"Hm, I adapted your reproducer to use scanpy 1.10.3’s code and it doesn’t seem to be an issue: https://gist.github.com/flying-sheep/b2ae449ab70a9358e07a82f284de5dca#file-score_genes_diagnostics_tests2-ipynb. I’m going to assume that this is fixed in 1.10.3. If you can reproduce it with 1.10.3, we can reopen it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/pull/3167:65,reliability,doe,doesn,65,"Hm, I adapted your reproducer to use scanpy 1.10.3’s code and it doesn’t seem to be an issue: https://gist.github.com/flying-sheep/b2ae449ab70a9358e07a82f284de5dca#file-score_genes_diagnostics_tests2-ipynb. I’m going to assume that this is fixed in 1.10.3. If you can reproduce it with 1.10.3, we can reopen it!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3167
https://github.com/scverse/scanpy/issues/3169:111,reliability,doe,doesn,111,"@gmvaccaro can you please create a minimal reproducible example? Running the following with your test_data.had doesn’t reproduce the problem:. ```py. adata = sc.read(""test_data.h5ad""). sc.tl.score_genes(adata, adata.var_names[:10]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3169
https://github.com/scverse/scanpy/issues/3169:35,usability,minim,minimal,35,"@gmvaccaro can you please create a minimal reproducible example? Running the following with your test_data.had doesn’t reproduce the problem:. ```py. adata = sc.read(""test_data.h5ad""). sc.tl.score_genes(adata, adata.var_names[:10]). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3169
https://github.com/scverse/scanpy/pull/3180:201,availability,robust,robust,201,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:201,reliability,robust,robust,201,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:184,safety,test,test,184,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:201,safety,robust,robust,201,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:24,testability,context,context,24,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:159,testability,simpl,simple,159,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:184,testability,test,test,184,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:159,usability,simpl,simple,159,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:375,usability,help,helpful,375,"Thanks! A little bit of context. We needed this aggregation for one of the projects using pseudobulks of the data. We could use scanpy aggregation methods for simple averaging, but to test the outlier-robust median aggregation, we had to write our code. scanpy didn't have it for some reason, so @farhadmd7 kindly agreed to contribute here. Perhaps someone else will find it helpful, too. @eroell, what do you think?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:351,deployability,releas,release,351,"Hi, thanks for the contribution! The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help? This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:100,usability,support,support,100,"Hi, thanks for the contribution! The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help? This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:181,usability,learn,learn,181,"Hi, thanks for the contribution! The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help? This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:194,usability,learn,learn,194,"Hi, thanks for the contribution! The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help? This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:324,usability,help,help,324,"Hi, thanks for the contribution! The converting to dense is quite iffy, we should probably add real support for sparse here. [We could use this as a base](https://github.com/scikit-learn/scikit-learn/blob/45cf8ec555a026c4263e8bef12850755a83df10e/sklearn/utils/sparsefuncs.py#L685). Do you think you can do that or should we help? This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:89,safety,test,test,89,"> @eroell, what do you think? See Phil's comment above, one more thing would be to add a test I suppose. If you want to try Phil's comments yourself @farhadmd7 please go ahead, else you can write here for more help as Phil mentioned!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:89,testability,test,test,89,"> @eroell, what do you think? See Phil's comment above, one more thing would be to add a test I suppose. If you want to try Phil's comments yourself @farhadmd7 please go ahead, else you can write here for more help as Phil mentioned!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:210,usability,help,help,210,"> @eroell, what do you think? See Phil's comment above, one more thing would be to add a test I suppose. If you want to try Phil's comments yourself @farhadmd7 please go ahead, else you can write here for more help as Phil mentioned!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:127,deployability,automat,automatically,127,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:35,safety,test,test,35,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:141,safety,test,tests,141,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:160,safety,test,tests,160,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:247,safety,test,tests,247,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:330,safety,test,tests,330,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:416,safety,test,tests,416,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:498,safety,test,tests,498,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:576,safety,test,tests,576,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:657,safety,test,tests,657,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:744,safety,test,tests,744,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:827,safety,test,tests,827,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:35,testability,test,test,35,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:127,testability,automat,automatically,127,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:141,testability,test,tests,141,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:160,testability,test,tests,160,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:247,testability,test,tests,247,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:330,testability,test,tests,330,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:416,testability,test,tests,416,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:498,testability,test,tests,498,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:576,testability,test,tests,576,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:657,testability,test,tests,657,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:744,testability,test,tests,744,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:827,testability,test,tests,827,"> one more thing would be to add a test I suppose. Already covered in by merging #3186. This way, adding `""median""` to AggType automatically tests it:. ```. …. tests/test_aggregated.py::test_aggregate_vs_pandas[median-numpy_ndarray] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csr] PASSED [ 1%]. tests/test_aggregated.py::test_aggregate_vs_pandas[median-scipy_csc] PASSED [ 1%]. …. tests/test_aggregated.py::test_aggregate_axis[median-numpy_ndarray] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csr] PASSED [ 2%]. tests/test_aggregated.py::test_aggregate_axis[median-scipy_csc] PASSED [ 2%]. …. tests/test_aggregated.py::test_aggregate_arraytype[median-numpy_ndarray] PASSED [ 3%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csr] PASSED [ 4%]. tests/test_aggregated.py::test_aggregate_arraytype[median-scipy_csc] PASSED [ 4%]. …. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:225,modifiability,refact,refactor,225,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:225,performance,refactor,refactor,225,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:72,safety,test,tests,72,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:161,safety,test,tests,161,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:72,testability,test,tests,72,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:161,testability,test,tests,161,"Thanks to everyone who commented here. Hey @flying-sheep, it passes the tests in https://github.com/scverse/scanpy/blob/e285c0f6ec77631d14d748d0927d38aae4391886/tests/test_aggregated.py. please let me know if I should fix or refactor anything. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3180:135,deployability,releas,release,135,"Hi, sorry for getting back so late, I was alternatingly really busy and sick. This looks nice! One more thing:. > This is also missing release notes in 1.11.0.md",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3180
https://github.com/scverse/scanpy/pull/3181:284,interoperability,share,share,284,"Hi! Thank you for your contribution! > Vector images would be rasterized when settings._vector_friendly is True. Yes, that’s intentional, and that’s how `vector_friendly` is documented. We won’t invert its behavior, but if you have a recommendation on how to improve the docs, please share!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3181
https://github.com/scverse/scanpy/pull/3181:174,usability,document,documented,174,"Hi! Thank you for your contribution! > Vector images would be rasterized when settings._vector_friendly is True. Yes, that’s intentional, and that’s how `vector_friendly` is documented. We won’t invert its behavior, but if you have a recommendation on how to improve the docs, please share!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3181
https://github.com/scverse/scanpy/pull/3181:206,usability,behavi,behavior,206,"Hi! Thank you for your contribution! > Vector images would be rasterized when settings._vector_friendly is True. Yes, that’s intentional, and that’s how `vector_friendly` is documented. We won’t invert its behavior, but if you have a recommendation on how to improve the docs, please share!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3181
https://github.com/scverse/scanpy/pull/3196:24,safety,test,test,24,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:175,security,access,access,175,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:24,testability,test,test,24,"Not exactly sure how to test this - it's not that the axis is misordered, it's that we were not informing the violin plot of this ordering. I am not sure if there is a way to access the underlying data of a plot...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:99,deployability,version,versions,99,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:99,integrability,version,versions,99,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:198,interoperability,specif,specifies,198,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:99,modifiability,version,versions,99,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:20,usability,experien,experience,20,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:193,usability,user,user,193,"I have some limited experience with that plot order stuff. There’s some compat code for old pandas versions added in #2816 which shows some spots where we mess with ordering. Generally. - when user specifies an order, we use that. - if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:972,availability,avail,avail,972,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:695,deployability,API,API,695,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:807,deployability,releas,release,807,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:695,integrability,API,API,695,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:228,interoperability,specif,specifies,228,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:695,interoperability,API,API,695,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:860,safety,test,testing,860,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:972,safety,avail,avail,972,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:860,testability,test,testing,860,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:174,usability,minim,minimally,174,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:223,usability,user,user,223,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:671,usability,user,user-facing,671,"@flying-sheep I think the [code added in that PR](https://github.com/scverse/scanpy/pull/2816/files#diff-5d0e683154209be7830f09b5389551bf9700a4184d08e97c46c23e2e4beb54a0) is minimally relevant to what happened here. > when user specifies an order, we use that. Right, so here the issue is that the category ordering is used for the labelling but we were not imposing it on the data itself when the violin plots render (separate from the axis labels, as the actual violin plots are added row-by-row). > if not, we rely on the DataFrame order for plotting, we don’t store this implicit order explicitly. In some sense the above also applies. If we want to add some sort of user-facing part of the API to allow for ordering, that is fine, but I think that should be separate as it would go into the next minor release and this is a fairly large bug. I'm fine not testing this because I genuinely don't know how and I spent a few hours yesterday trying different things to no avail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:364,deployability,API,API,364,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:357,integrability,pub,public,357,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:364,integrability,API,API,364,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:364,interoperability,API,API,364,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:54,safety,test,test,54,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:105,safety,test,test,105,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:4,security,trust,trust,4,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:54,testability,test,test,54,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:105,testability,test,test,105,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:24,usability,help,helps,24,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:77,usability,behavi,behavior,77,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/pull/3196:251,usability,help,help,251,"> I trust you that this helps 🤷. I guess we can add a test that cements this behavior, but it's tough to test that swap=original-transpose for the underlying data. I tried applying the ordering to what changed in the PR you referenced but that didn't help unfortunately. I don't know the provenance of that change, so I think this is fair. We are using the public API of seaborn in a way that fixes the underlying issue as one would expect.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3196
https://github.com/scverse/scanpy/issues/3199:119,performance,memor,memory,119,"I made a sketch for an implementation in https://github.com/scverse/scanpy/pull/3204, but aggregate only works with in-memory data. Might be a good idea to fix that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3199
https://github.com/scverse/scanpy/issues/3199:119,usability,memor,memory,119,"I made a sketch for an implementation in https://github.com/scverse/scanpy/pull/3204, but aggregate only works with in-memory data. Might be a good idea to fix that!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3199
https://github.com/scverse/scanpy/issues/3201:406,usability,user,user-attachments,406,"Could you provide a code sample to reproduce the problem you are seeing or provide data (ideally both)? ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata, adata.var.index[0:20], groupby=""bulk_labels"", standard_scale=""var"", dendrogram='dendrogram_leiden'). ```. Seems to work for me:. <img width=""776"" alt=""Screenshot 2024-08-07 at 16 58 01"" src=""https://github.com/user-attachments/assets/41468626-a013-485e-b074-81817664177b"">",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201
https://github.com/scverse/scanpy/issues/3201:518,security,jwt,jwt,518,"> Could you provide a code sample to reproduce the problem you are seeing or provide data (ideally both)? > . > ```python. > import scanpy as sc. > adata = sc.datasets.pbmc68k_reduced(). > sc.pl.dotplot(adata, adata.var.index[0:20], groupby=""bulk_labels"", standard_scale=""var"", dendrogram='dendrogram_leiden'). > ```. > . > Seems to work for me: <img alt=""Screenshot 2024-08-07 at 16 58 01"" width=""776"" src=""https://private-user-images.githubusercontent.com/43999641/355985530-41468626-a013-485e-b074-81817664177b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM3MDgwNTEsIm5iZiI6MTcyMzcwNzc1MSwicGF0aCI6Ii80Mzk5OTY0MS8zNTU5ODU1MzAtNDE0Njg2MjYtYTAxMy00ODVlLWIwNzQtODE4MTc2NjQxNzdiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODE1VDA3NDIzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkxMjdlMGIzYjI3MmEzNDY3MzY0ZGE2YmNjOTY5ZjBmY2U3Zjc0ODI3NGVhMzBjYTIyYWU5YTQxZjU0M2EyMjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.cmuUZwerBK_cHT6cMebT8qynHYnF0-4s6Q7eyXOEn4I"">. Thank you for your help, it works now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201
https://github.com/scverse/scanpy/issues/3201:424,usability,user,user-images,424,"> Could you provide a code sample to reproduce the problem you are seeing or provide data (ideally both)? > . > ```python. > import scanpy as sc. > adata = sc.datasets.pbmc68k_reduced(). > sc.pl.dotplot(adata, adata.var.index[0:20], groupby=""bulk_labels"", standard_scale=""var"", dendrogram='dendrogram_leiden'). > ```. > . > Seems to work for me: <img alt=""Screenshot 2024-08-07 at 16 58 01"" width=""776"" src=""https://private-user-images.githubusercontent.com/43999641/355985530-41468626-a013-485e-b074-81817664177b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM3MDgwNTEsIm5iZiI6MTcyMzcwNzc1MSwicGF0aCI6Ii80Mzk5OTY0MS8zNTU5ODU1MzAtNDE0Njg2MjYtYTAxMy00ODVlLWIwNzQtODE4MTc2NjQxNzdiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODE1VDA3NDIzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkxMjdlMGIzYjI3MmEzNDY3MzY0ZGE2YmNjOTY5ZjBmY2U3Zjc0ODI3NGVhMzBjYTIyYWU5YTQxZjU0M2EyMjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.cmuUZwerBK_cHT6cMebT8qynHYnF0-4s6Q7eyXOEn4I"">. Thank you for your help, it works now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201
https://github.com/scverse/scanpy/issues/3201:1249,usability,help,help,1249,"> Could you provide a code sample to reproduce the problem you are seeing or provide data (ideally both)? > . > ```python. > import scanpy as sc. > adata = sc.datasets.pbmc68k_reduced(). > sc.pl.dotplot(adata, adata.var.index[0:20], groupby=""bulk_labels"", standard_scale=""var"", dendrogram='dendrogram_leiden'). > ```. > . > Seems to work for me: <img alt=""Screenshot 2024-08-07 at 16 58 01"" width=""776"" src=""https://private-user-images.githubusercontent.com/43999641/355985530-41468626-a013-485e-b074-81817664177b.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjM3MDgwNTEsIm5iZiI6MTcyMzcwNzc1MSwicGF0aCI6Ii80Mzk5OTY0MS8zNTU5ODU1MzAtNDE0Njg2MjYtYTAxMy00ODVlLWIwNzQtODE4MTc2NjQxNzdiLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA4MTUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwODE1VDA3NDIzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTkxMjdlMGIzYjI3MmEzNDY3MzY0ZGE2YmNjOTY5ZjBmY2U3Zjc0ODI3NGVhMzBjYTIyYWU5YTQxZjU0M2EyMjcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.cmuUZwerBK_cHT6cMebT8qynHYnF0-4s6Q7eyXOEn4I"">. Thank you for your help, it works now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3201
https://github.com/scverse/scanpy/issues/3205:137,integrability,sub,subplot,137,"The docs don’t say it does, so this would be an enhancement, not a bug fix. it’s not high priority, since it’s easy to just do `ax = plt.subplot(); sc.pl.rank_genes_groups(adata, ax=ax)`. contributions are welcome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205
https://github.com/scverse/scanpy/issues/3205:22,reliability,doe,does,22,"The docs don’t say it does, so this would be an enhancement, not a bug fix. it’s not high priority, since it’s easy to just do `ax = plt.subplot(); sc.pl.rank_genes_groups(adata, ax=ax)`. contributions are welcome!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205
https://github.com/scverse/scanpy/issues/3205:32,usability,behavi,behaviour,32,"This might be true the expected behaviour is not mentioned here. Then as you pointed out it is more of an enhancement, which would be to make it match other plotting functions behaviour ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205
https://github.com/scverse/scanpy/issues/3205:176,usability,behavi,behaviour,176,"This might be true the expected behaviour is not mentioned here. Then as you pointed out it is more of an enhancement, which would be to make it match other plotting functions behaviour ;)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3205
https://github.com/scverse/scanpy/pull/3206:38,modifiability,paramet,parameters,38,@ilan-gold I cleaned up all the style parameters around where `None` is valid or not,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3206
https://github.com/scverse/scanpy/pull/3206:72,safety,valid,valid,72,@ilan-gold I cleaned up all the style parameters around where `None` is valid or not,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3206
https://github.com/scverse/scanpy/pull/3206:58,usability,effectiv,effective,58,"OK, I undid the `dendrogram` change and instead added the effective typing for all the dendrogram-related functions. I was confused by the unclear naming convention and thought that `dendrogram` was bool|str|None whereas `dendrogram_key` was str|None, but the names are just used interchangeably.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3206
https://github.com/scverse/scanpy/issues/3215:70,deployability,version,version,70,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:111,deployability,version,versions,111,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:209,deployability,version,version,209,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:70,integrability,version,version,70,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:111,integrability,version,versions,111,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:209,integrability,version,version,209,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:70,modifiability,version,version,70,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:111,modifiability,version,versions,111,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:209,modifiability,version,version,209,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:30,usability,confirm,confirmed,30,"Hi! You checked the. > I have confirmed this bug exists on the latest version of scanpy. checkbox, but in your versions, I see `scanpy==1.9.6` and not `scanpy==1.10.2`. Are you sure this happens in the newest version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:154,availability,error,error,154,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:88,deployability,updat,updated,88,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:113,deployability,version,version,113,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:2061,deployability,updat,updated,2061,"updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-09-04 17:28",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:309,energy efficiency,cloud,cloudpickle,309,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:113,integrability,version,version,113,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:113,modifiability,version,version,113,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:446,modifiability,deco,decorator,446,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:962,modifiability,pac,packaging,962,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:154,performance,error,error,154,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:278,performance,bottleneck,bottleneck,278,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:88,safety,updat,updated,88,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:154,safety,error,error,154,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:2061,safety,updat,updated,2061,"updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-09-04 17:28",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:88,security,updat,updated,88,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:2041,security,Session,Session,2041,"updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-09-04 17:28",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:2061,security,updat,updated,2061,"updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-09-04 17:28",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:154,usability,error,error,154,"Hi @flying-sheep , I’m using Scanpy on an HPC system, and even though the administrator updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3215:1611,usability,tool,toolz,1611,"updated it to the latest version, I'm still encountering the same error. -----. anndata 0.9.2. scanpy 1.10.2. -----. PIL 9.5.0. asciitree NA. asttokens NA. astunparse 1.6.3. backcall 0.2.0. bottleneck 1.3.6. cffi 1.15.0. cloudpickle 2.2.1. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2024.5.2. dateutil 2.9.0.post0. debugpy 1.5.1. decorator 4.4.2. defusedxml 0.7.1. dill 0.3.8. dot_parser NA. entrypoints 0.4. executing 0.8.3. fasteners 0.18. google NA. h5py 3.8.0. igraph 0.10.8. ipykernel 6.9.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.1. jinja2 3.1.2. joblib 1.4.0. jupyter_server 1.18.1. kiwisolver 1.4.2. legacy_api_wrap NA. leidenalg 0.10.1. llvmlite 0.42.0. louvain 0.8.2. lz4 4.3.2. markupsafe 2.1.1. matplotlib 3.6.0. mpl_toolkits NA. msgpack 1.0.5. natsort 8.4.0. numba 0.59.0. numcodecs 0.12.1. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 2.1.0. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.23.0. prompt_toolkit 3.0.20. psutil 5.9.1. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 16.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pydot 1.4.2. pygments 2.16.1. pynvml NA. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.11.2. seaborn 0.13.2. session_info 1.0.0. setuptools 61.2.0. six 1.16.0. sklearn 1.3.2. sphinxcontrib NA. stack_data 0.2.0. statsmodels 0.14.0. tblib 2.0.0. texttable 1.6.7. threadpoolctl 2.2.0. tlz 0.12.2. toolz 0.11.2. torch 2.2.0+cu121. torchgen NA. tornado 6.1. tqdm 4.63.0. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zarr 2.15.0. zipp NA. zmq 22.3.0. zoneinfo NA. zope NA. -----. IPython 8.4.0. jupyter_client 7.1.2. jupyter_core 4.10.0. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.12 (main, Apr 5 2022, 06:56:58) [GCC 7.5.0]. Linux-3.10.0-1160.99.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2024-09-04 17:28",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3215
https://github.com/scverse/scanpy/issues/3219:239,usability,help,help,239,Just a quick follow up it seems this primarily comes from changing the dir structure from `scanpy/scanpy/*/source_file.py` to `scanpy/src/scanpy/*/source_file.py` although line numbers may or may not also require correction. Also happy to help,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3219
https://github.com/scverse/scanpy/issues/3219:74,deployability,releas,release,74,"Thanks, good catch! This is already fixed in #3194, we just need to cut a release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3219
https://github.com/scverse/scanpy/pull/3220:23,deployability,releas,release,23,Could you please add a release note?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220
https://github.com/scverse/scanpy/pull/3220:25,deployability,releas,release,25,> Could you please add a release note? Sure; I added it.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3220
https://github.com/scverse/scanpy/pull/3227:667,availability,error,error,667,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:631,deployability,continu,continue,631,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:667,performance,error,error,667,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:104,safety,test,test,104,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:528,safety,except,except,528,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:597,safety,except,except,597,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:667,safety,error,error,667,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:99,testability,unit,unit,99,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:104,testability,test,test,104,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:42,usability,minim,minimal,42,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:250,usability,user,user-attachments,250,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/pull/3227:667,usability,error,error,667,"Hi, can you please create an issue with a minimal reproducible example? Alternatively please add a unit test that will trigger your newly added branch. You’ll be able to see if that worked when this comment goes away:. > ![grafik](https://github.com/user-attachments/assets/46daf9ee-93c4-4576-bbcd-c1b17c090e0d). Lastly, please follow the [pre-commit instructions](https://results.pre-commit.ci/run/github/80342493/1726160235.3-pI6xDsREqRW19ZysrYpg):. > ```pytb. > src/scanpy/preprocessing/_pca.py:268:13: E722 Do not use bare `except`. > |. > 266 | try:. > 267 | pca_.partial_fit(chunk). > 268 | except:. > | ^^^^^^ E722. > 269 | continue. > |. > ```. > . > Found 1 error.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3227
https://github.com/scverse/scanpy/issues/3228:11,availability,replic,replicated,11,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:2131,deployability,updat,updated,2131," NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-09-12 21:33. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:1021,interoperability,platform,platformdirs,1021,"I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.13 (tags/v3.9.13:6de2ca5, Ma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:394,modifiability,deco,decorator,394,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:978,modifiability,pac,packaging,978,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:429,safety,except,exceptiongroup,429,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:2131,safety,updat,updated,2131," NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-09-12 21:33. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:236,security,certif,certifi,236,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:561,security,iso,isoduration,561,This issue replicated when I made a new venv and reinstalled everything to get the following: . ```. -----. anndata 0.10.9. scanpy 1.10.2. -----. PIL 10.4.0. anyio NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:2111,security,Session,Session,2111," NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-09-12 21:33. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:2131,security,updat,updated,2131," NA. arrow 1.3.0. asttokens NA. attr 24.2.0. attrs 24.2.0. babel 2.16.0. certifi 2024.08.30. cffi 1.17.1. charset_normalizer 3.3.2. colorama 0.4.6. comm 0.2.2. cycler 0.12.1. cython_runtime NA. dateutil 2.9.0.post0. debugpy 1.8.5. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.2.2. executing 2.1.0. fastjsonschema NA. fqdn NA. h5py 3.11.0. idna 3.8. importlib_resources NA. ipykernel 6.29.5. isoduration NA. jedi 0.19.1. jinja2 3.1.4. joblib 1.4.2. json5 0.9.25. jsonpointer 3.0.0. jsonschema 4.23.0. jsonschema_specifications NA. jupyter_events 0.10.0. jupyter_server 2.14.2. jupyterlab_server 2.27.3. kiwisolver 1.4.7. lazy_loader 0.4. legacy_api_wrap NA. llvmlite 0.43.0. markupsafe 2.1.5. matplotlib 3.9.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.10.4. nt NA. numba 0.60.0. numpy 1.26.4. overrides NA. packaging 24.1. pandas 2.2.2. parso 0.8.4. platformdirs 4.3.2. pooch v1.8.2. prometheus_client NA. prompt_toolkit 3.0.47. psutil 6.0.0. pure_eval 0.2.3. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.18.0. pyparsing 3.1.4. pythoncom NA. pythonjsonlogger NA. pytz 2024.2. pywin32_bootstrap NA. pywin32_system32 NA. pywintypes NA. referencing NA. requests 2.32.3. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.13.1. send2trash NA. session_info 1.0.0. six 1.16.0. skimage 0.24.0. sklearn 1.5.2. sniffio 1.3.1. stack_data 0.6.3. threadpoolctl 3.5.0. tornado 6.4.1. tqdm 4.66.5. traitlets 5.14.3. typing_extensions NA. uri_template NA. urllib3 2.2.3. wcwidth 0.2.13. webcolors 24.8.0. websocket 1.8.0. win32api NA. win32com NA. win32con NA. win32trace NA. winerror NA. yaml 6.0.2. zipp NA. zmq 26.2.0. zoneinfo NA. -----. IPython 8.18.1. jupyter_client 8.6.2. jupyter_core 5.7.2. jupyterlab 4.2.5. notebook 7.2.2. -----. Python 3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]. Windows-10-10.0.22621-SP0. -----. Session information updated at 2024-09-12 21:33. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:435,availability,cluster,clustering,435,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:466,availability,cluster,clusters,466,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:500,availability,cluster,cluster,500,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:435,deployability,cluster,clustering,435,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:466,deployability,cluster,clusters,466,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:500,deployability,cluster,cluster,500,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:621,reliability,doe,does,621,"The issue is fixed by removing `flavor=igraph`, producing the following output instantly:. ```sc.tl.leiden(adata, n_iterations=2)```. ```. FutureWarning: In the future, the default backend for leiden will be igraph instead of leidenalg. To achieve the future defaults please pass: flavor=""igraph"" and n_iterations=2. directed must also be False to work with igraph's implementation. sc.tl.leiden(adata, n_iterations=2). running Leiden clustering. finished: found 26 clusters and added. 'leiden', the cluster labels (adata.obs, categorical) (0:00:00). ```. The warning seems to be incorrect, as passing `directed = False` does not fix the problem when `flavor=igraph`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:27,integrability,sub,subscribe,27,"Duplicate of #2969, please subscribe to that one. I don’t have access to Windows, so unless someone else fixes this, it’s probably not going to get fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3228:63,security,access,access,63,"Duplicate of #2969, please subscribe to that one. I don’t have access to Windows, so unless someone else fixes this, it’s probably not going to get fixed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3228
https://github.com/scverse/scanpy/issues/3241:70,deployability,version,versions,70,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:196,deployability,depend,depends,196,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:70,integrability,version,versions,70,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:196,integrability,depend,depends,196,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:70,modifiability,version,versions,70,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:196,modifiability,depend,depends,196,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:196,safety,depend,depends,196,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:196,testability,depend,depends,196,"Good point! I think the idea might be that they’re actually different versions of a gene that just have been mapped to the same gene name (and have e.g. different ENSEMBL IDs). But of course that depends on how the data was generated, and your method might be more appropriate for some datasets. Example from the tutorial:. ```py. import pooch. import scanpy as sc. EXAMPLE_DATA = pooch.create(. path=pooch.os_cache(""scverse_tutorials""),. base_url=""doi:10.6084/m9.figshare.22716739.v1/"",. ). EXAMPLE_DATA.load_registry_from_doi(). samples = {. ""s1d1"": ""s1d1_filtered_feature_bc_matrix.h5"",. ""s1d3"": ""s1d3_filtered_feature_bc_matrix.h5"",. }. adatas = {}. for sample_id, filename in samples.items():. path = EXAMPLE_DATA.fetch(filename). sample_adata = sc.read_10x_h5(path). #sample_adata.var_names_make_unique(). adatas[sample_id] = sample_adata. adatas[""s1d1""].var[adatas[""s1d1""].var.index.duplicated(keep=False)]. ```. > | | gene_ids | feature_types | genome | pattern | read | sequence |. > | --- | --- | --- | --- | --- | --- | --- |. > | TBCE | ENSG00000285053 | Gene Expression | GRCh38 | | | |. > | TBCE | ENSG00000284770 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000237940 | Gene Expression | GRCh38 | | | |. > | LINC01238 | ENSG00000261186 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000114395 | Gene Expression | GRCh38 | | | |. > | CYB561D2 | ENSG00000271858 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000280987 | Gene Expression | GRCh38 | | | |. > | MATR3 | ENSG00000015479 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234323 | Gene Expression | GRCh38 | | | |. > | LINC01505 | ENSG00000234229 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000284024 | Gene Expression | GRCh38 | | | |. > | HSPA14 | ENSG00000187522 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000188626 | Gene Expression | GRCh38 | | | |. > | GOLGA8M | ENSG00000261480 | Gene Expression | GRCh38 | | | |. > | GGT1 | ENSG00000286070 | Gene Expres",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:50,usability,document,documentation,50,"Thanks for the example! Could we maybe expand the documentation, asking the users to think about this step and select an appropriate strategy? Also, what is the most efficient way to aggregate the features with the same names? Would be great to have a function for that in scanpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:76,usability,user,users,76,"Thanks for the example! Could we maybe expand the documentation, asking the users to think about this step and select an appropriate strategy? Also, what is the most efficient way to aggregate the features with the same names? Would be great to have a function for that in scanpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:166,usability,efficien,efficient,166,"Thanks for the example! Could we maybe expand the documentation, asking the users to think about this step and select an appropriate strategy? Also, what is the most efficient way to aggregate the features with the same names? Would be great to have a function for that in scanpy",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:42,usability,efficien,efficient,42,Yes I would also be keen to know the most efficient way to aggregate the features,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:163,security,sign,significantly,163,"I checked the genes you showed. . These are genes that have alternative transcription start sites and/or alternative transcriptions termination sites, though they significantly intersect. They are transcribed from the same region in the genome +/- N nucleotides. Also, these genes are named the same as gene, however they have different names. For example, one of the variants of MATR3 should is called ENSG00000280987, while other is called MATR3. . https://www.genecards.org/cgi-bin/carddisp.pl?gene=ENSG00000280987. https://www.genecards.org/cgi-bin/carddisp.pl?gene=MATR3&keywords=ENSG00000015479. So this is a problem of the genome annotation, and these are separate genes that should not be aggregated. . Moreover, the more unique features you have, even if you don't understand them at the moment, the better. If you check other genes, you will see that they are different. . For example, one variant of GOLGA8M is protein coding, while another one is a lncRNA. . **It will be good to use their IDs instead of gene symbols. Otherwise it is impossible to separate one from another.**. We can also discuss how good transcript mapping is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:774,testability,understand,understand,774,"I checked the genes you showed. . These are genes that have alternative transcription start sites and/or alternative transcriptions termination sites, though they significantly intersect. They are transcribed from the same region in the genome +/- N nucleotides. Also, these genes are named the same as gene, however they have different names. For example, one of the variants of MATR3 should is called ENSG00000280987, while other is called MATR3. . https://www.genecards.org/cgi-bin/carddisp.pl?gene=ENSG00000280987. https://www.genecards.org/cgi-bin/carddisp.pl?gene=MATR3&keywords=ENSG00000015479. So this is a problem of the genome annotation, and these are separate genes that should not be aggregated. . Moreover, the more unique features you have, even if you don't understand them at the moment, the better. If you check other genes, you will see that they are different. . For example, one variant of GOLGA8M is protein coding, while another one is a lncRNA. . **It will be good to use their IDs instead of gene symbols. Otherwise it is impossible to separate one from another.**. We can also discuss how good transcript mapping is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:22,security,auth,authors,22,"Human Lung Cell Atlas authors also recommended using Ensembl IDs. Probably, for the related reasons. I agree that aggregation might not be the best default approach, but maybe we should explain the problem in the documentation. The genes you mentioned can be a beautiful example. @ShreyParikh07 , related to your recent problem. Maybe you don't need aggregation as well?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3241:213,usability,document,documentation,213,"Human Lung Cell Atlas authors also recommended using Ensembl IDs. Probably, for the related reasons. I agree that aggregation might not be the best default approach, but maybe we should explain the problem in the documentation. The genes you mentioned can be a beautiful example. @ShreyParikh07 , related to your recent problem. Maybe you don't need aggregation as well?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3241
https://github.com/scverse/scanpy/issues/3255:21,availability,avail,available,21,fyi there is scranpy available i have been using it for a while.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255
https://github.com/scverse/scanpy/issues/3255:21,reliability,availab,available,21,fyi there is scranpy available i have been using it for a while.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255
https://github.com/scverse/scanpy/issues/3255:21,safety,avail,available,21,fyi there is scranpy available i have been using it for a while.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255
https://github.com/scverse/scanpy/issues/3255:21,security,availab,available,21,fyi there is scranpy available i have been using it for a while.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3255
https://github.com/scverse/scanpy/issues/3261:97,availability,error,error,97,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:147,availability,error,error,147,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:283,availability,error,error,283,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:323,availability,error,error,323,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:78,deployability,stack,stack,78,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:354,deployability,stack,stackoverflow,354,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:153,integrability,messag,message,153,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:153,interoperability,messag,message,153,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:97,performance,error,error,97,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:147,performance,error,error,147,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:283,performance,error,error,283,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:323,performance,error,error,323,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:167,reliability,doe,does,167,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:69,safety,compl,complete,69,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:97,safety,error,error,97,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:147,safety,error,error,147,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:283,safety,error,error,283,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:323,safety,error,error,323,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:69,security,compl,complete,69,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:84,testability,trace,trace,84,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:228,testability,context,context,228,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:21,usability,minim,minimal,21,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:97,usability,error,error,97,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:147,usability,error,error,147,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:176,usability,help,help,176,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:283,usability,error,error,283,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:323,usability,error,error,323,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:372,usability,help,help,372,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:377,usability,minim,minimal-reproducible-example,377,"Hi, please create a [minimal reproducible example][mre], including a complete stack trace of the error. Mentioning which data set you used and the error message alone does not help us to figure out what happened, as we lack the context of both the steps you took that lead up to the error and where exactly in the code the error happened. [mre]: https://stackoverflow.com/help/minimal-reproducible-example",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:103,availability,error,error,103,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:630,availability,error,error,630,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:772,deployability,modul,module,772,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1064,energy efficiency,core,core,1064,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1235,energy efficiency,core,core,1235,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1424,energy efficiency,core,core,1424,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:772,modifiability,modul,module,772,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:859,modifiability,pac,packages,859,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1048,modifiability,pac,packages,1048,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1219,modifiability,pac,packages,1219,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1408,modifiability,pac,packages,1408,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:103,performance,error,error,103,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:630,performance,error,error,630,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:103,safety,error,error,103,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:630,safety,error,error,630,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:772,safety,modul,module,772,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1069,security,access,accessor,1069,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1248,security,access,accessor,1248,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1437,security,access,accessor,1437,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1515,security,access,accessor,1515,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1581,security,access,accessor,1581,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:103,usability,error,error,103,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:630,usability,error,error,630,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:790,usability,User,Users,790,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:979,usability,User,Users,979,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1150,usability,User,Users,1150,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/issues/3261:1339,usability,User,Users,1339,"I think the reason is Baron_human and Segerstolpe got different dimensions, which I printed out in the error. If so, how to fix it, many thanks. code. ```. x_Traindata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Baron_human/'. Train_name = 'Baron'. Testdata_path = 'F:/迅雷下载/Intra-dataset/Pancreatic_data/Segerstolpe/'. Testdata_name = 'Segerstolpe'. import scanpy as sc. test_adata = sc.read_csv(Testdata_path + Testdata_name + "".csv""). train_adata = sc.read_csv(x_Traindata_path + Train_name + "".csv""). all_adata = sc.AnnData. all_adata = all_adata.concatenate(train_adata). all_adata = all_adata.concatenate(test_adata). ```. error. ```. AnnData object with n_obs × n_vars = 2133 × 22757. AnnData object with n_obs × n_vars = 8569 × 17499. File ""<stdin>"", line 1, in <module>. File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\anndata\_core\anndata.py"", line 1806, in concatenate. out.var.columns.str.extract(pat, expand=False). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\accessor.py"", line 224, in __get__. accessor_obj = self._accessor(obj). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 191, in __init__. self._inferred_dtype = self._validate(data). File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python310\lib\site-packages\pandas\core\strings\accessor.py"", line 245, in _validate. raise AttributeError(""Can only use .str accessor with string values!""). AttributeError: Can only use .str accessor with string values! ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3261
https://github.com/scverse/scanpy/pull/3263:141,availability,operat,operation,141,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:8,deployability,updat,update,8,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:66,performance,perform,performance,66,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:8,safety,updat,update,8,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:8,security,updat,update,8,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:55,testability,understand,understand,55,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:66,usability,perform,performance,66,> Let's update the notebook as well. Would be great to understand performance difference before merging + get rid of the horrible densifying operation in `dask.ipynb`. On it: https://github.com/scverse/scanpy-tutorials/pull/137,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:104,energy efficiency,adapt,adapt,104,"Isaac says that lobpcg seems much less precise and is probably not worth it, so we should probably just adapt the warning to mention the imprecision and call it a day",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:104,integrability,adapt,adapt,104,"Isaac says that lobpcg seems much less precise and is probably not worth it, so we should probably just adapt the warning to mention the imprecision and call it a day",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:104,interoperability,adapt,adapt,104,"Isaac says that lobpcg seems much less precise and is probably not worth it, so we should probably just adapt the warning to mention the imprecision and call it a day",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:104,modifiability,adapt,adapt,104,"Isaac says that lobpcg seems much less precise and is probably not worth it, so we should probably just adapt the warning to mention the imprecision and call it a day",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:13,safety,test,test,13,Can we add a test here to find out (or to at least know) how far our implementation here is from https://github.com/scverse/scanpy/pull/3296 for sparse?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/pull/3263:13,testability,test,test,13,Can we add a test here to find out (or to at least know) how far our implementation here is from https://github.com/scverse/scanpy/pull/3296 for sparse?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3263
https://github.com/scverse/scanpy/issues/3272:386,deployability,contain,contains,386,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:638,deployability,contain,containing,638,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:37,energy efficiency,current,currently,37,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:359,interoperability,distribut,distributes,359,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:590,interoperability,specif,specific,590,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:235,security,auth,authors,235,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:179,testability,understand,understanding,179,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:280,testability,context,context,280,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:511,testability,understand,understanding,511,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:410,usability,custom,customers,410,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3272:842,usability,help,helps,842,"Hi! Coincidentally, we (scverse) are currently looking to speak with a lawyer about this because we want to make sure everyone can use scanpy and friends without problem. From my understanding, code at rest can be licensed however the authors want. Running that code in a certain context can result in the GPL’s license terms being applied. E.g. if a company distributes a product that contains a GPL library, customers of that product can ask the company for the source code of everything. As said, this is my understanding, and I’m not a lawyer. Note also that nothing about the above is specific to scanpy: Companies selling a product containing open source software always have to be aware of this. And that’s why we want to ask a corporate lawyer about what guarantees we should provide for companies and how we can do that. I hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3272
https://github.com/scverse/scanpy/issues/3276:118,deployability,updat,updates,118,"Unfortunately, the team did not get around to implementing the desired behavior yet and therefore, we do not have any updates yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276
https://github.com/scverse/scanpy/issues/3276:118,safety,updat,updates,118,"Unfortunately, the team did not get around to implementing the desired behavior yet and therefore, we do not have any updates yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276
https://github.com/scverse/scanpy/issues/3276:19,security,team,team,19,"Unfortunately, the team did not get around to implementing the desired behavior yet and therefore, we do not have any updates yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276
https://github.com/scverse/scanpy/issues/3276:118,security,updat,updates,118,"Unfortunately, the team did not get around to implementing the desired behavior yet and therefore, we do not have any updates yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276
https://github.com/scverse/scanpy/issues/3276:71,usability,behavi,behavior,71,"Unfortunately, the team did not get around to implementing the desired behavior yet and therefore, we do not have any updates yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3276
https://github.com/scverse/scanpy/pull/3279:76,deployability,depend,dependency,76,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:157,deployability,patch,patch,157,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:287,deployability,patch,patch,287,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:76,integrability,depend,dependency,76,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:76,modifiability,depend,dependency,76,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:76,safety,depend,dependency,76,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:157,safety,patch,patch,157,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:287,safety,patch,patch,287,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:157,security,patch,patch,157,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:287,security,patch,patch,287,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:76,testability,depend,dependency,76,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:56,usability,learn,learn-intelex,56,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3279:172,usability,user,user,172,@kaushalprasadhial We internal discussed adding `scikit-learn-intelex` as a dependency. We came to the conclusion that we dont want it as such. Since this a patch that the user can do regardless we think tath the best thing would be to have a notebook that would show the speedup of the patch. We could host this in a new notebook acceleration category.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3279
https://github.com/scverse/scanpy/pull/3283:445,deployability,modul,module,445,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:538,deployability,modul,module,538,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:445,modifiability,modul,module,445,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:538,modifiability,modul,module,538,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:552,performance,time,time,552,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:379,reliability,doe,doesn,379,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:445,safety,modul,module,445,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:538,safety,modul,module,538,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3283:387,usability,support,support,387,"@Zethson we did though! Where do you see `from __future__ import annotations` being added? The changes here aren’t in a type position (like `param: int`), so they have a runtime effect that isn’t influenced by `from __future__ import annotations`:. - `isinstance(obj, A | B)` results in the second argument having the type `types.UnionType` instead of `tuple`, which I guess 3.9 doesn’t support. - `SomeAlias = A | B` is also evaluated when the module is imported (when not in a `if TYPE_CHECKING` block), or at least has to be parsed at module import time. The same would be true for `cast(A | B, thing)` but I think we don’t do that anywhere because we don’t run MyPy here yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3283
https://github.com/scverse/scanpy/pull/3295:13,deployability,releas,release,13,I didn't add release note yet because I'm not sure if this should already go into 1.10.4,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3295
https://github.com/scverse/scanpy/pull/3299:9,safety,test,test,9,> why no test for a longer collection of colors? what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299
https://github.com/scverse/scanpy/pull/3299:103,safety,test,test,103,> why no test for a longer collection of colors? what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299
https://github.com/scverse/scanpy/pull/3299:9,testability,test,test,9,> why no test for a longer collection of colors? what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299
https://github.com/scverse/scanpy/pull/3299:103,testability,test,test,103,> why no test for a longer collection of colors? what do you mean? just a longer list? what would that test?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299
https://github.com/scverse/scanpy/pull/3299:234,modifiability,paramet,parametrize,234,"I can't request a change on a line you didn't change but roughly https://github.com/scverse/scanpy/pull/3299/files#diff-b8aa68d38b59341f74e2277bc6fde44b917d597363ebfd7bf613743d7098a7caR1340-R1344 would become. ```python. @pytest.mark.parametrize(""color"", [""n_genes"", ""bulk_labels"", [""n_genes"", ""bulk_labels""]]). def test_scatter_no_basis_per_obs(image_comparer, color):. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3299
https://github.com/scverse/scanpy/pull/3307:22,testability,simpl,simply,22,> Am I right that you simply. You are right!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307
https://github.com/scverse/scanpy/pull/3307:22,usability,simpl,simply,22,> Am I right that you simply. You are right!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307
https://github.com/scverse/scanpy/pull/3307:120,integrability,topic,topic,120,"great! then apart from my suggestions and [the crash problem](https://scverse.zulipchat.com/#narrow/channel/456188-Dask/topic/Numba.20in.20Dask/near/478897406), this looks ready.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3307
https://github.com/scverse/scanpy/issues/3310:9,usability,hint,hints,9,"The type hints will always be more precise than language in telling you what’s correct. Also there are examples. But I agree, “Tuple” (singular) is wrong and should be fixed!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3310
https://github.com/scverse/scanpy/pull/3315:41,performance,time,time,41,"Sorry about that, will keep in mind next time!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315
https://github.com/scverse/scanpy/pull/3315:44,modifiability,responsibil,responsibility,44,Don't worry @jeskowagner because I take the responsibility as the one that approved your PR :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3315
https://github.com/scverse/scanpy/pull/3316:20,performance,perform,performance,20,"it shouldn’t affect performance at all, just readability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3316
https://github.com/scverse/scanpy/pull/3316:20,usability,perform,performance,20,"it shouldn’t affect performance at all, just readability",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3316
https://github.com/scverse/scanpy/issues/3318:77,modifiability,layer,layers,77,"Well, the documentation of `highest_expr_genes` doesn’t say that it supports layers, but this is a very sensible feature request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3318:48,reliability,doe,doesn,48,"Well, the documentation of `highest_expr_genes` doesn’t say that it supports layers, but this is a very sensible feature request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3318:10,usability,document,documentation,10,"Well, the documentation of `highest_expr_genes` doesn’t say that it supports layers, but this is a very sensible feature request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3318:68,usability,support,supports,68,"Well, the documentation of `highest_expr_genes` doesn’t say that it supports layers, but this is a very sensible feature request.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3318:33,modifiability,layer,layer,33,"sorry, copilot hallucinated me a layer variable!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3318:39,modifiability,variab,variable,39,"sorry, copilot hallucinated me a layer variable!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3318
https://github.com/scverse/scanpy/issues/3320:2,availability,Error,Error,2,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:2,performance,Error,Error,2,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:2,safety,Error,Error,2,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:2,usability,Error,Error,2,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:109,usability,user,user-attachments,109,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:265,usability,user,user-attachments,265,# Error Output. Output when using a list of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/570abb0c-a986-45f1-8d5c-3fceddf02273). Output when using a dict of marker genes in the `var_names` arg. ![Image](https://github.com/user-attachments/assets/9221dfe4-1638-4284-beb9-d8c02fa9d4eb).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:27,deployability,depend,depending,27,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:27,integrability,depend,depending,27,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:27,modifiability,depend,depending,27,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:27,safety,depend,depending,27,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:187,safety,compl,complicated,187,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:187,security,compl,complicated,187,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:27,testability,depend,depending,27,"Yeah, that’s true. I think depending on what’s happening, it’s actually the spacer we add, not the area for the dendrogram, but sometimes we also need that spacer …. Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:551,availability,cluster,cluster,551,"I was able to ""hack"" my way to a solution. However I needed to call `StackedViolin.make_figure` to actually generate the figure that I could remove Axes from, and this creates the issue of showing the plot twice (one incorrect, one correct) in a Jupyter notebook. In a script though this shouldn't be an issue though. ```python. marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. violin_fig = sc.pl.stacked_violin(vis_adata, marker_genes, var_group_positions=None, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). # Remove the existing legend and add a new vertically-oriented one. violin_fig.legend(show = False). violin_fig.add_totals(). violin_fig.make_figure(). # For some reason, deleting all axes and remaking the figure makes it without the spacer above the plot (which was in ax[2] I think). violin_axes = violin_fig.fig.get_axes(). for ax in violin_axes:. violin_fig.fig.delaxes(ax). violin_fig.make_figure(). ```. ![Image](https://github.com/user-attachments/assets/c1e992fd-47b3-43a7-8937-cec7ffa53384).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:69,deployability,Stack,StackedViolin,69,"I was able to ""hack"" my way to a solution. However I needed to call `StackedViolin.make_figure` to actually generate the figure that I could remove Axes from, and this creates the issue of showing the plot twice (one incorrect, one correct) in a Jupyter notebook. In a script though this shouldn't be an issue though. ```python. marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. violin_fig = sc.pl.stacked_violin(vis_adata, marker_genes, var_group_positions=None, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). # Remove the existing legend and add a new vertically-oriented one. violin_fig.legend(show = False). violin_fig.add_totals(). violin_fig.make_figure(). # For some reason, deleting all axes and remaking the figure makes it without the spacer above the plot (which was in ax[2] I think). violin_axes = violin_fig.fig.get_axes(). for ax in violin_axes:. violin_fig.fig.delaxes(ax). violin_fig.make_figure(). ```. ![Image](https://github.com/user-attachments/assets/c1e992fd-47b3-43a7-8937-cec7ffa53384).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:551,deployability,cluster,cluster,551,"I was able to ""hack"" my way to a solution. However I needed to call `StackedViolin.make_figure` to actually generate the figure that I could remove Axes from, and this creates the issue of showing the plot twice (one incorrect, one correct) in a Jupyter notebook. In a script though this shouldn't be an issue though. ```python. marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. violin_fig = sc.pl.stacked_violin(vis_adata, marker_genes, var_group_positions=None, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). # Remove the existing legend and add a new vertically-oriented one. violin_fig.legend(show = False). violin_fig.add_totals(). violin_fig.make_figure(). # For some reason, deleting all axes and remaking the figure makes it without the spacer above the plot (which was in ax[2] I think). violin_axes = violin_fig.fig.get_axes(). for ax in violin_axes:. violin_fig.fig.delaxes(ax). violin_fig.make_figure(). ```. ![Image](https://github.com/user-attachments/assets/c1e992fd-47b3-43a7-8937-cec7ffa53384).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:15,security,hack,hack,15,"I was able to ""hack"" my way to a solution. However I needed to call `StackedViolin.make_figure` to actually generate the figure that I could remove Axes from, and this creates the issue of showing the plot twice (one incorrect, one correct) in a Jupyter notebook. In a script though this shouldn't be an issue though. ```python. marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. violin_fig = sc.pl.stacked_violin(vis_adata, marker_genes, var_group_positions=None, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). # Remove the existing legend and add a new vertically-oriented one. violin_fig.legend(show = False). violin_fig.add_totals(). violin_fig.make_figure(). # For some reason, deleting all axes and remaking the figure makes it without the spacer above the plot (which was in ax[2] I think). violin_axes = violin_fig.fig.get_axes(). for ax in violin_axes:. violin_fig.fig.delaxes(ax). violin_fig.make_figure(). ```. ![Image](https://github.com/user-attachments/assets/c1e992fd-47b3-43a7-8937-cec7ffa53384).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:1072,usability,user,user-attachments,1072,"I was able to ""hack"" my way to a solution. However I needed to call `StackedViolin.make_figure` to actually generate the figure that I could remove Axes from, and this creates the issue of showing the plot twice (one incorrect, one correct) in a Jupyter notebook. In a script though this shouldn't be an issue though. ```python. marker_genes = [""Pou4f3"", ""Calb2"", ""Pvalb"", ""Smpx"", ""Mlf1"", ""Sox2""] # 5 random Cochlear HCs P7 + Sox2. violin_fig = sc.pl.stacked_violin(vis_adata, marker_genes, var_group_positions=None, title=""Marker gene expression per cluster"", groupby=""spatial_clusters"", cmap=""YlOrRd"", show=False, return_fig=True). # Remove the existing legend and add a new vertically-oriented one. violin_fig.legend(show = False). violin_fig.add_totals(). violin_fig.make_figure(). # For some reason, deleting all axes and remaking the figure makes it without the spacer above the plot (which was in ax[2] I think). violin_axes = violin_fig.fig.get_axes(). for ax in violin_axes:. violin_fig.fig.delaxes(ax). violin_fig.make_figure(). ```. ![Image](https://github.com/user-attachments/assets/c1e992fd-47b3-43a7-8937-cec7ffa53384).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:5,energy efficiency,cool,cool,5,very cool! Happy you found a workaround. I’d really like to toss a lot of the plotting out and replace it with something declarative …,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:203,performance,time,time,203,"> Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int. @flying-sheep I feel like diving in, do you have an issue/PR to work on? I've been using scanpy for a long time, and want to contribute",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:23,safety,compl,complicated,23,"> Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int. @flying-sheep I feel like diving in, do you have an issue/PR to work on? I've been using scanpy for a long time, and want to contribute",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/issues/3320:23,security,compl,complicated,23,"> Our plotting code is complicated and needs to be overhauled. If anyone feels like diving int. @flying-sheep I feel like diving in, do you have an issue/PR to work on? I've been using scanpy for a long time, and want to contribute",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3320
https://github.com/scverse/scanpy/pull/3328:28,deployability,releas,release,28,@flying-sheep do you need a release note here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3328
https://github.com/scverse/scanpy/pull/3328:42,reliability,doe,doesn,42,"nah, I think this is small enough that it doesn’t need one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3328
https://github.com/scverse/scanpy/issues/3331:31,deployability,stack,stacktrace,31,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/issues/3331:227,deployability,fail,fails,227,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/issues/3331:251,integrability,sub,subset,251,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/issues/3331:227,reliability,fail,fails,227,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/issues/3331:72,usability,minim,minimal,72,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/issues/3331:359,usability,help,help,359,Could you please post the full stacktrace and ideally provide us with a minimal working example to more easily find out what's going wrong? Can you create an artificial AnnData object that has the properties where the function fails? Can you create a subset of your data and then recreate an AnnData object that looks similar and leads to the issue? LLMs can help you here. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/3331
https://github.com/scverse/scanpy/pull/3335:1080,availability,error,error,1080,"ersion lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:82,deployability,version,version,82,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:475,deployability,instal,installing,475,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:550,deployability,instal,installing,550,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7463,deployability,modul,module,7463,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1480,energy efficiency,core,core,1480,"ing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1564,energy efficiency,core,core,1564,". Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1638,energy efficiency,optim,optimization,1638,"etected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1726,energy efficiency,core,core,1726,"oncurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2630,energy efficiency,Current,Current,2630,"ask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3022,energy efficiency,core,core,3022,">/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 4",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3106,energy efficiency,core,core,3106,"/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3180,energy efficiency,optim,optimization,3180,"ding.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<ve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3268,energy efficiency,core,core,3268,"line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:82,integrability,version,version,82,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1204,integrability,wrap,wrapper,1204," thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1345,integrability,wrap,wrapper,1345,"sts/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2746,integrability,wrap,wrapper,2746,"xecute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2887,integrability,wrap,wrapper,2887,"sk/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4387,integrability,queue,queue,4387,"ile ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1204,interoperability,wrapper,wrapper,1204," thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1345,interoperability,wrapper,wrapper,1345,"sts/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2746,interoperability,wrapper,wrapper,2746,"xecute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2887,interoperability,wrapper,wrapper,2887,"sk/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. F",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3918,interoperability,socket,socket,3918,"anpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5022,interoperability,plug,pluggy,5022,"3 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. Fil",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5109,interoperability,plug,pluggy,5109,"nv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5195,interoperability,plug,pluggy,5195,"on3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5457,interoperability,plug,pluggy,5457,"k/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5544,interoperability,plug,pluggy,5544,"l.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _mu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5630,interoperability,plug,pluggy,5630,"py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _h",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6163,interoperability,plug,pluggy,6163,"lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<ven",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6250,interoperability,plug,pluggy,6250,"python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6336,interoperability,plug,pluggy,6336,"thon3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6511,interoperability,plug,pluggy,6511,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6598,interoperability,plug,pluggy,6598,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6684,interoperability,plug,pluggy,6684,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7025,interoperability,plug,pluggy,7025,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7112,interoperability,plug,pluggy,7112,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7198,interoperability,plug,pluggy,7198,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:82,modifiability,version,version,82,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:594,modifiability,layer,layer,594,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:679,modifiability,layer,layer,679,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:940,modifiability,layer,layer,940,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1055,modifiability,layer,layer,1055,"o call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/future",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1466,modifiability,pac,packages,1466," Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1550,modifiability,pac,packages,1550,"alling `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1624,modifiability,pac,packages,1624,"ccess has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1712,modifiability,pac,packages,1712,"e accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1796,modifiability,pac,packages,1796,"ugh a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1880,modifiability,pac,packages,1880," multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3008,modifiability,pac,packages,3008," File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3092,modifiability,pac,packages,3092," ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3166,modifiability,pac,packages,3166,"python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3254,modifiability,pac,packages,3254,"eading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x0000",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3338,modifiability,pac,packages,3338,"st):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3422,modifiability,pac,packages,3422," File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3983,modifiability,pac,packages,3983,"/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4448,modifiability,pac,packages,4448,"239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-pack",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4529,modifiability,pac,packages,4529,".py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/sit",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4610,modifiability,pac,packages,4610,"line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4687,modifiability,pac,packages,4687,"un. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/pyt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4765,modifiability,pac,packages,4765,"File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4919,modifiability,pac,packages,4919,"t.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5013,modifiability,pac,packages,5013," line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestproto",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5100,modifiability,pac,packages,5100,"ile ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5186,modifiability,pac,packages,5186,"lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5269,modifiability,pac,packages,5269,"ost recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5353,modifiability,pac,packages,5353,". File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", li",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5448,modifiability,pac,packages,5448,"ages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pyt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5535,modifiability,pac,packages,5535,"ask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 10",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5621,modifiability,pac,packages,5621,"hreaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 1",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5704,modifiability,pac,packages,5704,""", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5788,modifiability,pac,packages,5788,"e 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 33",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5873,modifiability,pac,packages,5873,"nt_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:5964,modifiability,pac,packages,5964,"yfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6055,modifiability,pac,packages,6055,"ticall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6154,modifiability,pac,packages,6154,"""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. Fi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6241,modifiability,pac,packages,6241,"nv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File """,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6327,modifiability,pac,packages,6327,">/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. Fil",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6410,modifiability,pac,packages,6410," File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in con",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6502,modifiability,pac,packages,6502,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6589,modifiability,pac,packages,6589,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6675,modifiability,pac,packages,6675,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6758,modifiability,pac,packages,6758,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6837,modifiability,pac,packages,6837,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:6923,modifiability,pac,packages,6923,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7016,modifiability,pac,packages,7016,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7103,modifiability,pac,packages,7103,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7189,modifiability,pac,packages,7189,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7272,modifiability,pac,packages,7272,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7361,modifiability,pac,packages,7361,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7463,modifiability,modul,module,7463,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:73,performance,parallel,parallel,73,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:168,performance,parallel,parallel,168,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:616,performance,Concurren,Concurrent,616,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:727,performance,concurren,concurrently,727,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:761,performance,Concurren,Concurrent,761,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:813,performance,parallel,parallel,813,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:856,performance,parallel,parallel,856,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1080,performance,error,error,1080,"ersion lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1638,performance,optimiz,optimization,1638,"etected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1966,performance,concurren,concurrent,1966,"is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in fu",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2041,performance,concurren,concurrent,2041,"hreading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:2376,performance,concurren,concurrent,2376,"py/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3180,performance,optimiz,optimization,3180,"ding.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016ed23000 (most recent call first):. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 89 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<ve",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3508,performance,concurren,concurrent,3508,"12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3583,performance,concurren,concurrent,3583,"2/threading.py"", line 1030 in _bootstrap. Current thread 0x000000016dd17000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4387,performance,queue,queue,4387,"ile ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:36,reliability,doe,doesn,36,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:19,safety,detect,detected,19,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:342,safety,test,test,342,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:347,safety,test,tests,347,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:643,safety,detect,detected,643,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1080,safety,error,error,1080,"ersion lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4829,safety,test,tests,4829,"rap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in fro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:7463,safety,modul,module,7463,""", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in from_call. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 241 in call_and_report. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 132 in runtestprotocol. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 113 in pytest_runtest_protocol. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 362 in pytest_runtestloop. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 337 in _main. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 283 in wrap_session. File ""<venv>/lib/python3.12/site-packages/_pytest/main.py"", line 330 in pytest_cmdline_main. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 175 in main. File ""<venv>/lib/python3.12/site-packages/_pytest/config/__init__.py"", line 201 in console_main. File ""<venv>/bin/pytest"", line 10 in <module>. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:19,security,detect,detected,19,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:627,security,access,access,627,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:643,security,detect,detected,643,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:718,security,access,accessed,718,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:772,security,access,access,772,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:3918,security,soc,socket,3918,"anpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 58 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in _worker. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-pa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:342,testability,test,test,342,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:347,testability,test,tests,347,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:462,testability,context,context,462,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:537,testability,context,context,537,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:4829,testability,test,tests,4829,"rap. Thread 0x000000016cd0b000 (most recent call first):. File ""<venv>/lib/python3.12/socket.py"", line 295 in accept. File ""<venv>/lib/python3.12/site-packages/pytest_rerunfailures.py"", line 433 in run_server. File ""<venv>/lib/python3.12/threading.py"", line 1010 in run. File ""<venv>/lib/python3.12/threading.py"", line 1073 in _bootstrap_inner. File ""<venv>/lib/python3.12/threading.py"", line 1030 in _bootstrap. Thread 0x00000001f9bdf240 (most recent call first):. File ""<venv>/lib/python3.12/threading.py"", line 355 in wait. File ""<venv>/lib/python3.12/queue.py"", line 171 in get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 138 in queue_get. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 501 in get_async. File ""<venv>/lib/python3.12/site-packages/dask/threaded.py"", line 90 in get. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 662 in compute. File ""<venv>/lib/python3.12/site-packages/dask/base.py"", line 376 in compute. File ""~/Dev/scanpy/tests/test_utils.py"", line 243 in test_is_constant_dask. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 159 in pytest_pyfunc_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/python.py"", line 1627 in runtest. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 174 in pytest_runtest_call. File ""<venv>/lib/python3.12/site-packages/pluggy/_callers.py"", line 103 in _multicall. File ""<venv>/lib/python3.12/site-packages/pluggy/_manager.py"", line 120 in _hookexec. File ""<venv>/lib/python3.12/site-packages/pluggy/_hooks.py"", line 513 in __call__. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 242 in <lambda>. File ""<venv>/lib/python3.12/site-packages/_pytest/runner.py"", line 341 in fro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:52,usability,help,help,52,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:140,usability,clear,clear,140,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:276,usability,support,supported,276,"Huh weird, it gets detected, but it doesn’t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1040,usability,user,user,1040,"t seem to help to call the non-parallel version lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/c",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3335:1080,usability,error,error,1080,"ersion lol. If I replace the `warn` with a `print`, it’s clear that the correct (non-parallel) function is called from Dask’s thread. Seems like calling numba from a `ThreadPoolExecutor` isn’t supported at all, even if it comes from dask. ```console. $ hatch test tests/test_utils.py::test_is_constant_dask[csr_matrix-0] --capture=no. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba function called from a non-threadsafe context. Try installing `tbb`. Numba workqueue threading layer is terminating: Concurrent access has been detected. - The workqueue threading layer is not threadsafe and may not be accessed concurrently by multiple threads. Concurrent access typically occurs through a nested parallel region launch or by calling Numba parallel=True functions from multiple Python threads. - Try using the TBB threading layer as an alternative, as it is, itself, threadsafe. Docs: https://numba.readthedocs.io/en/stable/user/threading-layer.html. Fatal Python error: Aborted. Thread 0x000000016fd2f000 (most recent call first):. File ""~/Dev/scanpy/src/scanpy/_compat.py"", line 133 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 109 in _. File ""<venv>/lib/python3.12/functools.py"", line 909 in wrapper. File ""~/Dev/scanpy/src/scanpy/_utils/compute/is_constant.py"", line 30 in func. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 157 in get. File ""<venv>/lib/python3.12/site-packages/dask/optimization.py"", line 1001 in __call__. File ""<venv>/lib/python3.12/site-packages/dask/core.py"", line 127 in _execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 225 in execute_task. File ""<venv>/lib/python3.12/site-packages/dask/local.py"", line 239 in batch_execute_tasks. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 64 in run. File ""<venv>/lib/python3.12/concurrent/futures/thread.py"", line 92 in ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3335
https://github.com/scverse/scanpy/pull/3336:31,availability,failur,failure,31,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336
https://github.com/scverse/scanpy/pull/3336:31,deployability,fail,failure,31,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336
https://github.com/scverse/scanpy/pull/3336:31,performance,failur,failure,31,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336
https://github.com/scverse/scanpy/pull/3336:31,reliability,fail,failure,31,"we need to finally fix that CI failure in this job, I only look into the `minimum_versions` job anymore before I merge PRs",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/3336
