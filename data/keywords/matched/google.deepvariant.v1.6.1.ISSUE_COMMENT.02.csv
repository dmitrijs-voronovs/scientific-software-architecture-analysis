id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/62:31,availability,error,error,31,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:406,availability,error,error,406,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:555,availability,error,error,555,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2223,availability,error,error-free,2223,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2406,availability,error,errors,2406,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:657,deployability,Log,Logits,657,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1842,deployability,contain,contains,1842,". >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2332,deployability,contain,contain,2332,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2571,deployability,version,version,2571,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:271,energy efficiency,current,currently,271,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1132,integrability,Sub,Subject,1132,"roducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1834,integrability,messag,message,1834,"er to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2453,integrability,messag,message,2453,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2571,integrability,version,version,2571,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:382,interoperability,specif,specifically,382,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1834,interoperability,messag,message,1834,"er to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1992,interoperability,distribut,distribute,1992,"epvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2453,interoperability,messag,message,2453,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2571,modifiability,version,version,2571,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:31,performance,error,error,31,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:406,performance,error,error,406,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:555,performance,error,error,555,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1356,performance,content,content,1356,"it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sende",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2223,performance,error,error-free,2223,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2406,performance,error,errors,2406,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2436,performance,content,contents,2436,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:41,reliability,doe,doesn,41,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2372,reliability,doe,does,2372,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:31,safety,error,error,31,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:406,safety,error,error,406,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:555,safety,error,error,555,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:657,safety,Log,Logits,657,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:701,safety,input,input,701,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1367,safety,safe,safe,1367,"ly. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2223,safety,error,error-free,2223,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2406,safety,error,errors,2406,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:657,security,Log,Logits,657,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1090,security,Auth,Author,1090,"fore. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have receive",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1102,security,auth,author,1102," could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mai",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1542,security,auth,authored,1542," Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required pleas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1761,security,auth,auth,1761," people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1851,security,confidential,confidential,1851,"ks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2212,security,secur,secured,2212,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2258,security,intercept,intercepted,2258,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2952,security,auth,auth,2952,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:657,testability,Log,Logits,657,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2516,testability,verif,verification,2516,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:31,usability,error,error,31,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:406,usability,error,error,406,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:555,usability,error,error,555,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:701,usability,input,input,701,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:792,usability,document,documentation,792,"Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2223,usability,error,error-free,2223,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2406,usability,error,errors,2406,"t@noreply.github.com>. > Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <. > author@noreply.github.com>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:692,availability,error,error,692,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1067,availability,error,error,1067,"ulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1249,availability,error,error,1249,"ent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3026,availability,error,error-free,3026,"inated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://gi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3209,availability,error,errors,3209,"d_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4505,availability,error,error-free,4505,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4683,availability,error,errors,4683,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1351,deployability,Log,Logits,1351,"ad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2645,deployability,contain,contains,2645,"y, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3135,deployability,contain,contain,3135,"der and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3374,deployability,version,version,3374,"his email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have rece",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4139,deployability,contain,contains,4139,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4611,deployability,contain,contain,4611,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4839,deployability,version,version,4839,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:932,energy efficiency,current,currently,932,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:431,integrability,Sub,Subject,431,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1935,integrability,Sub,Subject,1935,"ly have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2637,integrability,messag,message,2637,": Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3256,integrability,messag,message,3256,"_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3374,integrability,version,version,3374,"his email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have rece",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4131,integrability,messag,message,4131,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4727,integrability,messag,message,4727,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4839,integrability,version,version,4839,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1043,interoperability,specif,specifically,1043,"ricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outsid",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2637,interoperability,messag,message,2637,": Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2795,interoperability,distribut,distribute,2795,"omas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3256,interoperability,messag,message,3256,"_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4131,interoperability,messag,message,4131,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4283,interoperability,distribut,distribute,4283,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4727,interoperability,messag,message,4727,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3374,modifiability,version,version,3374,"his email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have rece",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4839,modifiability,version,version,4839,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:644,performance,content,content,644,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:692,performance,error,error,692,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1067,performance,error,error,1067,"ulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1249,performance,error,error,1249,"ent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2159,performance,content,content,2159,"to:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sende",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3026,performance,error,error-free,3026,"inated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://gi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3209,performance,error,errors,3209,"d_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3239,performance,content,contents,3239,"pt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the name",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4505,performance,error,error-free,4505,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4683,performance,error,errors,4683,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4710,performance,content,contents,4710,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:702,reliability,doe,doesn,702,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3175,reliability,doe,does,3175,". > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4649,reliability,doe,does,4649,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:655,safety,safe,safe,655,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:692,safety,error,error,692,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1067,safety,error,error,1067,"ulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1249,safety,error,error,1249,"ent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1351,safety,Log,Logits,1351,"ad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1395,safety,input,input,1395,"hor <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2170,safety,safe,safe,2170,"cations@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3026,safety,error,error-free,3026,"inated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://gi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3209,safety,error,errors,3209,"d_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4505,safety,error,error-free,4505,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4683,safety,error,errors,4683,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:395,security,Auth,Author,395,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:403,security,auth,author,403,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1351,security,Log,Logits,1351,"ad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1859,security,Auth,Author,1859,"n try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immedia",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1871,security,auth,author,1871," and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1904,security,auth,author,1904,"ave gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-ma",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2345,security,auth,authored,2345,"3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required pleas",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2564,security,auth,auth,2564,"mas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2654,security,confidential,confidential,2654,", 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3015,security,secur,secured,3015,"s email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the threa",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3061,security,intercept,intercepted,3061,". DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3755,security,auth,auth,3755,"ressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a resu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3860,security,auth,authored,3860,"ly by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Labo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4066,security,auth,auth,4066,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4148,security,confidential,confidential,4148,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4494,security,secur,secured,4494,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4540,security,intercept,intercepted,4540,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1351,testability,Log,Logits,1351,"ad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3319,testability,verif,verification,3319,"ng this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please not",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4787,testability,verif,verification,4787,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:160,usability,help,help,160,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:692,usability,error,error,692,"Hello,. Unfortunately the data I’m using are restricted by Federal regulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1067,usability,error,error,1067,"ulations and also are proprietary. Apart from sharing data, what can I provide that might help figure this out? Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1249,usability,error,error,1249,"ent: Thursday, April 12, 2018 3:34 PM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1395,usability,input,input,1395,"hor <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1486,usability,document,documentation,1486,"62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. From a quick look of your error, it doesn't look like anything I've ever. encountered before. If you could potentially set up a reproducible setting. that I can very quickly run, I can see if I can try it out and tell you. what might could have gone wrong. We don't currently have a tutorial for. training, unfortunately. And to be honest, even if we do, it probably. wouldn't specifically cover this error case. (from my phone). On Tue, Apr 10, 2018, 11:16 AM KBT59 <notifications@github.com<mailto:notifications@github.com>> wrote:. > OK – that proceeded further, I think. Now the error is. > ValueError: Can not squeeze dim[1], expected a dimension of 1, got 27 for. > 'InceptionV3/Logits/SpatialSqueeze' (op: 'Squeeze') with input shapes:. > [64,27,1,3]. >. >. > I hate to keep bothering people about this. Is there documentation on all. > of this that I can refer to? >. >. > Thanks,. > Brad Thomas. >. >. > From: Pi-Chuan Chang [mailto:notifications@github.com]. > Sent: Tuesday, April 10, 2018 1:04 PM. > To: google/deepvariant <deepvariant@noreply.github.com<mailto:deepvariant@noreply.github.com>>. > Cc: Brad Thomas <brad.thomas@neogenomics.com<mailto:brad.thomas@neogenomics.com>>; Author <. > author@noreply.github.com<mailto:author@noreply.github.com>>. > Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). >. > CAUTION: This email originated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3026,usability,error,error-free,3026,"inated from outside the organization. DO NOT click. > links or open attachments unless you recognize the sender and know the. > content is safe. >. > I think you'll want:. > tfrecord_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://gi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:3209,usability,error,errors,3209,"d_path:. > ""/home2/myModelAttempt/output/5PRR-RD_S86.examples.tfrecord-?????-of-00064"". >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub<. > https://github.com/google/deepvariant/issues/62#issuecomment-380193942>,. > or mute the thread<. > https://github.com/notifications/unsubscribe-auth/AifcqWYh56G1_S7aFjDrcbIt_6qII5goks5tnPP8gaJpZM4TIm9R>. >. >. > This message contains confidential information and is intended only for. > the individual named. If you are not the named addressee you should not. > disseminate, distribute or copy this e-mail. Please notify the sender. > immediately by e-mail if you have received this e-mail by mistake and. > delete this e-mail from your system. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4505,usability,error,error-free,4505,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:4683,usability,error,errors,4683,"m. E-mail transmission cannot be. > guaranteed to be secured or error-free as information could be intercepted,. > corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. > The sender therefore does not accept liability for any errors or omissions. > in the contents of this message, which arise as a result of e-mail. > transmission. If verification is required please request a hard-copy. > version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort. > Myers, FL 33913, http://www.neogenomics.com (2017). >. > —. > You are receiving this because you commented. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/62#issuecomment-380197853>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAczBalfAA5qelNx5damo_mTuPg7r4UJks5tnPbigaJpZM4TIm9R>. > . >. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-380935943>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWTCcHHVi1NrDCRWylTEadlDsGGAks5tn7pQgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:782,availability,error,error,782,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:972,availability,error,error,972,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:593,deployability,log,logic,593,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:63,integrability,sub,subsampled,63,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:219,integrability,sub,subsample,219,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:782,performance,error,error,782,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:972,performance,error,error,972,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:593,safety,log,logic,593,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:782,safety,error,error,782,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:972,safety,error,error,972,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:593,security,log,logic,593,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:190,testability,understand,understand,190,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:593,testability,log,logic,593,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:281,usability,command,commands,281,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:692,usability,visual,visualize,692,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:782,usability,error,error,782,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:972,usability,error,error,972,"Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). But I understand if you can't even subsample from your real data. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1369,availability,error,error,1369,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1559,availability,error,error,1559,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2249,availability,error,error-free,2249,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2427,availability,error,errors,2427,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1180,deployability,log,logic,1180,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1883,deployability,contain,contains,1883,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2355,deployability,contain,contain,2355,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2583,deployability,version,version,2583,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:371,integrability,Sub,Subject,371,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:664,integrability,sub,subsampled,664,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:816,integrability,sub,subsample,816,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1875,integrability,messag,message,1875,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2471,integrability,messag,message,2471,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2583,integrability,version,version,2583,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1875,interoperability,messag,message,1875,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2027,interoperability,distribut,distribute,2027,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2471,interoperability,messag,message,2471,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2583,modifiability,version,version,2583,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:584,performance,content,content,584,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1369,performance,error,error,1369,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1559,performance,error,error,1559,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2249,performance,error,error-free,2249,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2427,performance,error,errors,2427,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2454,performance,content,contents,2454,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2393,reliability,doe,does,2393,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:595,safety,safe,safe,595,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1180,safety,log,logic,1180,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1369,safety,error,error,1369,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1559,safety,error,error,1559,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2249,safety,error,error-free,2249,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2427,safety,error,errors,2427,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:335,security,Auth,Author,335,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:343,security,auth,author,343,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1180,security,log,logic,1180,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1604,security,auth,authored,1604,"iginally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Labo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1810,security,auth,auth,1810,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1892,security,confidential,confidential,1892,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2238,security,secur,secured,2238,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2284,security,intercept,intercepted,2284,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:787,testability,understand,understand,787,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1180,testability,log,logic,1180,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2531,testability,verif,verification,2531,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:868,usability,command,commands,868,"I’m generating a set from the GIAB exome data as you described. I’ll see what happens with it when I try to train with it. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee y",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1279,usability,visual,visualize,1279,"m>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1369,usability,error,error,1369,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1559,usability,error,error,1559,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2249,usability,error,error-free,2249,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2427,usability,error,errors,2427,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1771,availability,error,error,1771,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1961,availability,error,error,1961,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2651,availability,error,error-free,2651,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2829,availability,error,errors,2829,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1582,deployability,log,logic,1582,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2285,deployability,contain,contains,2285,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2757,deployability,contain,contain,2757,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2985,deployability,version,version,2985,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:773,integrability,Sub,Subject,773,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1066,integrability,sub,subsampled,1066,"e github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on Git",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1218,integrability,sub,subsample,1218,"was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqS",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2277,integrability,messag,message,2277,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2873,integrability,messag,message,2873,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2985,integrability,version,version,2985,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2277,interoperability,messag,message,2277,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2429,interoperability,distribut,distribute,2429,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2873,interoperability,messag,message,2873,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2985,modifiability,version,version,2985,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:986,performance,content,content,986,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1771,performance,error,error,1771,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1961,performance,error,error,1961,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2651,performance,error,error-free,2651,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2829,performance,error,errors,2829,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2856,performance,content,contents,2856,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2795,reliability,doe,does,2795,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:339,safety,test,testModeExamples,339,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:997,safety,safe,safe,997,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1582,safety,log,logic,1582,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1771,safety,error,error,1771,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1961,safety,error,error,1961,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2651,safety,error,error-free,2651,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2829,safety,error,errors,2829,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:737,security,Auth,Author,737,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:745,security,auth,author,745,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1582,security,log,logic,1582,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2006,security,auth,authored,2006,"iginally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Labo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2212,security,auth,auth,2212,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2294,security,confidential,confidential,2294,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2640,security,secur,secured,2640,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2686,security,intercept,intercepted,2686,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:339,testability,test,testModeExamples,339,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1189,testability,understand,understand,1189,"he file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifica",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1582,testability,log,logic,1582,"ub.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2933,testability,verif,verification,2933,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:268,usability,command,command,268,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:460,usability,help,help,460,"Hello,. I did make 64 examples from the GIAB exome data mentioned on the github site. I encountered the same problem I mentioned. I’ve attached an archive, bundle.zip that has important files. The file nohup.out shows what was returned when I ran model_train from the command line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this becaus",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1270,usability,command,commands,1270,"d line. Examples were made using the shell script in the bundle: testModeExamples.sh. I’ve included the two python scripts I’ve altered for my deep sequencing project. I appreciate your help. Let me know if there is more I should provide. Thank you,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Friday, April 13, 2018 10:14 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. Th",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1681,usability,visual,visualize,1681,"m>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1771,usability,error,error,1771,"ubject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1961,usability,error,error,1961,"e sender and know the content is safe. Hi,. originally I was thinking a small/synthetic dataset could subsampled from your data. I actually don't want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2651,usability,error,error-free,2651,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:2829,usability,error,errors,2829,"t want the full data anyway (that wouldn't really be a small thing I can try). I understand if you can't even subsample from that. How about at least posting the commands you used? From earlier discussions, it sounds like the main thing you're changing about the data representation is the pileup_image_height. You can actually do the same thing on the QuickStart or CaseStudy data too. It will just look like a taller image with the bottom being mostly empty. (You can use logic like this https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb to visualize them). And then, I suspect there's a high probability that you can get the same error on the CaseStudy data if you follow the same steps. Once you're able to do that, post every steps (similar to QuickStart and CaseStudy) here. And note the place where you're having an error. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381167653>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqSFWVfTRnfVvHyl6ecMC-XCahjurks5toMDJgaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1219,availability,error,error-free,1219,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1397,availability,error,errors,1397,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:853,deployability,contain,contains,853,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1325,deployability,contain,contain,1325,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1553,deployability,version,version,1553,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:272,integrability,Sub,Subject,272,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:845,integrability,messag,message,845,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1441,integrability,messag,message,1441,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1553,integrability,version,version,1553,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:845,interoperability,messag,message,845,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:997,interoperability,distribut,distribute,997,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1441,interoperability,messag,message,1441,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1553,modifiability,version,version,1553,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:485,performance,content,content,485,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1219,performance,error,error-free,1219,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1397,performance,error,errors,1397,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1424,performance,content,contents,1424,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1363,reliability,doe,does,1363,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:496,safety,safe,safe,496,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1219,safety,error,error-free,1219,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1397,safety,error,errors,1397,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:236,security,Auth,Author,236,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:244,security,auth,author,244,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:574,security,auth,authored,574,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:780,security,auth,auth,780,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:862,security,confidential,confidential,862,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1208,security,secur,secured,1208,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1254,security,intercept,intercepted,1254,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1501,testability,verif,verification,1501,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1219,usability,error,error-free,1219,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1397,usability,error,errors,1397,"Here is the zip file. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:85,availability,error,error,85,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1331,availability,error,error-free,1331,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1509,availability,error,errors,1509,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:965,deployability,contain,contains,965,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1437,deployability,contain,contain,1437,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1665,deployability,version,version,1665,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:384,integrability,Sub,Subject,384,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:957,integrability,messag,message,957,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1553,integrability,messag,message,1553,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1665,integrability,version,version,1665,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:957,interoperability,messag,message,957,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1109,interoperability,distribut,distribute,1109,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1553,interoperability,messag,message,1553,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1665,modifiability,version,version,1665,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:85,performance,error,error,85,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:597,performance,content,content,597,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1331,performance,error,error-free,1331,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1509,performance,error,errors,1509,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1536,performance,content,contents,1536,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1475,reliability,doe,does,1475,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:85,safety,error,error,85,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:608,safety,safe,safe,608,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1331,safety,error,error-free,1331,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1509,safety,error,errors,1509,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:348,security,Auth,Author,348,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:356,security,auth,author,356,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:686,security,auth,authored,686,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:892,security,auth,auth,892,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:974,security,confidential,confidential,974,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1320,security,secur,secured,1320,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1366,security,intercept,intercepted,1366,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1613,testability,verif,verification,1613,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:85,usability,error,error,85,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1331,usability,error,error-free,1331,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1509,usability,error,errors,1509,". Hello,. Did you receive the attachment I resent on 4/16? Also, any thoughts on the error I was seeing? Thank you and best regards,. Brad Thomas. From: Pi-Chuan Chang [mailto:notifications@github.com]. Sent: Saturday, April 14, 2018 12:09 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi,. I'm not seeing the zip file. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-381304103>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqT_omHfFPRVmhBNx0mJ-jQQyMRMXks5toYR4gaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:101,interoperability,share,share,101,"Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1387,availability,error,error-free,1387,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1565,availability,error,errors,1565,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1021,deployability,contain,contains,1021,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1493,deployability,contain,contain,1493,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1721,deployability,version,version,1721,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:347,integrability,Sub,Subject,347,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1013,integrability,messag,message,1013,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1609,integrability,messag,message,1609,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1721,integrability,version,version,1721,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:678,interoperability,share,share,678,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1013,interoperability,messag,message,1013,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1165,interoperability,distribut,distribute,1165,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1609,interoperability,messag,message,1609,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1721,modifiability,version,version,1721,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:560,performance,content,content,560,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1387,performance,error,error-free,1387,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1565,performance,error,errors,1565,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1592,performance,content,contents,1592,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1531,reliability,doe,does,1531,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:571,safety,safe,safe,571,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1387,safety,error,error-free,1387,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1565,safety,error,errors,1565,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:311,security,Auth,Author,311,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:319,security,auth,author,319,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:742,security,auth,authored,742,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:948,security,auth,auth,948,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1030,security,confidential,confidential,1030,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1376,security,secur,secured,1376,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1422,security,intercept,intercepted,1422,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1669,testability,verif,verification,1669,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1387,usability,error,error-free,1387,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1565,usability,error,errors,1565,"Frustrating. We are blocked from using Google Drive or DropBox. I will send the file from home. Thanks,. Brad Thomas. From: Paul Grosu [mailto:notifications@github.com]. Sent: Tuesday, May 1, 2018 10:50 AM. To: google/deepvariant <deepvariant@noreply.github.com>. Cc: Brad Thomas <brad.thomas@neogenomics.com>; Author <author@noreply.github.com>. Subject: [EXTERNAL]Re: [google/deepvariant] Deep sequencing (#62). CAUTION: This email originated from outside the organization. DO NOT click links or open attachments unless you recognize the sender and know the content is safe. Hi Brad,. Sometimes smtp (email) servers block zip files. Just put it on Google Drive or DropBox and share the link to it. ~p. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/62#issuecomment-385705660>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AifcqWj7l8lWX5469lRFaED45lcY1l0Kks5tuIQogaJpZM4TIm9R>. This message contains confidential information and is intended only for the individual named. If you are not the named addressee you should not disseminate, distribute or copy this e-mail. Please notify the sender immediately by e-mail if you have received this e-mail by mistake and delete this e-mail from your system. E-mail transmission cannot be guaranteed to be secured or error-free as information could be intercepted, corrupted, lost, destroyed, arrive late or incomplete, or contain viruses. The sender therefore does not accept liability for any errors or omissions in the contents of this message, which arise as a result of e-mail transmission. If verification is required please request a hard-copy version. NeoGenomics Laboratories, Suite 5, 12701 Commonwealth Dr, Fort Myers, FL 33913, http://www.neogenomics.com (2017).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:63,availability,ping,ping,63,"Hi,. I'll take a look. Give me a few days. Please feel free to ping back if you don't hear from me by end of this week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:55,availability,error,error,55,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:0,deployability,Updat,Update,0,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:55,performance,error,error,55,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:91,performance,tune,tuned,91,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:0,safety,Updat,Update,0,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:55,safety,error,error,55,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:0,security,Updat,Update,0,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:15,usability,confirm,confirm,15,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:55,usability,error,error,55,Update:. I can confirm that I'm able to reproduce your error. We're working on a fix. Stay tuned!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:390,energy efficiency,predict,predictions,390,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1107,energy efficiency,frequenc,frequency,1107,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:303,safety,avoid,avoid,303,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:314,safety,except,exception,314,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:390,safety,predict,predictions,390,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:515,safety,detect,detection,515,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:980,safety,detect,detect,980,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:515,security,detect,detection,515,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:980,security,detect,detect,980,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:597,usability,support,supported,597,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/62:1141,usability,help,helps,1141,"I've figured out what's going on here and have some good news and bad news. . First, the bad news is that setting the height to 2000 isn't going to work in the short run. This is a limitation coming from inception_v3 itself. At such large image sizes, we would have to run with spatial_squeeze=False to avoid this exception. By doing so we'd essentially end up with a ""tile"" of deepvariant predictions every 64 rows in the image, and then have to pool them together somehow, which makes sense in the general object detection case but not for us in DeepVariant. . The good news is that the maximum supported depth is 362. So you can get a lot more information into your images than the default 100 value. Give 362 a try and let us know if that works. . I should point out that we use a reservoir sampler to create these images. So a height of 362 means you'll get a random sampling of 362 - 5 [for the reference] reads from your very deep sequencing. It's not ideal if you want to detect things occurring in only 1 or 2 reads, but you get a reasonable number of reads if you are looking for things >1% or so frequency in the reads. Hope that helps! Mark",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/62
https://github.com/google/deepvariant/issues/63:518,deployability,releas,released,518,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:381,energy efficiency,current,currently,381,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:444,energy efficiency,model,model,444,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:508,energy efficiency,model,models,508,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:136,security,ident,identify,136,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:308,security,ident,identify,308,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:444,security,model,model,444,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:508,security,model,models,508,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/63:405,usability,document,documentation,405,"Hi,. [Quick Start](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-quick-start.md) provides a quick example of how you identify SNPs and Indels in a small region. [Case Study](https://github.com/google/deepvariant/blob/r0.5/docs/deepvariant-case-study.md) gives you a full example of how to identify SNPs and Indels in a whole genome on a single machine. We don't currently have detailed documentation on how to train your own model. I recommend you start with running DeepVariant using the models we released.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/63
https://github.com/google/deepvariant/issues/64:115,energy efficiency,predict,predict,115,"Yes, the truth_variants have to have genotypes, as these are used to compute the labels that DeepVariant trains to predict. It's not sufficient to just have sites. . As a general comment, we are aware of the need for more information about how to train DeepVariant, which we hope to produce in a reasonable timeframe.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:307,performance,time,timeframe,307,"Yes, the truth_variants have to have genotypes, as these are used to compute the labels that DeepVariant trains to predict. It's not sufficient to just have sites. . As a general comment, we are aware of the need for more information about how to train DeepVariant, which we hope to produce in a reasonable timeframe.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:115,safety,predict,predict,115,"Yes, the truth_variants have to have genotypes, as these are used to compute the labels that DeepVariant trains to predict. It's not sufficient to just have sites. . As a general comment, we are aware of the need for more information about how to train DeepVariant, which we hope to produce in a reasonable timeframe.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/64:28,deployability,releas,release,28,Thank you! Yes - the newest release 0.6.0 has fixed this issue and my truth VCF now works.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/64
https://github.com/google/deepvariant/issues/65:16,testability,understand,understand,16,"Hi,. not sure I understand the question. Have you seen this visualization example? https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. If you want to look at the value of the pileup image, this example can help you understand how to read the images.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/65
https://github.com/google/deepvariant/issues/65:244,testability,understand,understand,244,"Hi,. not sure I understand the question. Have you seen this visualization example? https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. If you want to look at the value of the pileup image, this example can help you understand how to read the images.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/65
https://github.com/google/deepvariant/issues/65:60,usability,visual,visualization,60,"Hi,. not sure I understand the question. Have you seen this visualization example? https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. If you want to look at the value of the pileup image, this example can help you understand how to read the images.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/65
https://github.com/google/deepvariant/issues/65:235,usability,help,help,235,"Hi,. not sure I understand the question. Have you seen this visualization example? https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. If you want to look at the value of the pileup image, this example can help you understand how to read the images.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/65
https://github.com/google/deepvariant/issues/66:48,deployability,instal,installation,48,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:146,deployability,instal,install,146,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:301,deployability,instal,installing,301,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:360,deployability,instal,install,360,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:67,energy efficiency,current,currently,67,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:8,safety,compl,completely,8,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:8,security,compl,completely,8,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:61,usability,guid,guide,61,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:216,usability,support,support,216,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/66:429,usability,help,help,429,"I'm not completely sure about your setting. Our installation guide currently is done on Ubuntu 16. . In your case, it seems like you're unable to install python-wheel? I think that's outside the scope of DeepVariant support. A few possible ways to get unstuck : maybe you can see whether you can skip installing python-wheel, and see what you actually need to install to proceed to the next step. I don't think we can be of more help on this issue. I'm closing this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/66
https://github.com/google/deepvariant/issues/67:14,energy efficiency,current,currently,14,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:527,interoperability,Specif,Specifically,527,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1117,interoperability,format,format,1117,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1133,modifiability,interm,intermediate,1133,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:756,safety,test,testdata,756,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:99,testability,understand,understanding,99,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:756,testability,test,testdata,756,"Hi,. we don't currently have a good tutorial for training mode yet. But a quick answer here - your understanding for the ""labels"" isn't quite correct. 0/0, 0/1, or 1/1 you're referring to is the representation in VCFs, which is HOM-REF, HET, and HOM-ALT. However, that's not how the ""labels"" are represented in the training examples. If you want to see examples of how each of the ""training examples"" that go into training, please look at this:. https://github.com/google/deepvariant/blob/r0.6/docs/visualizing_examples.ipynb. Specifically, this data here was generated with `make_examples` in training mode:. ```. # This tfrecord comes from HG002 PFDA data. I ran make_examples in training mode so we also have the labels. src = 'gs://deepvariant/datalab-testdata/make_examples_datalab.tfrecord.gz'. ```. The ""label"" that represent the 3 classes are actually 0, 1, or 2, which represents HOM-REF, HET, and HOM-ALT. You can see the `get_label` function in the notebook. The representation (0/0, 0/1, 1/1) you're seeing in the final VCF is after `postprocess_variants` step, where we properly write out the common VCF format from the intermediate representation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1228,deployability,Pipelin,Pipeline,1228,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1362,deployability,pipelin,pipeline,1362,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:276,energy efficiency,charg,charge,276,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:506,energy efficiency,model,model,506,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:833,energy efficiency,model,model,833,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1228,integrability,Pipelin,Pipeline,1228,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1362,integrability,pipelin,pipeline,1362,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1304,interoperability,specif,specifically,1304,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:435,performance,perform,perform,435,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:791,safety,input,input,791,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1168,safety,input,input,1168,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1381,safety,prevent,prevent,1381,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1421,safety,compl,completely,1421,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:506,security,model,model,506,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:578,security,modif,modify,578,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:833,security,model,model,833,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1381,security,preven,prevent,1381,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1412,security,ident,identify,1412,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1421,security,compl,completely,1421,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:110,testability,understand,understand,110,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:64,usability,help,helping,64,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:72,usability,clear,clear,72,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:158,usability,document,documentation,158,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:435,usability,perform,perform,435,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:791,usability,input,input,791,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1168,usability,input,input,1168,"Hi,. I see, that actually makes a lot more sense, thank you for helping clear that up. As for the training, I understand that there isn't really any official documentation on adding classes, however I was wondering if I could be pointed towards some of the files/functions in charge of calculating the result of the CNN, to see what needs to be changed for adding additional classes. Another option I was considering that is easier to perform, however is much more computationally heavy, is to train a new model from scratch for each of the classes I wish to add, where I would modify the VCF file given to the 'make_examples' script to make the labels be : 0/0 = undefined, 0/1 = yes, 0/2 = no, and to do this for every new class I wish to add. So I would run the vanilla DeepVariant on my input BAM, then do further runs with each model to further categorize variants that would fall within each of the classes I am examining (can possibly even process the initial output VCF such that the additional runs will only run for within those regions that were initially classified as a variant). Is such an approach possible? If all that is being done is converting each input into 6 channels and have it run through the Inception Pipeline then I believe my approach should be possible. I guess my question specifically is, is there anything within the DeepVariant pipeline that will prevent me from training it to identify completely new classes instead of the default HOM-REF, HET, and HOM-ALT?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:623,availability,down,down,623,"Hi masgouri@, . Thanks for the excellent question and for sharing that you've been having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1917,deployability,version,version,1917,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1125,energy efficiency,core,core,1125," are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1619,energy efficiency,predict,predict,1619,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1995,energy efficiency,predict,predicted,1995,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:2122,energy efficiency,predict,predict,2122,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1917,integrability,version,version,1917,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1979,integrability,bridg,bridge,1979,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1768,interoperability,standard,standard,1768,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1979,interoperability,bridg,bridge,1979,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:2077,interoperability,format,format,2077,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1917,modifiability,version,version,1917,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1953,modifiability,exten,extend,1953,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1532,reliability,doe,doesn,1532,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1684,reliability,doe,doesn,1684,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1619,safety,predict,predict,1619,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1995,safety,predict,predicted,1995,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:2122,safety,predict,predict,2122,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1081,testability,hook,hook,1081,"having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1238,testability,simpl,simple,1238,"ease send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:95,usability,experien,experiences,95,"Hi masgouri@, . Thanks for the excellent question and for sharing that you've been having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:153,usability,user,user,153,"Hi masgouri@, . Thanks for the excellent question and for sharing that you've been having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:210,usability,experien,experiences,210,"Hi masgouri@, . Thanks for the excellent question and for sharing that you've been having good experiences with DeepVariant. We are always interested in user stories so if you feel like sharing more about your experiences with DeepVariant please send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1238,usability,simpl,simple,1238,"ease send them our way. There are a few separate issues here; let me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1425,usability,learn,learn,1425,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1610,usability,learn,learn,1610,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:1857,usability,learn,learning,1857,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:2113,usability,learn,learn,2113,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/issues/67:2292,usability,help,helps,2292,"et me try to unpack them. -- There are some engineering constraints in DeepVariant that assume we train only 3 classes. One example is https://github.com/google/deepvariant/search?utf8=%E2%9C%93&q=DEFAULT_NUM_CLASSES&type= but there may be others. If you want to change the number of classes you'll need to track these down and generalize them. If you do that please send us a CL and we'll make sure to incorporate the changes into the master codebase here. Once you do that it should be possible to train as with as many labels as you like. -- You'll need to write your own labeler algorithm to provide a label for each training variant. These classes are in deepvariant/labeler. There are two (a PositionalLabeler and a HaplotypeLabeler) so you can use these as templates to hook up your own labeling algorithm. At the core these just need to return an integer label (0 ... N) for each example. Once you get that going it should be simple to label your own examples. Technically the labels can be anything. For example, if you emitted the reference base value as 0 for A, 1 for T, etc I'm pretty sure the machinery can learn to call the reference base from the image with perfect accuracy. -- The machinery of training really doesn't know anything about NGS data. It just takes the examples and tries to learn to predict the label. Once you get your labels in and the machinery doesn't expect just 3 it should be possible to train anything you want. You can use standard evaluation machinery to decide if your DeepVariant training run is successfully learning something. -- You'll likely need to write your own version of postprocess_variants (or extend it in some way) to bridge from the predicted labels and the information you want to export in the VCF (or other file format). In germline DeepVariant we learn to predict 0, 1, and 2 which mean hom-ref, het, and hom-alt, respectively, which is encoded in postprocess_variants. You'll need your own equivalent to this code. Hope this helps! Mark.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/67
https://github.com/google/deepvariant/pull/68:126,deployability,version,version,126,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:147,deployability,releas,release,147,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:46,energy efficiency,current,currently,46,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:126,integrability,version,version,126,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:126,modifiability,version,version,126,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:190,testability,plan,plan,190,"Thanks for the report. Unfortunately we can't currently take pull request from GitHub. . This include is fixed in an internal version, but the 0.6 release was cut before that change. I will plan to create a 0.6.1 to include this fix.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:28,usability,close,closed,28,Sure. Np. I'll mark this PR closed then.``,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:48,deployability,releas,released,48,"Hi @wangtz , thanks again for reporting. . I've released v0.6.1 which should addressed the issue you reported. https://github.com/google/deepvariant/releases/tag/v0.6.1. Please let me know if you see other problems.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/pull/68:149,deployability,releas,releases,149,"Hi @wangtz , thanks again for reporting. . I've released v0.6.1 which should addressed the issue you reported. https://github.com/google/deepvariant/releases/tag/v0.6.1. Please let me know if you see other problems.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/68
https://github.com/google/deepvariant/issues/69:196,interoperability,Specif,Specifically,196,"The content of the file seems wrong to me:. ```. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1. ```. Specifically, do you really just have one example in that `examples.tfrecord.gz` file? It doesn't really make sense to train on a file with one record, and I actually suspect weird things could happen. Can you create a more realistic training file, say, with at least 10,000 examples, and try again?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:4,performance,content,content,4,"The content of the file seems wrong to me:. ```. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1. ```. Specifically, do you really just have one example in that `examples.tfrecord.gz` file? It doesn't really make sense to train on a file with one record, and I actually suspect weird things could happen. Can you create a more realistic training file, say, with at least 10,000 examples, and try again?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:286,reliability,doe,doesn,286,"The content of the file seems wrong to me:. ```. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1. ```. Specifically, do you really just have one example in that `examples.tfrecord.gz` file? It doesn't really make sense to train on a file with one record, and I actually suspect weird things could happen. Can you create a more realistic training file, say, with at least 10,000 examples, and try again?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:107,usability,Document,Documents,107,"The content of the file seems wrong to me:. ```. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/wangpeng/testmake_examples/output/examples.tfrecord.gz"". num_examples: 1. ```. Specifically, do you really just have one example in that `examples.tfrecord.gz` file? It doesn't really make sense to train on a file with one record, and I actually suspect weird things could happen. Can you create a more realistic training file, say, with at least 10,000 examples, and try again?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:587,energy efficiency,model,model,587,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:11,safety,test,testdata,11,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:105,safety,test,testdata,105,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:587,security,model,model,587,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:11,testability,test,testdata,11,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:105,testability,test,testdata,105,"We use the testdata from DeepVariant source (https://github.com/google/deepvariant/tree/r0.6/deepvariant/testdata) .The test_nist.b37_chr20_100kbp_at_10mb.bed is really small, so we just can set one example in that examples.tfrecord.gz. . **test_nist.b37_chr20_100kbp_at_10mb.bed file:**. > chr20	10000846	10002407. chr20	10002520	10004171. chr20	10004273	10004964. chr20	10004994	10006386. chr20	10006409	10007800. chr20	10007824	10008018. chr20	10008043	10008079. chr20	10008100	10008707. chr20	10008808	10008897. chr20	10009002	10009791. chr20	10009933	10010531. We will try to train model with our realistic WES data, and set with at least 10,000 examples. Thanks",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1204,availability,echo,echo,1204,"ord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-0",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1196,deployability,log,logs,1196,"ne tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1303,deployability,log,log,1303,"me? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1578,deployability,log,log,1578,"/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:23,energy efficiency,model,model,23,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:285,energy efficiency,model,model,285,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:444,energy efficiency,model,model-,444,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:526,energy efficiency,MODEL,MODEL,526,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:547,energy efficiency,model,model,547,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3468,energy efficiency,model,model-,3468,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3548,energy efficiency,model,model,3548,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:138,interoperability,share,shared,138,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:91,performance,parallel,parallel,91,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:303,performance,time,time,303,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1232,performance,time,time,1232,"How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmd",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1264,performance,parallel,parallel,1264,"rd file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-0002",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:118,safety,input,input,118,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:191,safety,input,input,191,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:245,safety,input,input,245,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1196,safety,log,logs,1196,"ne tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1303,safety,log,log,1303,"me? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1578,safety,log,log,1578,"/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2948,safety,input,input,2948,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:23,security,model,model,23,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:285,security,model,model,285,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:444,security,model,model-,444,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:526,security,MODEL,MODEL,526,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:547,security,model,model,547,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1196,security,log,logs,1196,"ne tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1303,security,log,log,1303,"me? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1578,security,log,log,1578,"/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3468,security,model,model-,3468,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3548,security,model,model,3548,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1196,testability,log,logs,1196,"ne tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1303,testability,log,log,1303,"me? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1578,testability,log,log,1578,"/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:100,usability,tool,tool,100,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:118,usability,input,input,118,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:191,usability,input,input,191,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:245,usability,input,input,245,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:358,usability,Document,Documents,358,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:670,usability,Document,Documents,670,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:754,usability,Document,Documents,754,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:930,usability,Document,Documents,930,"We have tried to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:1006,usability,Document,Documents,1006,"ed to train model with the realisitic WES data. The script can pass.We used GNU parallel tool to split the input and generates shared output. But we met a problem that we just can input one tfrecord file to the pbtxt file. How can we input all of the tfrecord file to train model at the same time? **The make_examples script is:**. `BASE=""${HOME}/Documents/source"". BIN_DIR=""${BASE}/bin"". MODELS_DIR=""${BASE}/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard"". MODEL=""${MODELS_DIR}/model.ckpt"". N_SHARDS=""64"". BAM=""/sdbdata/WESdata/CL100026859_bwa/CL100026859_L02_14/PE150.2.rmdup.bam"". REF=""/home/suanfa/Documents/source/ref/hg19.fasta"". var=${BAM##*/}. var=${var%.*}. path=""/home/suanfa/Documents/shishiming/training_WES_model"". OUTPUT_DIR=""$path/output"". EXAMPLES=""${OUTPUT_DIR}/${var}.training.examples.tfrecord@${N_SHARDS}.gz"". CONFIDENT_REGIONS=""/home/suanfa/Documents/source/exome_region_bed/new_v4.bed"". TRUTH_VARIANTS=""/home/suanfa/Documents/source/NISTv3.3_baseline/HG001_GRCh37_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.new_ch rID.vcf.gz"". LOG_DIR=""${OUTPUT_DIR}/logs"" . echo 'Run make_examples'. ( time seq 0 $((N_SHARDS-1)) | \. parallel --halt 2 --joblog ""${LOG_DIR}/log"" --res ""${LOG_DIR}"" \. python ""${BIN_DIR}""/make_examples.zip \. --mode training \. --ref ""${REF}"" \. --reads ""${BAM}"" \. --examples ""${EXAMPLES}"" \. --confident_regions ${CONFIDENT_REGIONS} \. --truth_variants ${TRUTH_VARIANTS} \. --task {}. ) >""${LOG_DIR}/make_examples.log"" 2>&1`. **the part of the examples output:**. > PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.ex",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:2948,usability,input,input,2948,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3111,usability,Document,Documents,3111,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3293,usability,Document,Documents,3293,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:3427,usability,Document,Documents,3427,"00000-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00022-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00044-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00001-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00023-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00045-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00002-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00024-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00046-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00003-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00025-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00047-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00004-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00026-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00048-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00005-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00027-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00049-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00006-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00028-of-00064.gz PE150.2.rmdup.training.examples.tfrecord-00050-of-00064.gz. PE150.2.rmdup.training.examples.tfrecord-00007-of-00064.gz . ..... Just input the first tfrecord file to my-training-dataset.pbtxt file. **my-training-dataset.pbtxt file:**. `. name: ""my-training-dataset"". tfrecord_path: ""/home/suanfa/Documents/shishiming/training_WES_model/output/PE150.2.rmdup.training.examples.tfrecord-00000-of-00064.gz"". num_examples: 64. `. **The model_train script is:**. `python /home/suanfa/Documents/source/bin/model_train.zip \. --dataset_config_pbtxt ""./my-training-dataset.pbtxt"" \. --start_from_checkpoint ""/home/suanfa/Documents/source/DeepVariant/deepvariant-model-wes_and_wgs/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wes_standard/model.ckpt"" \. --batch_size 32 \. --train_dir ""/tmp/deepvariant/wex"" \. --number_of_steps 30000 \. --learning_rate 0.001. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:272,energy efficiency,Current,Currently,272,"Good to hear you're making progress. You can use patterns like:. ```. name: ""train"". tfrecord_path: ""/path/to/wes_train.examples-?????-of-00256.tfrecord.gz"". num_examples: 15705449. ```. Note: in order for the training to work correctly, you need to shuffle the examples. Currently we rely on the examples already being shuffled, and we don't do shuffling in the tensorflow training parti.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/69:27,usability,progress,progress,27,"Good to hear you're making progress. You can use patterns like:. ```. name: ""train"". tfrecord_path: ""/path/to/wes_train.examples-?????-of-00256.tfrecord.gz"". num_examples: 15705449. ```. Note: in order for the training to work correctly, you need to shuffle the examples. Currently we rely on the examples already being shuffled, and we don't do shuffling in the tensorflow training parti.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/69
https://github.com/google/deepvariant/issues/70:69,energy efficiency,Cloud,Cloud,69,"Hi, thanks for reporting. We're aware of this issue and a fix on the Cloud side will soon be out. We'll let you know when the fix is out. Meanwhile, a workaround is to explicitly set ""--call_variants_cores_per_worker 8"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:73,availability,error,error,73,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:187,availability,FAILUR,FAILURE,187,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:199,availability,Error,Error,199,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:475,availability,ERROR,ERROR,475,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,availability,error,error,524,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:534,availability,Error,Error,534,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2274,availability,error,error,2274,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2284,availability,Error,Error,2284,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:187,deployability,FAIL,FAILURE,187,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:260,deployability,Fail,Failed,260,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:286,deployability,fail,failed,286,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:512,deployability,fail,failed,512,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:595,deployability,Fail,Failed,595,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:621,deployability,fail,failed,621,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:836,deployability,log,logging,836,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:883,deployability,stage,stage,883,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:889,deployability,log,logs,889,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1331,deployability,stage,stage,1331,"/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1916,deployability,modul,module,1916,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2262,deployability,fail,failed,2262,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2345,deployability,Fail,Failed,2345,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2371,deployability,fail,failed,2371,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1357,energy efficiency,core,cores,1357,"Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to local",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1916,modifiability,modul,module,1916,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:73,performance,error,error,73,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:187,performance,FAILUR,FAILURE,187,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:199,performance,Error,Error,199,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:475,performance,ERROR,ERROR,475,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,performance,error,error,524,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:534,performance,Error,Error,534,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:904,performance,disk,disk-size,904,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1392,performance,disk,disk-size,1392,"/mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local direc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1595,performance,parallel,parallel,1595,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2274,performance,error,error,2274,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2284,performance,Error,Error,2284,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:187,reliability,FAIL,FAILURE,187,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:260,reliability,Fail,Failed,260,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:286,reliability,fail,failed,286,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:512,reliability,fail,failed,512,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:595,reliability,Fail,Failed,595,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:621,reliability,fail,failed,621,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2262,reliability,fail,failed,2262,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2345,reliability,Fail,Failed,2345,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2371,reliability,fail,failed,2371,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:73,safety,error,error,73,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:199,safety,Error,Error,199,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:335,safety,input,input,335,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:411,safety,input,input,411,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:475,safety,ERROR,ERROR,475,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,safety,error,error,524,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:534,safety,Error,Error,534,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:670,safety,input,input,670,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:746,safety,input,input,746,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:836,safety,log,logging,836,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:889,safety,log,logs,889,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1059,safety,input,input,1059,"8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1916,safety,modul,module,1916,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2274,safety,error,error,2274,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2284,safety,Error,Error,2284,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2420,safety,input,input,2420,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2496,safety,input,input,2496,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:836,security,log,logging,836,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:889,security,log,logs,889,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:836,testability,log,logging,836,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:889,testability,log,logs,889,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1804,testability,Trace,Traceback,1804,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:73,usability,error,error,73,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:199,usability,Error,Error,199,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:335,usability,input,input,335,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:411,usability,input,input,411,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:475,usability,ERROR,ERROR,475,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,usability,error,error,524,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:534,usability,Error,Error,534,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:670,usability,input,input,670,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:746,usability,input,input,746,"Hi Pi-Chuan,. Thanks. I set `--call_variants_cores_per_worker 8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 6",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1059,usability,input,input,1059,"8` and new error pops out. It would be great if guys can take a look of it as well. ```. make-examp--root--180505-205721-02: FAILURE. [u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']. [05/05/2018 21:27:38 ERROR gcp_deepvariant_runner.py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1500,usability,command,command,1500,"py] Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2274,usability,error,error,2274,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2284,usability,Error,Error,2284,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2420,usability,input,input,2420,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2496,usability,input,input,2496,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2547,usability,statu,status,2547,"ot--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxx: no space left on device']]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://xxxxx/wliang_deepvariant/ooooo.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'make_examples', '--image', 'gcr.io/deepvariant-docker/deepvariant:0.6.0', '--input', 'INPUT_BAM=gs://yyyyy.bam', 'INPUT_BAI=gs://yyyyy.bam.bai', 'INPUT_REF=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta', 'INPUT_REF_FAI=gs://xxxxx/reference/Homo_sapiens_assembly19.fasta.fai', '--output-recursive', 'EXAMPLES=gs://xxxxx/wliang_deepvariant/ooooo.stage/examples/0', '--min-cores', '8', '--min-ram', '30', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=0', '--env', 'SHARD_END_INDEX=511', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | parallel --halt 2 \\\n ./make_examples \\\n --mode calling \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord@""${SHARDS}"".gz \\\n --reads ""${INPUT_BAM}"" \\\n --ref ""${INPUT_REF}"" \\\n --task {} \\\n \n']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 638, in run. _run_make_examples(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 266, in _run_make_examples. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u'Error in job make-examp--root--180505-205721-02 - code 5: 9: Failed to localize files: failed to make local directory for /mnt/datadisk/input/gs/xxxxx/reference/Homo_sapiens_assembly19.fasta: mkdir /mnt/datadisk/input/gs/xxxxxx: no space left on device']]. (exit status 1). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:243,deployability,pipelin,pipeline,243,"Hi,. for your question in: https://github.com/google/deepvariant/issues/70#issuecomment-386838731. you'll need to set `--make_examples_disk_per_worker_gb` to a large enough value based on the size of their BAMs. We set it to 200gb for the WGS pipeline (it's set to 50gb by default; for quickstart). You'll need to change that if you have a really large BAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:243,integrability,pipelin,pipeline,243,"Hi,. for your question in: https://github.com/google/deepvariant/issues/70#issuecomment-386838731. you'll need to set `--make_examples_disk_per_worker_gb` to a large enough value based on the size of their BAMs. We set it to 200gb for the WGS pipeline (it's set to 50gb by default; for quickstart). You'll need to change that if you have a really large BAM.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:30,deployability,releas,release,30,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:63,deployability,updat,update,63,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:76,deployability,version,version,76,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:123,energy efficiency,cloud,cloud,123,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:76,integrability,version,version,76,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:76,modifiability,version,version,76,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:63,safety,updat,update,63,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:63,security,updat,update,63,The issue is fixed with 0.6.1 release of docker images. Please update image version to. `IMAGE_VERSION=0.6.1`. See https://cloud.google.com/genomics/deepvariant for more info.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,availability,error,error,102,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:159,availability,FAILUR,FAILURE,159,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:171,availability,Error,Error,171,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:267,availability,Error,Error,267,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:465,availability,ERROR,ERROR,465,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:514,availability,error,error,514,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,availability,Error,Error,524,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:620,availability,Error,Error,620,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1932,availability,checkpoint,checkpoint,1932,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2510,availability,error,error,2510,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2520,availability,Error,Error,2520,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2616,availability,Error,Error,2616,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:159,deployability,FAIL,FAILURE,159,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,deployability,fail,failed,229,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:303,deployability,resourc,resource,303,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:502,deployability,fail,failed,502,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:582,deployability,fail,failed,582,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:656,deployability,resourc,resource,656,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:844,deployability,log,logging,844,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:891,deployability,stage,stage,891,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:897,deployability,log,logs,897,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1135,deployability,stage,stage,1135,"t--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1343,deployability,stage,stage,1343,"unt': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2152,deployability,modul,module,2152,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2498,deployability,fail,failed,2498,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2578,deployability,fail,failed,2578,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2652,deployability,resourc,resource,2652,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:303,energy efficiency,resourc,resource,303,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:656,energy efficiency,resourc,resource,656,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1156,energy efficiency,MODEL,MODEL,1156,"FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1179,energy efficiency,model,models,1179,"b call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1374,energy efficiency,core,cores,1374,"be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1946,energy efficiency,MODEL,MODEL,1946,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1954,energy efficiency,model,model,1954,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2652,energy efficiency,resourc,resource,2652,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2152,modifiability,modul,module,2152,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,performance,error,error,102,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:159,performance,FAILUR,FAILURE,159,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:171,performance,Error,Error,171,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:267,performance,Error,Error,267,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:303,performance,resourc,resource,303,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:465,performance,ERROR,ERROR,465,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:514,performance,error,error,514,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,performance,Error,Error,524,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:620,performance,Error,Error,620,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:656,performance,resourc,resource,656,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:912,performance,disk,disk-size,912,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1409,performance,disk,disk-size,1409,"s in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2510,performance,error,error,2510,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2520,performance,Error,Error,2520,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2616,performance,Error,Error,2616,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2652,performance,resourc,resource,2652,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:159,reliability,FAIL,FAILURE,159,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:229,reliability,fail,failed,229,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:502,reliability,fail,failed,502,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:582,reliability,fail,failed,582,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1932,reliability,checkpoint,checkpoint,1932,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2498,reliability,fail,failed,2498,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2578,reliability,fail,failed,2578,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,safety,error,error,102,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:171,safety,Error,Error,171,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:267,safety,Error,Error,267,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:303,safety,resourc,resource,303,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:465,safety,ERROR,ERROR,465,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:514,safety,error,error,514,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,safety,Error,Error,524,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:620,safety,Error,Error,620,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:656,safety,resourc,resource,656,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:844,safety,log,logging,844,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:897,safety,log,logs,897,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1071,safety,input,input-recursive,1071,"er_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2152,safety,modul,module,2152,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2510,safety,error,error,2510,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2520,safety,Error,Error,2520,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2616,safety,Error,Error,2616,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2652,safety,resourc,resource,2652,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:844,security,log,logging,844,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:897,security,log,logs,897,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1156,security,MODEL,MODEL,1156,"FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1179,security,model,models,1179,"b call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/dee",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1946,security,MODEL,MODEL,1946,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1954,security,model,model,1954,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:303,testability,resourc,resource,303,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:656,testability,resourc,resource,656,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:844,testability,log,logging,844,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:897,testability,log,logs,897,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2040,testability,Trace,Traceback,2040,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2652,testability,resourc,resource,2652,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,usability,error,error,102,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:171,usability,Error,Error,171,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:267,usability,Error,Error,267,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:465,usability,ERROR,ERROR,465,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:514,usability,error,error,514,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:524,usability,Error,Error,524,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:620,usability,Error,Error,620,"Hi Pi-Chuan, . I used 0.6.1 docker images and also set `--call_variants_cores_per_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1071,usability,input,input-recursive,1071,"er_worker 8`, but same error pops out. ```. call-varia--root--180508-211940-52: FAILURE. [u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]. [05/08/2018 21:19:51 ERROR gcp_deepvariant_runner.py] Job failed with error [[u""Error in job call-varia--root--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. Fil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1549,usability,command,command,1549,"--180508-211940-52 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. Job args: ['--project', 'isb-cgc-06-0004', '--logging', 'gs://WWWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--18",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2510,usability,error,error,2510,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2520,usability,Error,Error,2520,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2616,usability,Error,Error,2616,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:2800,usability,statu,status,2800,"WWWW/wliang_deepvariant/XXXXX.stage/logs', '--boot-disk-size', '50', '--zones', 'us-west1-b', 'us-east1-d', '--wait', '--name', 'call_variants', '--image', 'gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1', '--input-recursive', 'EXAMPLES=gs://WWWWW/wliang_deepvariant/XXXXX.stage/examples/15', 'MODEL=gs://deepvariant/models/DeepVariant/0.6.0/DeepVariant-inception_v3-0.6.0+cl-191676894.data-wgs_standard', '--output-recursive', 'CALLED_VARIANTS=gs://WWWWW/wliang_deepvariant/XXXXX.stage/called_variants', '--min-cores', '8', '--min-ram', '60', '--disk-size', '50', '--env', 'SHARDS=512', '--env', 'SHARD_START_INDEX=480', '--env', 'SHARD_END_INDEX=511', '--env', 'CONCURRENT_JOBS=1', '--command', '\ncd /opt/deepvariant/bin/ && \\\nseq -f ""%05g"" ""${SHARD_START_INDEX}"" ""${SHARD_END_INDEX}"" | \\\nparallel --jobs ""${CONCURRENT_JOBS}"" --halt 2 \\\n./call_variants \\\n --examples ""${EXAMPLES}""/examples_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --outfile ""${CALLED_VARIANTS}""/call_variants_output.tfrecord-{}-of-""$(printf ""%05d"" ""${SHARDS}"")"".gz \\\n --checkpoint ""${MODEL}""/model.ckpt\n', '--accelerator-type', 'nvidia-tesla-k80', '--accelerator-count', '1']. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180508-211910-49 - code 2: failed to insert instance: googleapi: Error 400: Invalid value for field 'resource.guestAccelerators[0].acceleratorCount': '1'. At most 8 vCPUs can be used along with 1 accelerator cards in an instance., invalid""]]. (exit status 1). ```. Would you mind taking a look of this? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:29,deployability,log,log,29,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:7,interoperability,share,share,7,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:29,safety,log,log,29,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:29,security,log,log,29,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:29,testability,log,log,29,"Please share the full runner log, as well as config (YAML) file used.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:30,deployability,log,log,30,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,deployability,log,log,102,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:223,deployability,log,log,223,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:294,deployability,log,log,294,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:415,deployability,log,log,415,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:479,deployability,log,log,479,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:593,deployability,log,log,593,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:30,safety,log,log,30,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,safety,log,log,102,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:223,safety,log,log,223,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:294,safety,log,log,294,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:415,safety,log,log,415,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:479,safety,log,log,479,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:593,safety,log,log,593,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:30,security,log,log,30,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,security,log,log,102,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:223,security,log,log,223,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:294,security,log,log,294,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:415,security,log,log,415,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:479,security,log,log,479,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:593,security,log,log,593,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:30,testability,log,log,30,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:102,testability,log,log,102,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:223,testability,log,log,223,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:294,testability,log,log,294,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:415,testability,log,log,415,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:479,testability,log,log,479,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:593,testability,log,log,593,The following are full runner log. . [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1986206/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1986207/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1986208/ENHvj4m0LBjriPO-qfLP3oABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log). Please find the yaml file and the runner bash script here: https://github.com/ding-lab/RegulatoryGermline/tree/master/deepvariant. Thanks.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:10,testability,verif,verify,10,Could you verify setting call_variants_ram_per_worker_gb to 30 solves the issue?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:95,availability,avail,available,95,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:628,availability,error,error,628,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:638,availability,Error,Error,638,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:734,availability,Error,Error,734,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:79,deployability,resourc,resource,79,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:270,deployability,modul,module,270,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:616,deployability,fail,failed,616,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:696,deployability,fail,failed,696,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:749,deployability,resourc,resource,749,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:911,deployability,log,log,911,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1029,deployability,log,log,1029,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1150,deployability,log,log,1150,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1221,deployability,log,log,1221,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1342,deployability,log,log,1342,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1406,deployability,log,log,1406,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1520,deployability,log,log,1520,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:79,energy efficiency,resourc,resource,79,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:749,energy efficiency,resourc,resource,749,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:270,modifiability,modul,module,270,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:79,performance,resourc,resource,79,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:628,performance,error,error,628,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:638,performance,Error,Error,638,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:734,performance,Error,Error,734,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:749,performance,resourc,resource,749,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:95,reliability,availab,available,95,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:616,reliability,fail,failed,616,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:696,reliability,fail,failed,696,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:79,safety,resourc,resource,79,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:95,safety,avail,available,95,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:270,safety,modul,module,270,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:628,safety,error,error,628,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:638,safety,Error,Error,638,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:734,safety,Error,Error,734,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:749,safety,resourc,resource,749,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:911,safety,log,log,911,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1029,safety,log,log,1029,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1150,safety,log,log,1150,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1221,safety,log,log,1221,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1342,safety,log,log,1342,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1406,safety,log,log,1406,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1520,safety,log,log,1520,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:95,security,availab,available,95,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:911,security,log,log,911,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1029,security,log,log,1029,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1150,security,log,log,1150,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1221,security,log,log,1221,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1342,security,log,log,1342,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1406,security,log,log,1406,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1520,security,log,log,1520,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:79,testability,resourc,resource,79,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:158,testability,Trace,Traceback,158,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:749,testability,resourc,resource,749,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:911,testability,log,log,911,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1029,testability,log,log,1029,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1150,testability,log,log,1150,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1221,testability,log,log,1221,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1342,testability,log,log,1342,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1406,testability,log,log,1406,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:1520,testability,log,log,1520,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:628,usability,error,error,628,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:638,usability,Error,Error,638,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:734,usability,Error,Error,734,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:870,usability,statu,status,870,"Hi Nima, . I set the `--call_variants_ram_per_worker_gb 30`, and it seems like resource is not available. . ```. call-varia--root--180510-193828-03: SUCCESS. Traceback (most recent call last):. File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 655, in <module>. run(). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 642, in run. _run_call_variants(pipeline_args). File ""/opt/deepvariant_runner/src/gcp_deepvariant_runner.py"", line 322, in _run_call_variants. result.get(). File ""/usr/lib/python2.7/multiprocessing/pool.py"", line 567, in get. raise self._value. RuntimeError: Job failed with error [[u""Error in job call-varia--root--180510-193818-02 - code 2: failed to insert instance: googleapi: Error 404: The resource 'projects/isb-cgc-06-0004/zones/us-west1-a/acceleratorTypes/nvidia-tesla-k80' was not found, notFound""]]. (exit status 1). ```. Here are the full runner log. You can find out the yam file in the same repo. [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log](https://github.com/google/deepvariant/files/1993190/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stderr.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log](https://github.com/google/deepvariant/files/1993191/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl-stdout.log). [ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log](https://github.com/google/deepvariant/files/1993192/ELj2mta0LBjZy6CkirjPx8ABIOjMyffEGCoPcHJvZHVjdGlvblF1ZXVl.log).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:26,energy efficiency,GPU,GPU,26,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:111,energy efficiency,cloud,cloud,111,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:198,energy efficiency,GPU,GPU,198,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:211,energy efficiency,cloud,cloud,211,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:26,performance,GPU,GPU,26,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:198,performance,GPU,GPU,198,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:13,reliability,doe,doesn,13,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:88,usability,document,documentation,88,`us-west1-a` doesn't have GPU VM. Try `us-west1-b` (this is what we recoomended in the [documentation](https://cloud.google.com/genomics/deepvariant)). See following page for the list of zones with GPU. https://cloud.google.com/compute/docs/regions-zones/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/70:13,energy efficiency,cloud,cloud,13,Here https://cloud.google.com/compute/quotas#request_quotas,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/70
https://github.com/google/deepvariant/issues/71:124,availability,error,error,124,I suspect there's a problem with your BED file. Is there a bad interval in that BED file? I wonder if there's an off-by-one error somewhere in the BED reader (I really hope not).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:124,performance,error,error,124,I suspect there's a problem with your BED file. Is there a bad interval in that BED file? I wonder if there's an off-by-one error somewhere in the BED reader (I really hope not).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:124,safety,error,error,124,I suspect there's a problem with your BED file. Is there a bad interval in that BED file? I wonder if there's an off-by-one error somewhere in the BED reader (I really hope not).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:124,usability,error,error,124,I suspect there's a problem with your BED file. Is there a bad interval in that BED file? I wonder if there's an off-by-one error somewhere in the BED reader (I really hope not).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:44,testability,simpl,simply,44,Thank you - I'm attaching my BED file which simply defines the entire length of the chromosome (I am working on a bacterium):. NC_000962.3 0	4411531. Is this an issue with a non-human genome? (Saved with a .txt so that I could upload.). [confidence.bed.txt](https://github.com/google/deepvariant/files/1986525/confidence.bed.txt).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:44,usability,simpl,simply,44,Thank you - I'm attaching my BED file which simply defines the entire length of the chromosome (I am working on a bacterium):. NC_000962.3 0	4411531. Is this an issue with a non-human genome? (Saved with a .txt so that I could upload.). [confidence.bed.txt](https://github.com/google/deepvariant/files/1986525/confidence.bed.txt).,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:56,interoperability,share,share,56,This seems like a genuine bug. Is there any way you can share the genome reference and reads along with a command line that reproduces the issue? It's not clear to me what the actual issue is and that would help a lot debugging the actual problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:106,usability,command,command,106,This seems like a genuine bug. Is there any way you can share the genome reference and reads along with a command line that reproduces the issue? It's not clear to me what the actual issue is and that would help a lot debugging the actual problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:155,usability,clear,clear,155,This seems like a genuine bug. Is there any way you can share the genome reference and reads along with a command line that reproduces the issue? It's not clear to me what the actual issue is and that would help a lot debugging the actual problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:207,usability,help,help,207,This seems like a genuine bug. Is there any way you can share the genome reference and reads along with a command line that reproduces the issue? It's not clear to me what the actual issue is and that would help a lot debugging the actual problem.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:269,safety,test,test,269,"Thank you for looking into this. I'm running DeepVariant on a docker image. Below is my command line. My reference genome, reads, and truth VCF are 300Mb, so I will send via email if that is okay. ```. ref=H37Rv.fa. BAM=GCA_000193185.1_1_1.bowtie2.rmdup.bam. TRUTH_VCF=test.vcf.gz. base=${BAM%.rmdup.bam}. /opt/deepvariant/bin/make_examples --mode training --ref ${ref} --reads ${BAM} --examples ${base}.tfrecord --truth_variants ${TRUTH_VCF} --confident_regions confidence.bed . ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:269,testability,test,test,269,"Thank you for looking into this. I'm running DeepVariant on a docker image. Below is my command line. My reference genome, reads, and truth VCF are 300Mb, so I will send via email if that is okay. ```. ref=H37Rv.fa. BAM=GCA_000193185.1_1_1.bowtie2.rmdup.bam. TRUTH_VCF=test.vcf.gz. base=${BAM%.rmdup.bam}. /opt/deepvariant/bin/make_examples --mode training --ref ${ref} --reads ${BAM} --examples ${base}.tfrecord --truth_variants ${TRUTH_VCF} --confident_regions confidence.bed . ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:88,usability,command,command,88,"Thank you for looking into this. I'm running DeepVariant on a docker image. Below is my command line. My reference genome, reads, and truth VCF are 300Mb, so I will send via email if that is okay. ```. ref=H37Rv.fa. BAM=GCA_000193185.1_1_1.bowtie2.rmdup.bam. TRUTH_VCF=test.vcf.gz. base=${BAM%.rmdup.bam}. /opt/deepvariant/bin/make_examples --mode training --ref ${ref} --reads ${BAM} --examples ${base}.tfrecord --truth_variants ${TRUTH_VCF} --confident_regions confidence.bed . ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:36,availability,error,error,36,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:36,performance,error,error,36,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:36,safety,error,error,36,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:5,usability,confirm,confirming,5,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:36,usability,error,error,36,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:222,usability,command,command,222,"Just confirming I can reproduce the error myself. I think I know what the problem is. In the meantime you can use the previous labeling algorithm as a workaround. Just add ' --labeler_algorithm positional_labeler' to your command line, which is working for me just fine right now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:16,safety,test,test,16,Thank you! I'll test that out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:16,testability,test,test,16,Thank you! I'll test that out.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/71:123,deployability,releas,release,123,The fix for the issue with the haplotype_labeler is ready in the internal codebase and will appear in the next DeepVariant release. Thanks for working through these issues with us.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/71
https://github.com/google/deepvariant/issues/72:213,availability,error,error,213,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:397,availability,error,errors,397,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:432,availability,failur,failure,432,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:432,deployability,fail,failure,432,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:654,deployability,fail,failed,654,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1099,interoperability,specif,specify,1099,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:213,performance,error,error,213,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:397,performance,error,errors,397,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:432,performance,failur,failure,432,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:635,performance,parallel,parallel,635,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1165,performance,time,time,1165,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:432,reliability,fail,failure,432,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:455,reliability,doe,does,455,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:654,reliability,fail,failed,654,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:213,safety,error,error,213,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:397,safety,error,errors,397,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:699,safety,input,input,699,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:777,safety,input,input,777,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:838,safety,input,input,838,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:97,usability,user,user,97,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:102,usability,guid,guide,102,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:213,usability,error,error,213,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:397,usability,error,errors,397,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:411,usability,Command,Command,411,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:520,usability,command,command,520,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:699,usability,input,input,699,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:777,usability,input,input,777,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:838,usability,input,input,838,"Further to this question, I am trying to run 2 chromosome for the whole genome case study. . The user guide said that we can do ```--regions "" chr20 chr21"" ``` to run both chromosome, however, I get the following error when I run the make sample with ``` --regions ""chr20 chr21"" ```. I have also tried ```--regions ""20 21""```, but none of these works. . ```. E0814 18:04:05.051175 140174423590656 errors.py:64] Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_D92FlN/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '21']"". parallel: This job failed:. python /HD_disk/real-case-study-chr/input/bin/make_examples.zip --mode calling --ref /HD_disk/real-case-study-chr/input/data/hs37d5.fa.gz --reads /HD_disk/real-case-study-chr/input/data/HG002_NIST_150bp_50x.bam --examples /HD_disk/real-case-study-chr/output_1_2_3/HG002.examples.tfrecord@8.gz --regions 20 21 --gvcf /HD_disk/real-case-study-chr/output_1_2_3/HG002.gvcf.tfrecord@8.gz --task 2. ```. Would you please suggest how I should specify the region to get multiple chromosome running at the same time. For single chromosome, ``` --regions ""20"" ``` works fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:166,availability,error,error,166,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:474,availability,error,error,474,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:166,performance,error,error,166,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:474,performance,error,error,474,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:166,safety,error,error,166,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:474,safety,error,error,474,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:7,testability,verif,verified,7,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:166,usability,error,error,166,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:474,usability,error,error,474,"I just verified that --regions ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" in fact processes two regions. So make_examples is working as expected. Your error looks like it is caused by missing the quotes around the regions argument. So make_examples interprets:. `... --regions 20 21 --gvcf /HD_disk/real-case...`. as . `... --regions 20` <= keyword args for make_examples. `21 --gvcf /HD_disk/real-case...` <= positional arguments to make_examples. hence the error you are seeing. Just doing:. `... --regions ""20 21"" --gvcf /HD_disk/real-case...`. should fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:471,deployability,log,log,471,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1586,deployability,log,log,1586,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1745,deployability,log,log,1745,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1800,deployability,log,log,1800,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1922,deployability,log,log,1922,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1951,deployability,log,log,1951,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:2067,deployability,log,log,2067,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1716,performance,parallel,parallel,1716,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:338,reliability,doe,does,338,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1955,reliability,doe,does,1955,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:471,safety,log,log,471,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1586,safety,log,log,1586,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1745,safety,log,log,1745,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1800,safety,log,log,1800,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1922,safety,log,log,1922,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1951,safety,log,log,1951,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:2067,safety,log,log,2067,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:471,security,log,log,471,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1586,security,log,log,1586,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1745,security,log,log,1745,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1800,security,log,log,1800,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1922,security,log,log,1922,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1951,security,log,log,1951,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:2067,security,log,log,2067,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:471,testability,log,log,471,"Thank you for the reply. I have included the "" "" in the code however it appears missing at runtime.It worked when I replace that with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1586,testability,log,log,1586,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1745,testability,log,log,1745,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1800,testability,log,log,1800,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1922,testability,log,log,1922,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1951,testability,log,log,1951,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:2067,testability,log,log,2067,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:1599,usability,indicat,indicated,1599,"hat with ``` --regions ' ""20 21"" ' ```. However, a further question is that when should we include the chr in the region. Apparently ``` --regions ' ""chr20:10,000,000-10,001,000 chr20:10,002,000-10,003,000"" ' ``` does not work but ``` --regions ' ""20:10,000,000-10,001,000 20:10,002,000-10,003,000"" ' ``` is fine. . One more problem is about the log file of the make sample. . It appears to show variant candidate in each region and finally display the total number of variant, i.e. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 7 candidates in 20:10000000-10000999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . However, for region 20:10,002,000-10,003,000, I get. ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ``` . which the final candidate variant is less than the candidate in the region. When I run with region 20:10,000,000-10,001,000 20:10,002,000-10,003,000, . ``` . I0815 12:48:59.877676 140644793067264 make_examples.py:782] Found 9 candidates in 20:10002000-10002999 [1.56s elapsed]. I0815 12:48:59.899951 140644793067264 make_examples.py:1053] Found 7 candidate variants . ```. . which is the same as just running region 20:10,002,000-10,003,000 only. But when I check the call variant log file, it indicated that 16 samples are run, which is correct (7 for first region and 9 for second region). . As I am using ```parallel```, my guess is the log file and final variant number shown in make sample log file only show the total number in 1 partition instead of all. Is that the case? I am not sure if I misunderstand the log file, or the make sample log does not really reflect the total number of variant. Should I only refer to sample number shown in Call Variant log file to get the total number of candidate variant? . .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:66,interoperability,specif,specify,66,"Also, when I try to run the hap.py to verify the result, I cannot specify the region with ``` -l ""20:10000000-10001000 20:10002000-10003000"" ``` or ``` -l '""20:10000000-10001000 20:10002000-10003000""' ```. Do you know how I should set the region for hap.py for multiple chromosome?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:38,testability,verif,verify,38,"Also, when I try to run the hap.py to verify the result, I cannot specify the region with ``` -l ""20:10000000-10001000 20:10002000-10003000"" ``` or ``` -l '""20:10000000-10001000 20:10002000-10003000""' ```. Do you know how I should set the region for hap.py for multiple chromosome?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:34,deployability,depend,depends,34,"The exact name for the chromosome depends on your reference file. If the reference FASTA names its chromosomes chr1, chr2 you need to use ""chr"" in the prefix. If the reference FASTA calls them 1, 2, etc you need to use that name.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:34,integrability,depend,depends,34,"The exact name for the chromosome depends on your reference file. If the reference FASTA names its chromosomes chr1, chr2 you need to use ""chr"" in the prefix. If the reference FASTA calls them 1, 2, etc you need to use that name.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:34,modifiability,depend,depends,34,"The exact name for the chromosome depends on your reference file. If the reference FASTA names its chromosomes chr1, chr2 you need to use ""chr"" in the prefix. If the reference FASTA calls them 1, 2, etc you need to use that name.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:34,safety,depend,depends,34,"The exact name for the chromosome depends on your reference file. If the reference FASTA names its chromosomes chr1, chr2 you need to use ""chr"" in the prefix. If the reference FASTA calls them 1, 2, etc you need to use that name.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:34,testability,depend,depends,34,"The exact name for the chromosome depends on your reference file. If the reference FASTA names its chromosomes chr1, chr2 you need to use ""chr"" in the prefix. If the reference FASTA calls them 1, 2, etc you need to use that name.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:133,interoperability,specif,specify,133,"Thank you for the reply. . I have one more question about using regions. When I try to run the hap.py to verify the result, I cannot specify the region with ```-l ""20:10000000-10001000 20:10002000-10003000""``` or ``` -l '""20:10000000-10001000 20:10002000-10003000""'```. Do you know how I should set the region for hap.py for multiple chromosome?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:105,testability,verif,verify,105,"Thank you for the reply. . I have one more question about using regions. When I try to run the hap.py to verify the result, I cannot specify the region with ```-l ""20:10000000-10001000 20:10002000-10003000""``` or ``` -l '""20:10000000-10001000 20:10002000-10003000""'```. Do you know how I should set the region for hap.py for multiple chromosome?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:82,availability,error,error,82,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:133,availability,failur,failure,133,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:41,deployability,fail,fail,41,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:133,deployability,fail,failure,133,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:82,performance,error,error,82,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:133,performance,failur,failure,133,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:41,reliability,fail,fail,41,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:133,reliability,fail,failure,133,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:156,reliability,doe,does,156,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:82,safety,error,error,82,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:82,usability,error,error,82,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:112,usability,Command,Command,112,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:221,usability,command,command,221,"Even if I only set the mode(which should fail by asking for other flags) the same error appears. Using 0.7.0: . Command line parsing failure: make_examples does not accept positional arguments but some are present on the command line: ""['/tmp/Bazel.runfiles_TAWAeF/runfiles/com_google_deepvariant/deepvariant/make_examples.py', '--mode', 'calling']"".",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/72:376,usability,command,command,376,"@akmohtashami your question seems to be more relevant to the earlier ones:. https://github.com/google/deepvariant/issues/72#issuecomment-412946034. and the relevant answer is : https://github.com/google/deepvariant/issues/72#issuecomment-412948943. When there's something related to positional arguments, it's often becomes something wasn't quoted correctly. What's your full command line?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/72
https://github.com/google/deepvariant/issues/73:657,availability,error,error,657,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:873,availability,error,error,873,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:537,deployability,depend,depending,537,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:556,deployability,version,version,556,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:27,integrability,messag,message,27,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:537,integrability,depend,depending,537,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:556,integrability,version,version,556,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:663,integrability,messag,message,663,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:27,interoperability,messag,message,27,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:663,interoperability,messag,message,663,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:809,interoperability,specif,specify,809,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:537,modifiability,depend,depending,537,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:556,modifiability,version,version,556,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:657,performance,error,error,657,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:873,performance,error,error,873,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:308,safety,input,input,308,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:537,safety,depend,depending,537,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:657,safety,error,error,657,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:873,safety,error,error,873,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:537,testability,depend,depending,537,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:308,usability,input,input,308,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:631,usability,help,help,631,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:657,usability,error,error,657,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:873,usability,error,error,873,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:964,usability,help,helped,964,"Hi,. as you can see in the message:. ```. I0514 22:42:53.306706 140678655026944 make_examples.py:946] Common contigs are [u'1', u'2', u'3', u'4', u'5', u'6', u'7', u'8', u'9', u'10', u'11', u'12', u'13', u'14', u'15', u'16', u'17', u'18', u'19', u'20', u'21', u'22', u'X', u'Y']. ```. This shows that in the input files you gave to make_examples use the convention *without* the prefix ""chr"". Therefore, in this case you should use `--regions ""20""` in your argument. It could be a bit confusing, but both conventions exist. For example, depending on which version of the reference you're using they can also be different. Would it help if we add a bit more error message? . Maybe in addition to ""Could not parse"", we can say something more verbose like:. `Could not parse chr20 : make sure if the regions you specify are in the contigs of your BAM and FASTA file. A common error is to use ""chr"" prefix on files that don't have it, or vice versa.`. Would that have helped?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:62,deployability,releas,releases,62,We've added a more verbose message. It will come out in later releases of Nucleus and DeepVariant. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:27,integrability,messag,message,27,We've added a more verbose message. It will come out in later releases of Nucleus and DeepVariant. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/73:27,interoperability,messag,message,27,We've added a more verbose message. It will come out in later releases of Nucleus and DeepVariant. Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/73
https://github.com/google/deepvariant/issues/74:612,availability,slo,slower,612,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:180,deployability,log,log,180,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:677,deployability,resourc,resources,677,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:806,deployability,pipelin,pipelines,806,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1080,deployability,pipelin,pipelines,1080,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:111,energy efficiency,cloud,cloud,111,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:677,energy efficiency,resourc,resources,677,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:782,energy efficiency,optim,optimized,782,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:825,energy efficiency,cloud,cloud,825,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:883,energy efficiency,Cloud,Cloud,883,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1074,energy efficiency,Cloud,Cloud,1074,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:334,integrability,batch,batches,334,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:459,integrability,batch,batches,459,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:806,integrability,pipelin,pipelines,806,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:965,integrability,compon,components,965,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1080,integrability,pipelin,pipelines,1080,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:73,interoperability,share,share,73,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:889,interoperability,Platform,Platform,889,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:965,interoperability,compon,components,965,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:965,modifiability,compon,components,965,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:334,performance,batch,batches,334,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:459,performance,batch,batches,459,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:677,performance,resourc,resources,677,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:782,performance,optimiz,optimized,782,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1037,performance,perform,performance,1037,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:612,reliability,slo,slower,612,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:180,safety,log,log,180,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:677,safety,resourc,resources,677,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:180,security,log,log,180,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:180,testability,log,log,180,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:677,testability,resourc,resources,677,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:946,testability,understand,understand,946,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:83,usability,command,command,83,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:551,usability,confirm,confirm,551,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:936,usability,user,users,936,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1037,usability,perform,performance,1037,"Hi, thanks for reporting this issue. If you used a GCE instance, can you share the command you used to start a cloud machine? . And, if you look at your `""${LOG_DIR}/call_variants.log""`, you should be able to see lines like these:. ```. I0405 16:03:16.308625 140490269800192 call_variants.py:353] Processed 4680192 examples in 146256 batches [0.67 sec per 100]. I0405 16:03:16.524780 140490269800192 call_variants.py:353] Processed 4680224 examples in 146257 batches [0.67 sec per 100]. ```. Can you tell me what your ""sec per 100"" is? This will also confirm your speed for call_variants. I'm guessing it's much slower than 0.67 sec per 100. You should also watch your systems resources -- is there enough RAM, etc. And, I would also suggest that you check out the [cost- and speed-optimized, Docker-based pipelines](https://cloud.google.com/genomics/deepvariant) created for Google Cloud Platform. Case studies are created so that the users can understand the key components of DeepVariant, but if you want to look for production-grade performance, you should consider the Cloud pipelines instead.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:581,availability,slo,slower,581,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:636,deployability,configurat,configuration,636,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:227,energy efficiency,core,cores,227,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:395,energy efficiency,profil,profile,395,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:636,integrability,configur,configuration,636,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:636,modifiability,configur,configuration,636,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:347,performance,network,network,347,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:395,performance,profil,profile,395,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:481,performance,time,time,481,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:532,performance,time,time,532,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:666,performance,time,time,666,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:581,reliability,slo,slower,581,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:347,security,network,network,347,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:636,security,configur,configuration,636,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:537,usability,close,closely,537,"Thank you for the reply. I am running it on a linux server instead of using GCE. . The ""sec per 100"" is ""2.68 sec per 100"". My machine has 16Gb RAM and DeepVariant added 1-2 Gb RAM usage and total RAM usage peaks at 5Gb with 8 cores fully utilized. The data file, make_examples and call_variants result are all written to local storage instead of network storage. . I was trying to get a timing profile and check if the program runs as expected. One thing I am curious is that the time taken to run make_examples matches the report time closely, however, the call_variants is much slower. I wonder if there is any problem in setting or configuration as the reported time of call_variants is much faster.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,availability,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1504,availability,down,downloaded,1504,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:522,deployability,api,apicid,522,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:543,deployability,api,apicid,543,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:661,deployability,api,apic,661,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,deployability,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1403,deployability,manag,management,1403,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:102,energy efficiency,core,core,102,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:186,energy efficiency,CPU,CPU,186,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:249,energy efficiency,cpu,cpuinfo,249,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:299,energy efficiency,cpu,cpu,299,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:315,energy efficiency,model,model,315,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:328,energy efficiency,model,model,328,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:358,energy efficiency,CPU,CPU,358,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:416,energy efficiency,cpu,cpu,416,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:492,energy efficiency,core,core,492,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:506,energy efficiency,cpu,cpu,506,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:510,energy efficiency,core,cores,510,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:588,energy efficiency,cpu,cpuid,588,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,energy efficiency,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1397,energy efficiency,power,power,1397,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1403,energy efficiency,manag,management,1403,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1476,energy efficiency,optim,optimized,1476,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:522,integrability,api,apicid,522,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:543,integrability,api,apicid,543,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:661,integrability,api,apic,661,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:522,interoperability,api,apicid,522,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:543,interoperability,api,apicid,543,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:661,interoperability,api,apic,661,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:186,performance,CPU,CPU,186,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:249,performance,cpu,cpuinfo,249,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:299,performance,cpu,cpu,299,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:358,performance,CPU,CPU,358,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:416,performance,cpu,cpu,416,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:437,performance,cach,cache,437,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:506,performance,cpu,cpu,506,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:588,performance,cpu,cpuid,588,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1476,performance,optimiz,optimized,1476,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:765,reliability,rdt,rdtscp,765,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,reliability,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,safety,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1403,safety,manag,management,1403,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:315,security,model,model,315,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:328,security,model,model,328,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:887,testability,monitor,monitor,887,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1430,usability,confirm,confirm,1430,"Hi Bowen, just an FYI that I'm looking into this a bit. I'm going to try running call_variants on a 8 core machine on GCE to see how the timing looks. Can you send us the details of the CPU you are trying to run on? For example:. $ head -n 26 /proc/cpuinfo. processor	: 0. vendor_id	: GenuineIntel. cpu family	: 6. model		: 63. model name	: Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz. stepping	: 2. microcode	: 0x3c. cpu MHz		: 1200.024. cache size	: 30720 KB. physical id	: 0. siblings	: 24. core id		: 0. cpu cores	: 12. apicid		: 0. initial apicid	: 0. fpu		: yes. fpu_exception	: yes. cpuid level	: 15. wp		: yes. flags		: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm epb invpcid_single kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm xsaveopt cqm_llc cqm_occup_llc ibpb ibrs stibp dtherm ida arat pln pts. bugs		: cpu_meltdown spectre_v1 spectre_v2. bogomips	: 5187.99. clflush size	: 64. cache_alignment	: 64. address sizes	: 46 bits physical, 48 bits virtual. power management:. Also, just to confirm - you are using DV 0.6.1 with our gcp optimized TF wheel (this is downloaded by run-prereqs.sh)?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,availability,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:324,deployability,api,apicid,324,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:344,deployability,api,apicid,344,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:459,deployability,api,apic,459,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,deployability,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1303,deployability,manag,management,1303,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1587,deployability,version,version,1587,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:2056,deployability,instal,install,2056,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:45,energy efficiency,cpu,cpuinfo,45,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:109,energy efficiency,cpu,cpu,109,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:125,energy efficiency,model,model,125,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:137,energy efficiency,model,model,137,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:159,energy efficiency,Core,Core,159,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:176,energy efficiency,CPU,CPU,176,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:223,energy efficiency,cpu,cpu,223,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:296,energy efficiency,core,core,296,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:309,energy efficiency,cpu,cpu,309,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:313,energy efficiency,core,cores,313,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:388,energy efficiency,cpu,cpuid,388,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,energy efficiency,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1297,energy efficiency,power,power,1297,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1303,energy efficiency,manag,management,1303,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1712,energy efficiency,model,models,1712,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1966,energy efficiency,optim,optimized,1966,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:2023,energy efficiency,optim,optimized,2023,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:324,integrability,api,apicid,324,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:344,integrability,api,apicid,344,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:459,integrability,api,apic,459,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1587,integrability,version,version,1587,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:324,interoperability,api,apicid,324,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:344,interoperability,api,apicid,344,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:459,interoperability,api,apic,459,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1536,interoperability,specif,specify,1536,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1587,modifiability,version,version,1587,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:45,performance,cpu,cpuinfo,45,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:109,performance,cpu,cpu,109,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:176,performance,CPU,CPU,176,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:223,performance,cpu,cpu,223,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:243,performance,cach,cache,243,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:309,performance,cpu,cpu,309,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:388,performance,cpu,cpuid,388,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1966,performance,optimiz,optimized,1966,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:2023,performance,optimiz,optimized,2023,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:563,reliability,rdt,rdtscp,563,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,reliability,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,safety,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1303,safety,manag,management,1303,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1865,safety,test,testdata,1865,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:125,security,model,model,125,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:137,security,model,model,137,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1712,security,model,models,1712,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:689,testability,monitor,monitor,689,"Thank you for the reply. . Following are the cpuinfo of my machine. processor : 0. vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:1865,testability,test,testdata,1865,"vendor_id : GenuineIntel. cpu family : 6. model : 94. model name : Intel(R) Core(TM) i7-6700 CPU @ 3.40GHz. stepping : 3. microcode : 0xc2. cpu MHz : 1013.093. cache size : 8192 KB. physical id : 0. siblings : 8. core id : 0. cpu cores : 4. apicid : 0. initial apicid : 0. fpu : yes. fpu_exception : yes. cpuid level : 22. wp : yes. flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt rsb_ctxsw spec_ctrl retpoline kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx rdseed adx smap clflushopt xsaveopt xsavec xgetbv1 dtherm ida arat pln pts hwp hwp_notify hwp_act_window hwp_epp. bugs : cpu_meltdown spectre_v1 spectre_v2. bogomips : 6816.62. clflush size : 64. cache_alignment : 64. address sizes : 39 bits physical, 48 bits virtual. power management:. I have used the preliminaries set in the exome case study, namely. ```. BASE=""/HD_disk/exome-case-study"". BUCKET=""gs://deepvariant"". BIN_VERSION=""0.6.1"". MODEL_VERSION=""0.6.0"". MODEL_CL=""191676894"". # Note that we don't specify the CL number for the binary, only the bin version. BIN_BUCKET=""${BUCKET}/binaries/DeepVariant/${BIN_VERSION}/DeepVariant-${BIN_VERSION}+cl-*"". MODEL_BUCKET=""${BUCKET}/models/DeepVariant/${MODEL_VERSION}/DeepVariant-inception_v3-${MODEL_VERSION}+cl-${MODEL_CL}.data-wes_standard"". DATA_BUCKET=""${BUCKET}/exome-case-study-testdata"". ```. I have also run the run_prereq.sh, however, I am not entirely sure if I have the gcp optimized TF wheel. Can you show me which one is the gcp optimized TF wheel and how can I install that if I have not?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:601,deployability,observ,observed,601,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:959,deployability,observ,observed,959,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:176,energy efficiency,core,cores,176,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:370,energy efficiency,core,cores,370,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:654,energy efficiency,core,cores,654,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:688,energy efficiency,core,cores,688,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:747,energy efficiency,core,cores,747,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:787,energy efficiency,core,core,787,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:520,modifiability,scal,scaling,520,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:601,testability,observ,observed,601,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:959,testability,observ,observed,959,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:726,usability,efficien,efficiently,726,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:947,usability,close,close,947,"Hi @BowenKwan . I dug into this a bit and I think it is working as expected. Here are some take aways:. There are 57238 total examples in the exome. * On a batch_size 32 on 64 cores runs this runs at 0.67 sec per 100 [from pichuan] with total runtime 6m 21s. Expected runtime is 57238 / 100 * 0.67 seconds = 6m so this is all matching. * With a batch_size 32 on a GCE 8 cores instance DV 0.6 runs at 2.53 sec per 100, so expected runtime is 57238 / 100 * 2.53 seconds = 24 min. * The expected run rate (assuming perfect scaling from 64 => 8) is 0.67 * 8 = 5.36 sec per 100. This is 2x larger than the observed rate [in the positive direction] because 64 cores isn't as well utilized as 8 cores. So we are in fact running more efficiently on the 8 cores, again as expected. * I ran the 8 core call_variants end2end on the GCE instance and in fact it takes only 24 m. * You are reporting a run rate of 2.68 sec per 100 in one comment, which is very close to my observed GCE rate. * My guess: did you leave out the --regions ${CAPTURE_BED} argument? This changes how many examples are generated and could lead to a 8 hr runtime of call_variants even at 2.53 secs per 100. Leaving out that flag will result in candidates being generated genome-wide, so you'll have many more candidates and a concomitantly longer runtime.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:8,usability,help,help,8,Glad to help. Unfortunately there's no easy way to do it via the command line but you can use python and TF such as in https://lonelycoding.com/obtaining-total-number-of-records-from-tfrecords-file-in-tensorflow/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/74:65,usability,command,command,65,Glad to help. Unfortunately there's no easy way to do it via the command line but you can use python and TF such as in https://lonelycoding.com/obtaining-total-number-of-records-from-tfrecords-file-in-tensorflow/,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/74
https://github.com/google/deepvariant/issues/75:15,deployability,log,log,15,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:44,deployability,fail,failed,44,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:44,reliability,fail,failed,44,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:116,reliability,doe,doesn,116,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:15,safety,log,log,15,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:15,security,log,log,15,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:15,testability,log,log,15,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/75:97,usability,indicat,indicate,97,"Hi,. from your log, it seems like this call failed `read.aligned_quality[read_pos]`, which might indicate that read doesn't have a quality score?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/75
https://github.com/google/deepvariant/issues/76:138,performance,content,content,138,"Hi,. the link is a gist with a short python script. You should be able to just paste that into a file yourself. Are you unable to see the content of the gist?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/76
https://github.com/google/deepvariant/issues/77:21,deployability,log,log,21,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:34,interoperability,specif,specifically,34,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:21,safety,log,log,21,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:21,security,log,log,21,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:21,testability,log,log,21,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:25,usability,close,closely,25,"Hi,. looking at your log closely, specifically this:. ```. File ""/tmp/Bazel.runfiles_1j54j0yh/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 549, in build_calling_regions. regions = ranges.RangeSet.from_contigs(contigs). ```. and . ```. ValueError: IntervalTree: Null Interval objects not allowed in IntervalTree: Interval(0, 0). ```. It seems like you might have contigs in your reference files that are empty. Is that expected?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:88,usability,help,help,88,This is not expected. I am going to investigate and come back to you. . Thanks for your help.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:14,deployability,updat,update,14,"If there's no update on this, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:14,safety,updat,update,14,"If there's no update on this, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:14,security,updat,update,14,"If there's no update on this, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/77:43,usability,close,close,43,"If there's no update on this, I'm going to close this for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/77
https://github.com/google/deepvariant/issues/78:132,availability,error,error,132,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup. If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:197,deployability,releas,release,197,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup. If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:132,performance,error,error,132,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup. If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:132,safety,error,error,132,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup. If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:132,usability,error,error,132,"Hi. What OS are you running on? I actually don't see this crash on the Ubuntu 16 setup. If you can let me know how to reproduce the error, we'll make sure to fix it and will come out with the next release. Thanks for reporting!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:533,deployability,modul,module,533,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:566,interoperability,format,format,566,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:533,modifiability,modul,module,533,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:200,safety,test,testing,200,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:533,safety,modul,module,533,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:200,testability,test,testing,200,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:470,testability,Trace,Traceback,470,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:173,usability,behavi,behavior,173,"Hi. This is actually happening in the Docker image provided with DeepVariant. (It's been converted to a Singularity image, but it's difficult to imagine that affecting this behavior.). Doing a little testing, the ""%m"" seems to crash Python 2 but not Python 3. Perhaps that's somehow the difference? And this is (I think) coming via TensorFlow, which might also matter. ```. Python 2.7.10 (default, Jul 14 2015, 19:46:27). [GCC 4.8.2] on linux. 'asdf %0.001mean' % (3,). Traceback (most recent call last):. File ""python"", line 1, in <module>. ValueError: unsupported format character 'm' (0x6d) at index 11. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:187,reliability,doe,doesn,187,"I will add a space between % and m. Do you think that will fix the problem you're seeing? There really should be a space anyway, so I will add it. When I try %%, it displays two %, which doesn't seem correct to me.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:84,integrability,messag,message,84,"Seems like it should work. This is indeed an annoying corner case, but the `--help` message is pretty important. :-)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:84,interoperability,messag,message,84,"Seems like it should work. This is indeed an annoying corner case, but the `--help` message is pretty important. :-)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:78,usability,help,help,78,"Seems like it should work. This is indeed an annoying corner case, but the `--help` message is pretty important. :-)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:120,deployability,releas,release,120,"Yes, I agree that --help is important! Thanks for reporting. This is now fixed internally and will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/78:20,usability,help,help,20,"Yes, I agree that --help is important! Thanks for reporting. This is now fixed internally and will come out in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/78
https://github.com/google/deepvariant/issues/79:17,deployability,releas,released,17,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/79:8,energy efficiency,model,model,8,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/79:244,modifiability,scenario,scenario,244,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/79:294,modifiability,pac,packaged,294,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/79:8,security,model,model,8,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/79:383,usability,help,help,383,"No. The model we released is diploid. . Long answer: in terms of the implementation, many of the utility functions try to take into account different ploidy. But in the actual case of DeepVariant we haven't done anything other than the diploid scenario. so if you're looking for an already pre-packaged caller, the answer is no. But if you're looking for Python functions that might help with your development, please feel free to look into the code in Nucleus and deepvariant, and let us know if you have any questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/79
https://github.com/google/deepvariant/issues/80:80,energy efficiency,model,models,80,"Dear DeepVariant team,. We are also interested in training and trying different models for DeepVariant. Could you please kindly let us know more details about sequencing and alignment data you are using to generate the labeled examples? Look forward to hearing from you! Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:17,security,team,team,17,"Dear DeepVariant team,. We are also interested in training and trying different models for DeepVariant. Could you please kindly let us know more details about sequencing and alignment data you are using to generate the labeled examples? Look forward to hearing from you! Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:80,security,model,models,80,"Dear DeepVariant team,. We are also interested in training and trying different models for DeepVariant. Could you please kindly let us know more details about sequencing and alignment data you are using to generate the labeled examples? Look forward to hearing from you! Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:269,availability,down,download,269,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:154,deployability,releas,release,154,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:177,deployability,version,version,177,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:415,deployability,releas,release,415,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:452,deployability,releas,release,452,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:49,energy efficiency,Current,Currently,49,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:328,energy efficiency,current,currently,328,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:106,integrability,pub,public,106,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:121,integrability,pub,public,121,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:177,integrability,version,version,177,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:190,integrability,pub,public,190,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:363,integrability,pub,public,363,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:177,modifiability,version,version,177,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:407,testability,plan,plan,407,"Thanks for your interest in trying out training! Currently, DeepVariant is trained using a combination of public and non-public data, as described in the release notes for each version. For public data sources, like Genome in a Bottle or BaseSpace, we encourage you to download the data directly from the original source. . I'm currently working on a list of the public data sources that we're using. We'll plan to release that information in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:19,deployability,releas,release,19,"Hi,. In the latest release we added this page:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md. As well as a training tutorial:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md. If you decide to train a model, we would love to hear your feedback as detailed as you are willing to provide us. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:290,energy efficiency,model,model,290,"Hi,. In the latest release we added this page:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md. As well as a training tutorial:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md. If you decide to train a model, we would love to hear your feedback as detailed as you are willing to provide us. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:290,security,model,model,290,"Hi,. In the latest release we added this page:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md. As well as a training tutorial:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md. If you decide to train a model, we would love to hear your feedback as detailed as you are willing to provide us. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/80:324,usability,feedback,feedback,324,"Hi,. In the latest release we added this page:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-details-training-data.md. As well as a training tutorial:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md. If you decide to train a model, we would love to hear your feedback as detailed as you are willing to provide us. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/80
https://github.com/google/deepvariant/issues/81:93,deployability,build,build,93,Can you provide a bit more information? Are you using a docker image where the binaries were build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:104,energy efficiency,GPU,GPU,104,Can you provide a bit more information? Are you using a docker image where the binaries were build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:104,performance,GPU,GPU,104,Can you provide a bit more information? Are you using a docker image where the binaries were build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:108,usability,support,support,108,Can you provide a bit more information? Are you using a docker image where the binaries were build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:327,deployability,build,build,327,I used the precompiled docker image from your site. https://console.cloud.google.com/gcr/images/deepvariant-docker/GLOBAL/deepvariant_runner@sha256:0c0e698d8c1749e17d3b248245a06456feeac534834314c90e209b4ff1b2b23b/details?tab=info. docker pull gcr.io/deepvariant-docker/deepvariant_runner:0.6.1. I thought that the binaries are build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:68,energy efficiency,cloud,cloud,68,I used the precompiled docker image from your site. https://console.cloud.google.com/gcr/images/deepvariant-docker/GLOBAL/deepvariant_runner@sha256:0c0e698d8c1749e17d3b248245a06456feeac534834314c90e209b4ff1b2b23b/details?tab=info. docker pull gcr.io/deepvariant-docker/deepvariant_runner:0.6.1. I thought that the binaries are build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:338,energy efficiency,GPU,GPU,338,I used the precompiled docker image from your site. https://console.cloud.google.com/gcr/images/deepvariant-docker/GLOBAL/deepvariant_runner@sha256:0c0e698d8c1749e17d3b248245a06456feeac534834314c90e209b4ff1b2b23b/details?tab=info. docker pull gcr.io/deepvariant-docker/deepvariant_runner:0.6.1. I thought that the binaries are build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:338,performance,GPU,GPU,338,I used the precompiled docker image from your site. https://console.cloud.google.com/gcr/images/deepvariant-docker/GLOBAL/deepvariant_runner@sha256:0c0e698d8c1749e17d3b248245a06456feeac534834314c90e209b4ff1b2b23b/details?tab=info. docker pull gcr.io/deepvariant-docker/deepvariant_runner:0.6.1. I thought that the binaries are build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:342,usability,support,support,342,I used the precompiled docker image from your site. https://console.cloud.google.com/gcr/images/deepvariant-docker/GLOBAL/deepvariant_runner@sha256:0c0e698d8c1749e17d3b248245a06456feeac534834314c90e209b4ff1b2b23b/details?tab=info. docker pull gcr.io/deepvariant-docker/deepvariant_runner:0.6.1. I thought that the binaries are build with GPU support?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:39,energy efficiency,GPU,GPU,39,"You should use DeepVariant image (with GPU support). docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1. The image you mentioned is DeepVariant runner, which pulls and runs Deepvariant docker images on Google cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:218,energy efficiency,cloud,cloud,218,"You should use DeepVariant image (with GPU support). docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1. The image you mentioned is DeepVariant runner, which pulls and runs Deepvariant docker images on Google cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:39,performance,GPU,GPU,39,"You should use DeepVariant image (with GPU support). docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1. The image you mentioned is DeepVariant runner, which pulls and runs Deepvariant docker images on Google cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:43,usability,support,support,43,"You should use DeepVariant image (with GPU support). docker pull gcr.io/deepvariant-docker/deepvariant_gpu:0.6.1. The image you mentioned is DeepVariant runner, which pulls and runs Deepvariant docker images on Google cloud.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:158,availability,error,error,158,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:169,deployability,log,log,169,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:176,interoperability,share,share,176,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:158,performance,error,error,158,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:158,safety,error,error,158,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:169,safety,log,log,169,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:169,security,log,log,169,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:169,testability,log,log,169,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:122,usability,command,command,122,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:158,usability,error,error,158,Please provide more information. What image did you use? Did you use the runner image or deepvarinat image directly? What command did you use? Did you get an error? Any log to share?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:544,availability,checkpoint,checkpoint,544,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:93,deployability,instal,install,93,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:596,deployability,log,log,596,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:132,energy efficiency,GPU,GPU,132,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:558,energy efficiency,MODEL,MODEL,558,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:132,performance,GPU,GPU,132,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:310,performance,time,time,310,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:544,reliability,checkpoint,checkpoint,544,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:596,safety,log,log,596,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:558,security,MODEL,MODEL,558,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:596,security,log,log,596,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:596,testability,log,log,596,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:146,usability,document,documented,146,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:352,usability,USER,USER,352,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:366,usability,USER,USER,366,"Hi @JoelDaon , were you able to run this? What I found recently is that I actually needed to install `nvidia-docker` in addition to GPU driver. I documented it for myself here:. https://gist.github.com/pichuan/6465d5f7ab56dd15a8f0d5f4d2763724. Once you have `nvidia-docker`, you'll run something like:. ```. ( time sudo nvidia-docker run \. -v /home/${USER}:/home/${USER} \. gcr.io/deepvariant-docker/deepvariant_gpu:""${BIN_VERSION}"" \. /opt/deepvariant/bin/call_variants \. --outfile ""${CALL_VARIANTS_OUTPUT}"" \. --examples ""${EXAMPLES}"" \. --checkpoint ""${MODEL}"". ) >""${LOG_DIR}/call_variants.log"" 2>&1. ```. I'd love to hear whether you're able to get it work or not. Thank you!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/81:43,usability,support,support,43,Yes it worked for me. Thanks a lot for the support!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/81
https://github.com/google/deepvariant/issues/83:319,integrability,sub,substitution,319,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:52,interoperability,compatib,compatible,52,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:124,interoperability,convers,conversion,124,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:7,testability,understand,understand,7,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:312,testability,simpl,simple,312,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:312,usability,simpl,simple,312,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:397,usability,close,close,397,"Hi,. I understand that it's a common use case to be compatible with GATK. We'll consider potentially adding a flag for that conversion. But since we're following the spec (using the VCF v4.3 spec: page 25 of this doc https://samtools.github.io/hts-specs/VCFv4.3.pdf), this won't be of high priority. For now the simple substitution you're doing is correct. I filed a bug internally to track. I'll close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:31,deployability,updat,update,31,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:120,deployability,releas,release,120,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:512,integrability,sub,substantially,512,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:147,reliability,pra,practices,147,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:31,safety,updat,update,31,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:31,security,updat,update,31,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/83:234,usability,user,users,234,"Hi @andremrsantos. I wanted to update this issue with recent developments for cohort merging. With the DeepVariant v0.9 release, we recommend Best practices for multi-sample variant calling with DeepVariant. We encourage you or other users interested in multi-sample calling to follow these recommendations to combine multiple DeepVariant gVCFs. In our benchmarks, we found this merging approach more accurate than merging with GATK GenotypeGVCFs (and we found merging DeepVariant gVCFs using GATK GenotypeGVCFs substantially less accurate than the single-sample DeepVariant VCFs themselves). Thank you.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/83
https://github.com/google/deepvariant/issues/84:298,availability,restor,restore,298,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:15,deployability,stack,stackoverflow,15,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:86,deployability,stack,stackoverflow,86,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:146,energy efficiency,model,model-ckpt-meta,146,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:253,energy efficiency,model,model,253,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:313,energy efficiency,model,model,313,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:298,reliability,restor,restore,298,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:146,security,model,model-ckpt-meta,146,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:197,security,Session,Session,197,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:253,security,model,model,253,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/84:313,security,model,model,313,"I took this to stackoverflow. Here's the answer in case anyone else needs it: https://stackoverflow.com/questions/51233023/extract-graph-def-from-model-ckpt-meta. To summarize:. ```python. with tf.Session() as sess:. saver = tf.train.import_meta_graph('model.ckpt.meta', clear_devices=True). saver.restore(sess, 'model.ckpt'). tf.train.write_graph(sess.graph_def, ""."", ""graph.pbtxt"", True). ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/84
https://github.com/google/deepvariant/issues/85:24,reliability,doe,does,24,"Hi Shruti,. DeepVariant does not accept multiple BAM files as input. You'll need to preprocess them into one BAM as input to DeepVariant. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/85
https://github.com/google/deepvariant/issues/85:62,safety,input,input,62,"Hi Shruti,. DeepVariant does not accept multiple BAM files as input. You'll need to preprocess them into one BAM as input to DeepVariant. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/85
https://github.com/google/deepvariant/issues/85:116,safety,input,input,116,"Hi Shruti,. DeepVariant does not accept multiple BAM files as input. You'll need to preprocess them into one BAM as input to DeepVariant. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/85
https://github.com/google/deepvariant/issues/85:62,usability,input,input,62,"Hi Shruti,. DeepVariant does not accept multiple BAM files as input. You'll need to preprocess them into one BAM as input to DeepVariant. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/85
https://github.com/google/deepvariant/issues/85:116,usability,input,input,116,"Hi Shruti,. DeepVariant does not accept multiple BAM files as input. You'll need to preprocess them into one BAM as input to DeepVariant. Thanks.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/85
https://github.com/google/deepvariant/issues/86:264,deployability,pipelin,pipeline,264,"Hi Shruti,. I notice in your .yaml that both the --outfile and --gvcf_outfile flags are set to ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" . These flags should have different names set, as they are two distinct output files. Please reopen this issue if rerunning the pipeline with the distinct names does not resolve your problem. regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:264,integrability,pipelin,pipeline,264,"Hi Shruti,. I notice in your .yaml that both the --outfile and --gvcf_outfile flags are set to ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" . These flags should have different names set, as they are two distinct output files. Please reopen this issue if rerunning the pipeline with the distinct names does not resolve your problem. regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:297,reliability,doe,does,297,"Hi Shruti,. I notice in your .yaml that both the --outfile and --gvcf_outfile flags are set to ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" . These flags should have different names set, as they are two distinct output files. Please reopen this issue if rerunning the pipeline with the distinct names does not resolve your problem. regards,. Cory",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:49,deployability,updat,update,49,"Thanks Cory. I will fix that and re-run. I shall update you if that resolves the issue. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:49,safety,updat,update,49,"Thanks Cory. I will fix that and re-run. I shall update you if that resolves the issue. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:49,security,updat,update,49,"Thanks Cory. I will fix that and re-run. I shall update you if that resolves the issue. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:64,availability,error,error,64,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:553,deployability,observ,observing,553,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:436,energy efficiency,core,core,436,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:577,integrability,coupl,couple,577,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:577,modifiability,coupl,couple,577,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:64,performance,error,error,64,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:42,safety,compl,completed,42,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:64,safety,error,error,64,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:42,security,compl,completed,42,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:553,testability,observ,observing,553,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:577,testability,coupl,couple,577,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:64,usability,error,error,64,"Hi Cory,. After fixing the issue, the run completed without any error. . My yaml file has arguments for both vcf and gvcf but different values. --outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_FILE_NAME}"" \. --gvcf_outfile ""${OUTPUT_BUCKET}""/""${OUTPUT_GVCF_FILE_NAME}"" \. However, the vcf generated by deepvariant seems to be small in size (495M), given that this is WGS. The vcf file that I received for this case from a clinical bioinformatics core that runs GATK3 is (2.7GB). I am wondering if I am missing something in my script for running deepvariant. I am observing this trend on couple of other WGS cases for which I ran deepvariant. I have attached my bash and yaml file for your reference. . Will appreciate any suggestions/pointers from you. Best,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:59,availability,error,error,59,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:59,performance,error,error,59,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:59,safety,error,error,59,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:227,testability,verif,verifying,227,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:59,usability,error,error,59,"Hi Shruti,. Glad to hear that the renaming fixed the prior error. I don't see the bash or yaml files attached, but I'm curious how many variants are present in the VCF output file and how that compares to the GATK3 output (and verifying that you're running on human samples). File sizes can vary due to additional annotations added or compression (and compression level) applied to the result. On a Unix system you can find the number of lines in the output VCF file using. wc -l ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"". or, if it's gzip compressed,. zcat ""${OUTPUT_BUCKET}/${OUTPUT_FILE_NAME}"" | wc -l",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:110,energy efficiency,core,core,110,"Hi Cory,. I think I know why the file size of deepvariant and gatk3 vcfs are so different. The bioinformatics core vcf that is generated using gatk3 has a lot more reference calls in the vcf than deepvariant. . If I filter out all homozygous-reference variants and also FILTER!=""PASS"", the number of SNVs and INDELS are comparable in both vcfs. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:216,integrability,filter,filter,216,"Hi Cory,. I think I know why the file size of deepvariant and gatk3 vcfs are so different. The bioinformatics core vcf that is generated using gatk3 has a lot more reference calls in the vcf than deepvariant. . If I filter out all homozygous-reference variants and also FILTER!=""PASS"", the number of SNVs and INDELS are comparable in both vcfs. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/86:270,integrability,FILTER,FILTER,270,"Hi Cory,. I think I know why the file size of deepvariant and gatk3 vcfs are so different. The bioinformatics core vcf that is generated using gatk3 has a lot more reference calls in the vcf than deepvariant. . If I filter out all homozygous-reference variants and also FILTER!=""PASS"", the number of SNVs and INDELS are comparable in both vcfs. Thanks,. Shruti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/86
https://github.com/google/deepvariant/issues/87:187,deployability,build,build,187,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:251,deployability,build,build,251,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:566,deployability,releas,release,566,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:135,energy efficiency,cloud,cloudbuild,135,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:540,integrability,sub,sub-directory,540,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:325,security,access,access,325,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:346,usability,document,document,346,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:586,usability,help,help,586,"Hi Paul,. there is actually some explanation in the file (below the Copyright lines):. https://github.com/google/deepvariant/blob/r0.7/cloudbuild.yaml#L28-L34. We use these yaml files to build and push docker images. You probably could re-use them to build and push DeepVariant docker images to projects where you have write access to. We didn't document these more, because we didn't think it's a very common use case. If it's confusing to have these files on the top level, I can check with my colleagues and see if we can move them to a sub-directory in the next release. Would that help?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:298,availability,cluster,cluster,298,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1738,availability,avail,available,1738,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:46,deployability,Build,Build,46,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:121,deployability,automat,automate,121,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:298,deployability,cluster,cluster,298,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:396,deployability,resourc,resources,396,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:808,deployability,build,build,808,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:964,deployability,version,version,964,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1022,deployability,build,build,1022," the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, wh",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1052,deployability,build,build,1052,"d has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` arg",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1082,deployability,build,build,1082,"e for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1145,deployability,build,build-generated,1145,"t of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1175,deployability,build,build,1175," else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1220,deployability,build,build-and-test,1220,"ome Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1325,deployability,build,build,1325,"ard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1435,deployability,build,build,1435,"e time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1470,deployability,build,build,1470,"eir boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit to",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1583,deployability,build,build,1583,"helmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to it",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1623,deployability,build,building,1623,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1665,deployability,build,builds,1665,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1969,deployability,Build,Build,1969,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2008,deployability,build,build,2008,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2072,deployability,build,build,2072,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2099,deployability,Build,Builds,2099,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2168,deployability,Contain,Container,2168,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2206,deployability,build,build,2206,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2233,deployability,Build,Builds,2233,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2286,deployability,Build,Builds,2286,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2342,deployability,Build,Builds,2342,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2386,deployability,scale,scale,2386,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2425,deployability,Pipelin,Pipelines,2425,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2435,deployability,API,API,2435,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:40,energy efficiency,Cloud,Cloud,40,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:390,energy efficiency,Cloud,Cloud,390,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:396,energy efficiency,resourc,resources,396,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1550,energy efficiency,GPU,GPU,1550,"possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1963,energy efficiency,Cloud,Cloud,1963,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2088,energy efficiency,cloud,cloudbuild,2088,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2212,energy efficiency,cloud,cloudbuild,2212,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2229,energy efficiency,CPU,CPU,2229,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2271,energy efficiency,CPU,CPU,2271,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2282,energy efficiency,GPU,GPU,2282,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2324,energy efficiency,GPU,GPU,2324,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2386,energy efficiency,scale,scale,2386,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:964,integrability,version,version,964,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2425,integrability,Pipelin,Pipelines,2425,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2435,integrability,API,API,2435,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1535,interoperability,compatib,compatibility,1535,"simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something whi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2178,interoperability,Registr,Registry,2178,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2435,interoperability,API,API,2435,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:964,modifiability,version,version,964,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2386,modifiability,scal,scale,2386,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:390,performance,Cloud resourc,Cloud resources,390,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:440,performance,time,time,440,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1550,performance,GPU,GPU,1550,"possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2229,performance,CPU,CPU,2229,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2271,performance,CPU,CPU,2271,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2282,performance,GPU,GPU,2282,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2324,performance,GPU,GPU,2324,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2386,performance,scale,scale,2386,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:68,reliability,pra,practical,68,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1105,reliability,doe,does,1105,"would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds D",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1738,reliability,availab,available,1738,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:396,safety,resourc,resources,396,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1191,safety,detect,detects,1191,"agine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1230,safety,test,test,1230,"ioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1518,safety,test,test,1518,"irectory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnaly",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1695,safety,compl,completed,1695,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1738,safety,avail,available,1738,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1890,safety,compl,completed,1890,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1191,security,detect,detects,1191,"agine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1695,security,compl,completed,1695,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1738,security,availab,available,1738,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1890,security,compl,completed,1890,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:15,testability,understand,understand,15,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:121,testability,automat,automate,121,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:396,testability,resourc,resources,396,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:542,testability,simpl,simple,542,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1230,testability,test,test,1230,"ioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1518,testability,test,test,1518,"irectory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnaly",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:96,usability,user,users,96,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:158,usability,hint,hinting,158,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:542,usability,simpl,simple,542,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:565,usability,user,users,565,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:679,usability,minim,minimal,679,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:730,usability,document,documentation,730,"Hi Pichuan,. I understand the nature of Cloud Build, and has a very practical use-case for many users that would like to automate their analysis. I'm sort of hinting at something else. So just imagine you are pitching this to some Bioinformatician that has been doing their analysis on an internal cluster for years. S/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1316,usability,user,user,1316,"/he has heard from others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker imag",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1331,usability,statu,status,1331,"om others of the benefits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1353,usability,user,user,1353,"fits of DeepVariant through Google Cloud resources, and now has a little bit of free time to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a Deep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1441,usability,statu,status,1441," to try it out to convince their boss to use it. The idea is that the root directory should be as simple as possible, so users don't get overwhelmed or confused - with all the other directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. `",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1729,usability,user,user,1729,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2046,usability,help,help,2046,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2078,usability,help,help,2078,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2223,usability,help,help,2223,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:2610,usability,help,helps,2610,"her directories in the tree flowing naturally from it. A minimal number of obvious scripts (with associated documentation) should naturally transition them from source code, through the build phase, and as quickly to the analysis process. Basically less is more, and you do not want to add more to the main directory as you begin to approach version 1.0. So ideally what would be nice is to have one build script - let's call it `build` - that reads a `config/build` directory - and does the following:. 1. Analyzes hidden build-generated files under `.build/...`, and detects if the `prereq` and `build-and-test` phases have been successfully processed. Otherwise, it would report back to the user the build status, and query the user with a recommendation on the next required step to run. For example:. ```. $ build status. Checking DeepVariant build prerequisites... OK. Checking DeepVariant test environment compatibility [GPU]... OK. Checking DeepVariant build binaries... MISSING. Proceed with building binaries [Y/n]? ```. 2. Once the builds have been successfully completed, then it would tell the user the available options to run (i.e. `make_examples`, `call_variants`, `postprocess_variants`, `pkrusche/hap.py`, etc.) as well as any analysis that has been completed if a `results` or `analysis-results` folder is present. 3. For Cloud Build, that would also be part of the `build` script, when they provide the `help` argument:. ```. $ ./build help. ... cloudbuild Builds Docker images of DeepVariant, and . pushes them on the Google Container Registry (gcr.io) . ... $ ./build cloudbuild help. CPU Builds a DeepVariant Docker image for CPU usage. GPU Builds a DeepVariant Docker image for GPU usage. Runner Builds a DeepVariant Docker image for large-scale analysis run. using the Genomics Pipelines API. $. ```. Even `Runner` is a bit too general, so maybe calling it `LargeScaleAnalysis`, or something which should be instantly recognizable as to its intended use. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:211,deployability,build,build,211,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:223,deployability,Build,Build,223,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:237,deployability,build,build,237,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:290,deployability,build,build,290,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:107,energy efficiency,cloud,cloud,107,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:205,energy efficiency,cloud,cloud,205,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:267,energy efficiency,cloud,cloud,267,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:284,energy efficiency,cloud,cloud-build,284,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:52,integrability,pub,published,52,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:346,usability,tool,tool,346,"For the use case you mentioned, one should just use published docker images (see images pointed in https://cloud.google.com/genomics/docs/tutorials/deepvariant). These config files are meant to be used by cloud build. See ""Build using a build config file"" in https://cloud.google.com/cloud-build/docs/quickstart-docker for how they are used. The tool you suggested will be useful once DeepVariant accepts external contributions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:67,deployability,updat,updated,67,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:174,deployability,version,version,174,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:268,deployability,releas,release,268,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:541,deployability,updat,update,541,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:751,deployability,Version,Version,751,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1091,deployability,configurat,configuration-file-for-each,1091,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1257,deployability,pipelin,pipeline,1257,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1482,deployability,version,versions,1482,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:174,integrability,version,version,174,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:751,integrability,Version,Version,751,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1091,integrability,configur,configuration-file-for-each,1091,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1257,integrability,pipelin,pipeline,1257,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1482,integrability,version,versions,1482,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:174,modifiability,version,version,174,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:751,modifiability,Version,Version,751,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1091,modifiability,configur,configuration-file-for-each,1091,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1482,modifiability,version,versions,1482,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:67,safety,updat,updated,67,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:541,safety,updat,update,541,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:704,safety,test,testing,704,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:825,safety,review,review,825,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1358,safety,input,input,1358,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:67,security,updat,updated,67,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:541,security,updat,update,541,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1091,security,configur,configuration-file-for-each,1091,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1639,security,barrier,barriers,1639,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:704,testability,test,testing,704,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:825,testability,review,review,825,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:566,usability,document,document,566,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:859,usability,help,helped,859,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1157,usability,document,documentation,1157,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1358,usability,input,input,1358,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1428,usability,user,user,1428,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1620,usability,user,users,1620,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1665,usability,user,users,1665,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:1734,usability,help,helps,1734,"Hi Nima,. That is a good point, and glad to see the tutorials page updated today. Though it would have been nice to have it highlight the `--use_tpu` flag option and `0.7.0` version, rather than the `0.6.x`. The tags in the docker images for the runner are still as a release candidate `0.7.0rc1`, with `0.6.1` as the `latest`. In any case, you guys are doing great work, and there is quite a lot of expertise on this side of the world as well to expand on DeepVariant's capabilities, and foster an even greater community. You might want to update the [contributing document](https://github.com/google/deepvariant/blob/master/CONTRIBUTING.md), since it mentions 1H 2018 for external contributions and CI testing on GitHub - and it's almost September. Version 0.7 seemed to have just dropped out of the sky without any formal review process, and we could have helped you iron out some of the kinks (i.e. such as minor spelling on the [TPU case study](https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-tpu-training-case-study.md#shuffle-each-set-of-examples-and-generate-a-data-configuration-file-for-each) [s/Optoinal/Optional]). Your [Docker documentation](https://github.com/google/deepvariant/blob/master/docs/deepvariant-docker.md#run-the-pipeline) still lists your image to use as `0.4.1`, which has an older channel representation of the input data - though using `latest` is a comment that might make a new user not realize the amount of difference between the versions. Some things seemed a bit rushed, and doing it together would have provided more eyes with expanded tutorials for attracting new users to lower any barriers to entry for new users - who can be quite picky when trying out new software. Hope it helps,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:97,deployability,updat,updated,97,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:72,energy efficiency,Cloud,Cloud,72,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:115,energy efficiency,cloud,cloud,115,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:97,safety,updat,updated,97,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:97,security,updat,updated,97,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:29,usability,feedback,feedback,29,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:427,usability,document,document,427,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:575,usability,document,documentation,575,"Hi @pgrosu , thanks for your feedback! Thanks to @nmousavi 's work, the Cloud runner page is now updated:. https://cloud.google.com/genomics/docs/tutorials/deepvariant with 0.7.0, and 0.7.0 deepvariant_runner image is now tagged as latest. In terms of our GitHub page --. I fixed a few small thing such as the typo (and ran spell checking and fixed a few more!) Also fixed the `0.4.1` issue. I'll also address the contributing document at some point soon. These changes are right now still just in our internal codebase. I'll get it out when I have a chance to push out some documentation fixes. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:776,performance,time,time,776,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:543,testability,simpl,simple,543,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:824,testability,plan,plan,824,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:909,testability,plan,plan,909,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:205,usability,user,users,205,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:241,usability,experien,experience,241,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:364,usability,clear,clear,364,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:454,usability,user,users,454,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:543,usability,simpl,simple,543,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/87:787,usability,close,close,787,"Hi @pgrosu , I filed an internal issue to track your suggestions in https://github.com/google/deepvariant/issues/87#issuecomment-413745335. I'll need to digest it a bit more, and probably talk to to a few users in more detail to design this experience better. On a high level, I think I'll need to at least think about overhauling the GitHub page to make it super clear how to run - even just with our docker image, it's apparently still not obvious for users to find (because it's hidden in the docs). And, the suggestion of making things as simple as possible is great one - both in terms of the directory structure, and also the output that our programs output. I think I have stared DeepVariant for too long that I'm losing empathy for people who look at it for the first time. I'll close this issue on GitHub, but will plan to think about this in more detail and hope to get back with at least some more plan later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/87
https://github.com/google/deepvariant/issues/88:23,availability,error,error,23,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:124,availability,echo,echo,124,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:218,energy efficiency,Cloud,Cloud,218,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:77,modifiability,variab,variables,77,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:592,modifiability,variab,variable,592,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:23,performance,error,error,23,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:23,safety,error,error,23,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:263,security,ssh,ssh,263,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:465,security,ssh,ssh,465,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:23,usability,error,error,23,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/88:472,usability,USER,USER,472,"First of all, from the error you're seeing, I think you forgot to set up the variables in that shell. Basically, if you do `echo $LOG_DIR` in that shell, you'll find it's empty. And, instead of directly using a Google Cloud shell in the browser, you can consider ssh into your machine from a terminal, like in this section:. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#request-a-machine. You can do something like `gcloud compute ssh ""${USER}-deepvariant-casestudy"" --zone ""us-west1-b""`. Using screen should certainly work. You'll just need to paste in the variable settings in this section again, because otherwise they'll all be empty strings. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md#preliminaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/88
https://github.com/google/deepvariant/issues/89:9,deployability,log,log,9,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:62,deployability,instal,installed,62,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:88,deployability,build,build-prereq,88,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:178,deployability,instal,install,178,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:192,deployability,fail,failed,192,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:234,deployability,log,log,234,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:249,deployability,instal,installation,249,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:262,deployability,fail,failed,262,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:324,deployability,build,build,324,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:509,deployability,build,building,509,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:192,reliability,fail,failed,192,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:262,reliability,fail,failed,262,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9,safety,log,log,9,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:234,safety,log,log,234,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9,security,log,log,9,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:234,security,log,log,234,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9,testability,log,log,9,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:234,testability,log,log,234,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:141,usability,command,command,141,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:502,usability,prefer,prefer,502,"From the log, it seems like the issue is that `bazel` was not installed. After you run `build-prereq.sh`, can you try typing in `bazel` as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,availability,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:184,availability,error,error,184,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:454,availability,state,state,454,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:300,deployability,instal,installation,300,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:373,deployability,instal,install,373,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:419,deployability,Build,Building,419,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:428,deployability,depend,dependency,428,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:428,integrability,depend,dependency,428,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:454,integrability,state,state,454,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:396,modifiability,pac,package,396,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:428,modifiability,depend,dependency,428,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:591,modifiability,extens,extension,591,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:622,modifiability,pac,package,622,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,performance,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:184,performance,error,error,184,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,safety,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:184,safety,error,error,184,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:428,safety,depend,dependency,428,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:365,security,apt,apt-get,365,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:540,security,apt,apt,540,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:428,testability,depend,dependency,428,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,usability,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:184,usability,error,error,184,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:267,usability,tool,tools,267,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error . solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazel. Unexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazel. Reading package lists... Done. Building dependency tree . Reading state information... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. E: Unable to locate package bazel.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,availability,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:180,availability,error,error,180,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:450,availability,state,state,450,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:296,deployability,instal,installation,296,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:369,deployability,instal,install,369,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:420,deployability,depend,dependency,420,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:737,deployability,log,log,737,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:788,deployability,instal,installed,788,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:813,deployability,build,build-prereq,813,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:900,deployability,instal,install,900,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:914,deployability,fail,failed,914,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:956,deployability,log,log,956,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:971,deployability,instal,installation,971,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:984,deployability,fail,failed,984,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1046,deployability,build,build,1046,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1231,deployability,build,building,1231,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:420,integrability,depend,dependency,420,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:450,integrability,state,state,450,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:390,modifiability,pac,package,390,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:420,modifiability,depend,dependency,420,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:585,modifiability,extens,extensionE,585,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:614,modifiability,pac,package,614,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,performance,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:180,performance,error,error,180,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:914,reliability,fail,failed,914,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:984,reliability,fail,failed,984,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,safety,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:180,safety,error,error,180,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:420,safety,depend,dependency,420,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:737,safety,log,log,737,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:956,safety,log,log,956,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:361,security,apt,apt-get,361,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:534,security,apt,apt,534,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:737,security,log,log,737,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:956,security,log,log,956,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1297,security,auth,authored,1297,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:420,testability,depend,dependency,420,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:737,testability,log,log,737,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:956,testability,log,log,956,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:101,usability,error,error,101,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:180,usability,error,error,180,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:263,usability,tool,tools,263,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:863,usability,command,command,863,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:1224,usability,prefer,prefer,1224,"@pichuan thank you for your prompt response, i ran bazel as you instructed and and got the following error solokopi@solokopi-All-Series:~/Desktop/deepvariant-r0.7$ bazelUnexpected error reading .blazerc file '/home/solokopi/Desktop/deepvariant-r0.7/../tensorflow/tools/bazel.rc'. And i tried the installation and got this:. solokopi@solokopi-All-Series:~$ sudo apt-get install bazelReading package lists... DoneBuilding dependency tree       Reading state information... DoneN: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extensionE: Unable to locate package bazel. On Friday, August 24, 2018, 8:40:23 AM PDT, Pi-Chuan Chang <notifications@github.com> wrote: . . . From the log, it seems like the issue is that bazel was not installed. After you run build-prereq.sh, can you try typing in bazel as a command and see if it exits? And, if install bazel failed for you, can you paste the part of log of how the installation failed for you? By the way, is there a reason why you want to build your own binaries? In the latest instructions, we moved to using docker directly. I'm curious whether that worked for you or not. Would love to know if there's a reason to prefer building your own binaries. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:17,deployability,build,build-prereq,17,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:50,deployability,instal,installed,50,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:147,deployability,build,build-prereq,147,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:284,deployability,build,build,284,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:290,deployability,version,versions,290,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:306,deployability,instal,install-ubuntu,306,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:326,deployability,instal,install-with-installer-ubuntu,326,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:415,deployability,build,building,415,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:483,deployability,instal,install,483,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:290,integrability,version,versions,290,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:290,modifiability,version,versions,290,"Hi,. if you run `build-prereq.sh`, it should have installed it for you. This section is relevant:. https://github.com/google/deepvariant/blob/r0.7/build-prereq.sh#L88. But if that somehow didn't work for you, you can directly use the instructions on bazel's page:. https://docs.bazel.build/versions/master/install-ubuntu.html#install-with-installer-ubuntu. I would still recommend using our docker image instead of building your own binaries!! If you do that, you don't even need to install bazel!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:140,deployability,instal,installation,140,"so, had been finding my ways around it but still. please can you give me more information on how to use the docker image, because the bazel installation is not just working out for me. thank you i so much appreciate.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:16,deployability,updat,updated,16,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:16,safety,updat,updated,16,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:16,security,updat,updated,16,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:270,testability,simpl,simplify,270,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:270,usability,simpl,simplify,270,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:283,usability,document,documentation,283,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:313,usability,clear,clear,313,"Hi, we recently updated the quick start and case studies to use docker. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-quick-start.md. https://github.com/google/deepvariant/blob/r0.7/docs/deepvariant-case-study.md. It seems like I should rearrange and simplify our documentation to make it more clear. Can you tell me where is the place you first read? Is it the main github page, or did you clone the codebase and directly start from there? I will try to make some improvement next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:140,deployability,contain,container,140,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:290,deployability,instal,install,290,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:192,interoperability,prox,proxy,192,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:222,security,vpn,vpn,222,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:300,security,vpn,vpn,300,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:36,usability,help,help,36,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:88,usability,experien,experienced,88,"@pichuan thank you so much for your help on this, running it via docker is easier but i experienced some challenges pulling the deepvariant container from the docker hub, which i presume is a proxy issue, i think i need a vpn because i am in china and google domains are blocked. trying to install a vpn on my ubuntu.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:184,availability,down,download,184,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built. You can just get it from this zip file:. https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip. which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel. Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:175,deployability,releas,releases,175,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built. You can just get it from this zip file:. https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip. which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel. Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:352,deployability,instal,installing,352,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built. You can just get it from this zip file:. https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip. which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel. Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:248,energy efficiency,model,model,248,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built. You can just get it from this zip file:. https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip. which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel. Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:248,security,model,model,248,"@solokopi since you're already on Ubuntu 16, you can also try using the binaries that we built. You can just get it from this zip file:. https://github.com/google/deepvariant/releases/download/v0.7.0/deepvariant.zip. which has the binaries and the model files. You'll need to run `run-prereq.sh` first to set up your machine. But that will not require installing bazel. Please let me know if that works for you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3236,availability,down,download,3236,"/etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Compon",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4640,availability,state,state,4640,"d-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6806,availability,down,download,6806,"(main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Compon",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8301,availability,state,state,8301," /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9219,availability,state,state,9219,"s' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:284,deployability,Stage,Stage,284,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:484,deployability,Releas,Release,484,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:540,deployability,updat,updates,540,"@pichuan hi, i got the zip file and ra run-prereq.sh and this was the output:. solokopi@solokopi-All-Series:~/Desktop/DeepVariant-0.7.0+cl-208818123$ sudo bash run-prereq.sh. [sudo] password for solokopi: . ========== Load config settings. ========== [2018年 08月 28日 星期二 10:31:05 CST] Stage 'Misc setup' starting. Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease. Hit:2 http://mirrors.aliyun.com/ubuntu xenial InRelease . Hit:3 http://dl.google.com/linux/chrome/deb stable Release . Hit:4 http://mirrors.aliyun.com/ubuntu xenial-updates InRelease . Get:6 http://mirrors.aliyun.com/ubuntu xenial-backports InRelease [107 kB] . Hit:7 http://mirrors.aliyun.com/ubuntu xenial-security InRelease . Hit:8 http://ppa.launchpad.net/webupd8team/java/ubuntu xenial InRelease . Err:9 http://storage.googleapis.com/bazel-apt stable InRelease . Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. Err:10 http://packages.cloud.google.com/apt cloud-sdk-xenial InRelease . Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. Fetched 107 kB in 12min 0s (148 B/s) . Reading package lists... Done. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2713,deployability,Fail,Failed,2713,"google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:2954,deployability,Fail,Failed,2954,"ud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:3226,deployability,fail,failed,3226,"e times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://storage.googleapis.com/bazel-apt/dists/stable/InRelease Cannot initiate the connection to storage.googleapis.com:80 (2404:6800:4012:1::2010). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::2010 80]. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4008:803::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4008:803::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4605,deployability,Build,Building,4605,"etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4614,deployability,depend,dependency,4614,"urces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target P",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4694,deployability,version,version,4694,"ges) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4751,deployability,automat,automatically,4751,"/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.lis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4765,deployability,instal,installed,4765,"d-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:4983,deployability,upgrad,upgraded,4983,"es.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Tran",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5001,deployability,instal,installed,5001,"oud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5034,deployability,upgrad,upgraded,5034,"ations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5209,deployability,Stage,Stage,5209,"et DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is co",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:5216,deployability,Updat,Update,5216,"11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. Reading package lists... Done. Building dependency tree . Reading state information... Done. sudo is already the newest version (1.8.16-0ubuntu1.5). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:43:08 CST] Stage 'Update package list' starting. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configure",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6528,deployability,Fail,Failed,6528,"google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:6796,deployability,fail,failed,6796,"anslations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Failed to fetch http://packages.cloud.google.com/apt/dists/cloud-sdk-xenial/InRelease Cannot initiate the connection to packages.cloud.google.com:80 (2404:6800:4012:1::200e). - connect (101: Network is unreachable) [IP: 2404:6800:4012:1::200e 80]. W: Some index files failed to download. They have been ignored, or old ones used instead. W: Target Packages (main/binary-amd64/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-i386/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8188,deployability,Stage,Stage,8188,"ces.list.d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Buildin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8195,deployability,Instal,Install,8195,".d/google-cloud-sdk.list:2. W: Target Packages (main/binary-all/Packages) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building depend",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8266,deployability,Build,Building,8266,"s) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8275,deployability,depend,dependency,8275,"igured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8361,deployability,version,version,8361,"/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). pytho",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8416,deployability,version,version,8416,"slations (main/i18n/Translation-en_US) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8467,deployability,version,version,8467,"d multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8512,deployability,version,version,8512,"oogle-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8574,deployability,version,version,8574,"d-sdk.list:2. W: Target Translations (main/i18n/Translation-en) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-im",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8637,deployability,automat,automatically,8637," configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'su",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8651,deployability,instal,installed,8651,"multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11 (main/dep11/Components-amd64.yml) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8869,deployability,upgrad,upgraded,8869,"s.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requiremen",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8887,deployability,instal,installed,8887,"ud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-dat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:8920,deployability,upgrad,upgraded,8920,"es.list.d/google-cloud-sdk.list:2. W: Target DEP-11-icons (main/dep11/icons-64x64.tar) is configured multiple times in /etc/apt/sources.list.d/google-cloud-sdk.list:1 and /etc/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9095,deployability,Stage,Stage,9095,"c/apt/sources.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9102,deployability,Instal,Install,9102,"urces.list.d/google-cloud-sdk.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9127,deployability,infrastructur,infrastructure,9127,"k.list:2. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9184,deployability,Build,Building,9184,"Stage 'Install development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/pyt",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9193,deployability,depend,dependency,9193,"tall development packages' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9281,deployability,version,version,9281," tree . Reading state information... Done. pkg-config is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9334,deployability,version,version,9334," is already the newest version (0.29.1-0ubuntu1). unzip is already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement al",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9393,deployability,version,version,9393,"already the newest version (6.0-20ubuntu1). zip is already the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9449,deployability,automat,automatically,9449,"the newest version (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sorted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9463,deployability,instal,installed,9463,"ersion (3.0-11). curl is already the newest version (7.47.0-1ubuntu2.8). zlib1g-dev is already the newest version (1:1.2.8.dfsg-2ubuntu4.1). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9681,deployability,upgrad,upgraded,9681,"ed:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/loca",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9699,deployability,instal,installed,9699,"ux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dis",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9732,deployability,upgrad,upgraded,9732,"rs-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:9993,deployability,Stage,Stage,9993,"rces.list.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:10000,deployability,Instal,Install,10000,"t.d/' as it has an invalid filename extension. ========== [2018年 08月 28日 星期二 10:55:10 CST] Stage 'Install python packaging infrastructure' starting. Reading package lists... Done. Building dependency tree . Reading state information... Done. python-wheel is already the newest version (0.29.0-1). python-dev is already the newest version (2.7.12-1~16.04). python-pip is already the newest version (8.1.1-2ubuntu0.4). The following packages were automatically installed and are no longer required:. libllvm5.0 linux-headers-4.13.0-36 linux-headers-4.13.0-36-generic. linux-image-4.13.0-36-generic linux-image-extra-4.13.0-36-generic. Use 'sudo apt autoremove' to remove them. 0 upgraded, 0 newly installed, 0 to remove and 7 not upgraded. N: Ignoring file 'google-chrome.list.1' in directory '/etc/apt/sources.list.d/' as it has an invalid filename extension. Requirement already up-to-date: pip in /usr/local/lib/python2.7/dist-packages (18.0). ========== [2018年 08月 28日 星期二 10:55:12 CST] Stage 'Install python packages' starting. Requirement already satisfied: contextlib2 in /usr/local/lib/python2.7/dist-packages (0.5.5). Requirement already satisfied: enum34 in /usr/local/lib/python2.7/dist-packages (1.1.6). Requirement already satisfied: sortedcontainers==1.5.3 in /usr/local/lib/python2.7/dist-packages (1.5.3). Requirement already satisfied: intervaltree in /usr/local/lib/python2.7/dist-packages (2.1.0). Requirement already satisfied: sortedcontainers in /usr/local/lib/python2.7/dist-packages (from intervaltree) (1.5.3). Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (2.0.0). Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (4.2.0). Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.0.2). Requirement already satisfied: six>=1.9 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0) (1.11.0). Requirement a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:12149,deployability,modul,modules,12149,"hon2.7/dist-packages (2.19.1). Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2018.8.13). Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (3.0.4). Requirement already satisfied: urllib3<1.24,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (1.23). Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests>=2.18) (2.7). Requirement already satisfied: scipy==1.0 in /usr/local/lib/python2.7/dist-packages (1.0.0). Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy==1.0) (1.14.0). Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python2.7/dist-packages (4.1.2). Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.4.4). Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.2.2). Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (1.11.0). Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (0.11.3). Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from oauth2client>=4.0.0) (3.4.2). Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python2.7/dist-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13673,deployability,api,api-python-client,13673,"st-packages (1.7). Requirement already satisfied: six in /usr/local/lib/python2.7/dist-packages (1.11.0). Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13782,deployability,upgrad,upgrade,13782,". Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages (0.0). Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13868,deployability,api,api-python-client,13868,"equirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:13937,deployability,upgrad,upgrade,13937,"hon2.7/dist-packages (from sklearn) (0.19.2). Requirement already satisfied: pandas in /usr/local/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14026,deployability,api,api-python-client,14026,"cal/lib/python2.7/dist-packages (0.23.4). Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14094,deployability,upgrad,upgrade,14094,"atisfied: numpy>=1.9.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (1.14.0). Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14186,deployability,api,api-python-client,14186,"ent already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14254,deployability,upgrad,upgrade,14254,"/python2.7/dist-packages (from pandas) (2.7.3). Requirement already satisfied: pytz>=2011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14335,deployability,api,api-python-client,14335,"011k in /usr/local/lib/python2.7/dist-packages (from pandas) (2018.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skippin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14404,deployability,upgrad,upgrade,14404,"18.5). Requirement already satisfied: six>=1.5 in /usr/local/lib/python2.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14487,deployability,api,api-python-client,14487," (from python-dateutil>=2.5.0->pandas) (1.11.0). Requirement already satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google C",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14555,deployability,upgrad,upgrade,14555,"ready satisfied: psutil in /usr/local/lib/python2.7/dist-packages (5.4.7). Requirement already up-to-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14650,deployability,api,api-python-client,14650,"-date: google-api-python-client in /usr/local/lib/python2.7/dist-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14718,deployability,upgrad,upgrade,14718,"t-packages (1.7.4). Requirement already satisfied, skipping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
https://github.com/google/deepvariant/issues/89:14820,deployability,api,api-python-client,14820,"ping upgrade: httplib2<1dev,>=0.9.2 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.11.3). Requirement already satisfied, skipping upgrade: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (3.0.0). Requirement already satisfied, skipping upgrade: google-auth-httplib2>=0.0.3 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (0.0.3). Requirement already satisfied, skipping upgrade: six<2dev,>=1.6.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.11.0). Requirement already satisfied, skipping upgrade: google-auth>=1.4.1 in /usr/local/lib/python2.7/dist-packages (from google-api-python-client) (1.5.1). Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (3.4.2). Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (2.1.0). Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python2.7/dist-packages (from google-auth>=1.4.1->google-api-python-client) (0.2.2). Requirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in /usr/local/lib/python2.7/dist-packages (from rsa>=3.1.4->google-auth>=1.4.1->google-api-python-client) (0.4.4). ========== [2018年 08月 28日 星期二 10:55:17 CST] Stage 'Install TensorFlow pip package' starting. Skipping tf-nightly as it is not installed. Skipping tensorflow as it is not installed. Skipping tf-nightly-gpu as it is not installed. Skipping tensorflow-gpu as it is not installed. Installing Google Cloud Platform optimized CPU-only TensorFlow wheel. % Total % Received % Xferd Average Speed Time Time Time Current. Dload Upload Total Spent Left Speed. 0 0 0 0 0 0 0 0 --:--:-- 0:02:09 --:--:-- 0curl: (7) Failed to connect to storage.googleapis.com port 443: Connection timed out.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/89
