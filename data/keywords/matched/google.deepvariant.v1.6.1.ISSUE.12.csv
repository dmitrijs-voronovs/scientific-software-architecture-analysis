id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/419:842,performance,Error,Error,842,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:881,performance,parallel,parallel,881,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1928,performance,time,time,1928,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1944,performance,parallel,parallel,1944,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2724,performance,error,errors,2724,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:900,reliability,fail,failed,900,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2327,reliability,Doe,Does,2327,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:842,safety,Error,Error,842,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1416,safety,modul,module,1416,"c.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2348,safety,test,test,2348,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2384,safety,test,test,2384,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2682,safety,input,input,2682,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2724,safety,error,errors,2724,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2559,security,access,access,2559,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2595,security,access,access,2595,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:848,testability,trace,trace,848,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1318,testability,Trace,Traceback,1318," 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2348,testability,test,test,2348,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2384,testability,test,test,2384,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2749,testability,context,context,2749,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:19,usability,statu,status,19,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:223,usability,statu,status,223,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:555,usability,Command,Command,555,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:842,usability,Error,Error,842,"make_examples exit status 252; **Describe the issue:**. Running DeepVariant v1.1.0 on viral amplicon PacBio HiFi data, aligned with pbmm2, using the run_deepvariant script. Core dump during the make_examples step with exit status 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1222,usability,user,user,1222,"tatus 252. **Setup**. - Operating system: CentOS Linux release 7.4.1708 (Core), singularity version 3.5.3-1.el7. - DeepVariant version: 1.1.0. - Installation method (Docker, built from source, etc.): singularity image pulled from docker://google/deepvariant:1.1.0. - Type of data: PacBio HiFi amplicons. **Steps to reproduce:**. - Command:. ```bash. singularity exec --bind /scratch:/tmp,/usr/lib/locale/ \. docker://google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1734,usability,command,command,1734,"ref.fa \. --reads reads.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:1917,usability,Command,Command,1917,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2308,usability,statu,status,2308,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2682,usability,input,input,2682,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/419:2724,usability,error,errors,2724,"s.bam \. --output_vcf ""deepvariant/output.vcf.gz"" \. --num_shards 24 -v 2. ```. - Error trace: (if applicable). ```bash. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples /tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz --add_hp_channel --alt_aligned_pileup diff_channels --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 2. real 0m35.091s. user 0m1.452s. sys 0m1.237s. I0205 10:26:31.374659 47922265431040 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 23 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ref.fa --reads reads.bam --examples ""/tmp/tmp7rsj5zvh/make_examples.tfrecord@24.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 252. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? - I have limited access to docker in general, and no access to docker on this machine. I've been running v1.0.0 on singularity on different input types (human WGS) regularly without errors. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/419
https://github.com/google/deepvariant/issues/420:178,deployability,manag,manager,178,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:522,deployability,manag,manager,522,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:554,deployability,Fail,Failed,554,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:734,deployability,modul,module,734,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:1955,deployability,modul,module,1955,"ke_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3181,deployability,continu,continue,3181,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:178,energy efficiency,manag,manager,178,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:522,energy efficiency,manag,manager,522,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2230,integrability,sub,subprocess,2230,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2323,integrability,sub,subprocess,2323,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2404,integrability,sub,subprocess,2404,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2478,integrability,buffer,buffer,2478,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2817,integrability,buffer,buffer,2817,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:820,interoperability,platform,platform,820,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:734,modifiability,modul,module,734,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:793,modifiability,pac,packages,793,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:1955,modifiability,modul,module,1955,"ke_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2015,modifiability,pac,packages,2015,"s(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2115,modifiability,pac,packages,2115,"/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. -----",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2444,performance,time,time,2444,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2459,performance,parallel,parallel,2459,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2783,performance,time,time,2783,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2798,performance,parallel,parallel,2798,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:554,reliability,Fail,Failed,554,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:178,safety,manag,manager,178,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:202,safety,input,input,202,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:522,safety,manag,manager,522,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:734,safety,modul,module,734,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:1955,safety,modul,module,1955,"ke_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3099,safety,Test,Test,3099,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3104,safety,Test,Test,3104,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:509,security,password,password,509,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:587,testability,Trace,Traceback,587,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:1878,testability,Trace,Traceback,1878," ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3099,testability,Test,Test,3099,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3104,testability,Test,Test,3104,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:70,usability,help,help,70,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:202,usability,input,input,202,"Can`t open .bam file; I am running Docker image of your software. Pls help to solve the problem. Here are the codes for running it:. BIN_VERSION=""1.1.0"". export OUTPUT_DIR=/home/manager/deepvariant-run/input. sudo docker run -v ""${OUTPUT_DIR}"":/opt/deepvariant/output dajunluo/deepvariant python run_deepvariant.py \. --model_type=WGS \. --ref=Reference.fasta \. --reads=newtest.bam \. --output_vcf=../output/test_output.vcf.gz \. --output_gvcf=../test_output/output.g.vcf.gz. ls $OUTPUT_DIR. Result:. [sudo] password for manager: . [E::hts_open_format] Failed to open file newtest.bam. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1235, in <module>. tf.app.run(). File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:1849,usability,user,user,1849,"run. _sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1186, in main. options = default_options(add_flags=True, flags_obj=FLAGS). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 315, in default_options. with sam.SamReader(flags_obj.reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2252,usability,command,command,2252,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2435,usability,Command,Command,2435,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2740,usability,statu,status,2740,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:2768,usability,command,command,2768,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/issues/420:3199,usability,help,helping,3199,"reads) as sam_reader:. File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/genomics_reader.py"", line 216, in __init__. self._reader = self._native_reader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 255, in _native_reader. return NativeSamReader(input_path, **kwargs). File ""/tmp/Bazel.runfiles_a5JjgU/runfiles/com_google_deepvariant/third_party/nucleus/io/sam.py"", line 232, in __init__. use_original_base_quality_scores=use_original_base_quality_scores). ValueError: Not found: Could not open newtest.bam. real	0m6.581s. user	0m4.128s. sys	0m1.476s. Traceback (most recent call last):. File ""run_deepvariant.py"", line 235, in <module>. app.run(main). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run. _run_main(main, args). File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""run_deepvariant.py"", line 215, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python2.7/subprocess.py"", line 541, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command 'time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}' returned non-zero exit status 1. ***** Running the command:*****. time seq 0 0 | parallel -k --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""Reference.fasta"" --reads ""newtest.bam"" --examples ""/tmp/deepvariant_tmp_output/make_examples.tfrecord@1.gz"" --gvcf ""/tmp/deepvariant_tmp_output/gvcf.tfrecord@1.gz"" --task {}. data newtest.bam Reference Reference.fasta Test Test.bam. ------------------. (program exited with code: 0). Press return to continue. Thx for helping me.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/420
https://github.com/google/deepvariant/pull/421:31,security,modif,modified,31,Add HP Blog to the DV blog!; I modified `figcaption` to use a small gray text. figcaption was not used anywhere else that I could see.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/421
https://github.com/google/deepvariant/issues/422:107,availability,error,error,107,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:296,availability,state,state,296,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:443,availability,error,error,443,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:552,availability,Operat,Operating,552,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1142,availability,Error,Error,1142,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:308,deployability,contain,contained,308,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:604,deployability,version,version,604,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:623,deployability,Instal,Installation,623,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:79,energy efficiency,GPU,GPU,79,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:842,energy efficiency,gpu,gpu,842,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1251,energy efficiency,GPU,GPU,1251,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:296,integrability,state,state,296,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:492,integrability,sub,submit,492,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:604,integrability,version,version,604,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:766,interoperability,bind,bind,766,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:604,modifiability,version,version,604,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:673,modifiability,Pac,PacBio,673,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:766,modifiability,bind,bind,766,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:900,modifiability,PAC,PACBIO,900,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:79,performance,GPU,GPU,79,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:107,performance,error,error,107,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:443,performance,error,error,443,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:842,performance,gpu,gpu,842,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1142,performance,Error,Error,1142,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1251,performance,GPU,GPU,1251,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:107,safety,error,error,107,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:425,safety,compl,completes,425,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:443,safety,error,error,443,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1142,safety,Error,Error,1142,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:425,security,compl,completes,425,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1148,testability,trace,trace,1148,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:107,usability,error,error,107,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:204,usability,indicat,indicate,204,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:443,usability,error,error,443,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:499,usability,command,command,499,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:733,usability,Command,Command,733,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/422:1142,usability,Error,Error,1142,"No such file or directory; Hello, when running DeepVariant on a machine with a GPU, we get . [the attached error](https://github.com/google/deepvariant/files/5947987/DeepVariantError.txt). which seems to indicate that DeepVariant cannot find the samples in the working directory which is a solid state drive contained within the node. Oddly enough, when we rerun without removing the files in the /tmp directory, DeepVariant completes without error. Do you have any explanation for this? The submit command is below as system information. **Setup**. - Operating system: CentOS7, cuda/11.0. - DeepVariant version: v1.1.0. - Installation method: Singularity. - Type of data: PacBio HiFi from SQII with hg38. **Steps to reproduce:**. - Command: `singularity run --nv --bind $(readlink -f dv_wd):/wd /path/to/deepvariant/images/deepvariant_1.1.0-gpu.sif /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/wd/hg38.ref.fasta --reads=/wd/${sample}.bam --output_vcf=/wd/${sample}.vcf --output_gvcf=/wd/${sample}.gvcf --novcf_stats_report --intermediate_results_dir=/tmp/deepvariant_tmp/$( whoami )_${sample}/ --num_shards=${threads}`. - Error trace: Included above. - We have also tried out a similar process running on another machine without a GPU, and we do not see this issue.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/422
https://github.com/google/deepvariant/issues/423:147,deployability,stage,stages,147,"""How DeepVariant works"" figure on Github dark mode; **Describe the issue:**. You may want to consider adding a white background to your diagram of stages in DeepVariant under ""How DeepVariant works"" in your README. Since Github added dark mode, SVG diagrams without set backgrounds are difficult to view for users with this setting. There is an [active feature request open for Github](https://github.community/t/support-theme-context-for-images-in-light-vs-dark-mode/147981/38), but I thought that you all might appreciate the Github issue. . Here is a screenshot of the figure on my screen - . <img width=""851"" alt=""Screen Shot 2021-02-10 at 7 28 19 PM"" src=""https://user-images.githubusercontent.com/9423424/107672807-547d6c00-6c63-11eb-9f46-9116b8adae56.png"">. Thank you! Keep up the great work!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/423
https://github.com/google/deepvariant/issues/423:427,testability,context,context-for-images-in-light-vs-dark-mode,427,"""How DeepVariant works"" figure on Github dark mode; **Describe the issue:**. You may want to consider adding a white background to your diagram of stages in DeepVariant under ""How DeepVariant works"" in your README. Since Github added dark mode, SVG diagrams without set backgrounds are difficult to view for users with this setting. There is an [active feature request open for Github](https://github.community/t/support-theme-context-for-images-in-light-vs-dark-mode/147981/38), but I thought that you all might appreciate the Github issue. . Here is a screenshot of the figure on my screen - . <img width=""851"" alt=""Screen Shot 2021-02-10 at 7 28 19 PM"" src=""https://user-images.githubusercontent.com/9423424/107672807-547d6c00-6c63-11eb-9f46-9116b8adae56.png"">. Thank you! Keep up the great work!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/423
https://github.com/google/deepvariant/issues/423:308,usability,user,users,308,"""How DeepVariant works"" figure on Github dark mode; **Describe the issue:**. You may want to consider adding a white background to your diagram of stages in DeepVariant under ""How DeepVariant works"" in your README. Since Github added dark mode, SVG diagrams without set backgrounds are difficult to view for users with this setting. There is an [active feature request open for Github](https://github.community/t/support-theme-context-for-images-in-light-vs-dark-mode/147981/38), but I thought that you all might appreciate the Github issue. . Here is a screenshot of the figure on my screen - . <img width=""851"" alt=""Screen Shot 2021-02-10 at 7 28 19 PM"" src=""https://user-images.githubusercontent.com/9423424/107672807-547d6c00-6c63-11eb-9f46-9116b8adae56.png"">. Thank you! Keep up the great work!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/423
https://github.com/google/deepvariant/issues/423:413,usability,support,support-theme-context-for-images-in-light-vs-dark-mode,413,"""How DeepVariant works"" figure on Github dark mode; **Describe the issue:**. You may want to consider adding a white background to your diagram of stages in DeepVariant under ""How DeepVariant works"" in your README. Since Github added dark mode, SVG diagrams without set backgrounds are difficult to view for users with this setting. There is an [active feature request open for Github](https://github.community/t/support-theme-context-for-images-in-light-vs-dark-mode/147981/38), but I thought that you all might appreciate the Github issue. . Here is a screenshot of the figure on my screen - . <img width=""851"" alt=""Screen Shot 2021-02-10 at 7 28 19 PM"" src=""https://user-images.githubusercontent.com/9423424/107672807-547d6c00-6c63-11eb-9f46-9116b8adae56.png"">. Thank you! Keep up the great work!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/423
https://github.com/google/deepvariant/issues/423:669,usability,user,user-images,669,"""How DeepVariant works"" figure on Github dark mode; **Describe the issue:**. You may want to consider adding a white background to your diagram of stages in DeepVariant under ""How DeepVariant works"" in your README. Since Github added dark mode, SVG diagrams without set backgrounds are difficult to view for users with this setting. There is an [active feature request open for Github](https://github.community/t/support-theme-context-for-images-in-light-vs-dark-mode/147981/38), but I thought that you all might appreciate the Github issue. . Here is a screenshot of the figure on my screen - . <img width=""851"" alt=""Screen Shot 2021-02-10 at 7 28 19 PM"" src=""https://user-images.githubusercontent.com/9423424/107672807-547d6c00-6c63-11eb-9f46-9116b8adae56.png"">. Thank you! Keep up the great work!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/423
https://github.com/google/deepvariant/pull/424:0,deployability,Updat,Update,0,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/pull/424:74,reliability,doe,doesn,74,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/pull/424:0,safety,Updat,Update,0,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/pull/424:0,security,Updat,Update,0,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/pull/424:30,usability,Command,Command,30,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/pull/424:38,usability,document,documentation,38,"Update deepvariant-docker.md; Command documentation not working. . gsutil doesn't work without quote when using ""asterisk"".",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/424
https://github.com/google/deepvariant/issues/425:132,energy efficiency,model,model,132,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:293,energy efficiency,model,model,293,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:132,security,model,model,132,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:170,security,modif,modify,170,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:293,security,model,model,293,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:329,security,modif,modification,329,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/425:0,testability,Coverag,Coverage,0,"Coverage depth over 100X; This might not be an issue, but a question. For dataset with sequencing depth >100X, will the pre-trained model still be fully functional if we modify the tensor size following https://github.com/google/deepvariant/blob/r0.5/deepvariant/make_examples.py#L177? or the model has to be retrained after the modification? Thank you,. Hugh",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/425
https://github.com/google/deepvariant/issues/426:0,safety,test,test,0,test; This is a test.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/426
https://github.com/google/deepvariant/issues/426:16,safety,test,test,16,test; This is a test.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/426
https://github.com/google/deepvariant/issues/426:0,testability,test,test,0,test; This is a test.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/426
https://github.com/google/deepvariant/issues/426:16,testability,test,test,16,test; This is a test.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/426
https://github.com/google/deepvariant/issues/427:43,deployability,stage,stage,43,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:103,energy efficiency,cloud,cloud,103,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:342,energy efficiency,CPU,CPU,342,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:65,integrability,coupl,couple,65,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:220,interoperability,specif,specific,220,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:65,modifiability,coupl,couple,65,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:75,performance,time,times,75,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:342,performance,CPU,CPU,342,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:12,reliability,doe,does,12,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:65,testability,coupl,couple,65,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/427:425,usability,help,help,425,"Deepvariant does not pass to call variants stage; . I have run a couple of times deepvariant on Google cloud, following the steps described at the corresponding webpage, and obtained the expected results. However, for a specific sample only make_examples and gvcf.tfrecord files are generated. The VM instance is running for 10 hours at 100% CPU and suddenly drops to almost 0% without the generation of any new results. Any help will be appreciated!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/427
https://github.com/google/deepvariant/issues/428:9,energy efficiency,model,model,9,"no human model use; in my project ,my species is pig——diploid,haploid genome size 2.5Gb,how to use deepvariant in my pig data ?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/428
https://github.com/google/deepvariant/issues/428:9,security,model,model,9,"no human model use; in my project ,my species is pig——diploid,haploid genome size 2.5Gb,how to use deepvariant in my pig data ?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/428
https://github.com/google/deepvariant/issues/429:30,availability,failur,failure,30,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:391,availability,Operat,Operating,391,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1723,availability,Error,Error,1723," cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3328,availability,error,errors,3328,"out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3471,availability,error,errors,3471,"g the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3614,availability,error,errors,3614,"199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5275,availability,error,error,5275,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:30,deployability,fail,failure,30,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:254,deployability,fail,fails,254,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:427,deployability,version,version,427,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:445,deployability,Instal,Installation,445,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2456,deployability,log,log,2456,"-output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2871,deployability,log,log,2871,"er 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3286,deployability,log,log,3286,".vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:693,energy efficiency,CPU,CPUs,693,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:427,integrability,version,version,427,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1853,integrability,batch,batches,1853,"ocale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_var",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5233,interoperability,bind,bindings,5233,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:427,modifiability,version,version,427,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5233,modifiability,bind,bindings,5233,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:30,performance,failur,failure,30,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:693,performance,CPU,CPUs,693,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1723,performance,Error,Error,1723," cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1853,performance,batch,batches,1853,"ocale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_var",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2086,performance,time,time,2086,"ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2495,performance,time,time,2495,"ut.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creatio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2910,performance,time,time,2910,"319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	783",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3328,performance,error,errors,3328,"out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3471,performance,error,errors,3471,"g the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3614,performance,error,errors,3614,"199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5275,performance,error,error,5275,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:30,reliability,fail,failure,30,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:254,reliability,fail,fails,254,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3947,reliability,Doe,Does,3947,"ariants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermedi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1723,safety,Error,Error,1723," cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2456,safety,log,log,2456,"-output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2871,safety,log,log,2871,"er 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3286,safety,log,log,3286,".vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3328,safety,error,errors,3328,"out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3471,safety,error,errors,3471,"g the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3614,safety,error,errors,3614,"199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3968,safety,test,test,3968,"ir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4008,safety,test,test,4008,"out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4227,safety,input,input,4227,"_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4390,safety,input,input,4390,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4447,safety,input,input,4447,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4499,safety,input,input,4499,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4551,safety,input,input,4551,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5275,safety,error,error,5275,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2456,security,log,log,2456,"-output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2871,security,log,log,2871,"er 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3286,security,log,log,3286,".vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:542,testability,instrument,instrument,542,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1729,testability,trace,trace,1729,"e reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfreco",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2456,testability,log,log,2456,"-output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2871,testability,log,log,2871,"er 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3286,testability,log,log,3286,".vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3968,testability,test,test,3968,"ir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ``",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4008,testability,test,test,4008,"out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4990,testability,context,context,4990,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:140,usability,help,helpfull,140,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:181,usability,indicat,indicated,181,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:810,usability,Command,Command,810,"DeepTrio postprocess_variants failure; **Describe the issue:**. Are the `--output_gvcf` flags with DeepTrio required arguments? . In the `--helpfull` page of DeepTrio, they are not indicated as required; however, when omitting just these flags, DeepTrio fails to generate the expected VCF outputs. . ```. --output_gvcf_child . --output_gvcf_parent1. --output_gvcf_parent2. ```. **Setup**. - Operating system: Linux. - DeepTrio version: 1.1.0. - Installation method (Docker, built from source, etc.): Singularity . - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) I am running DeepTrio using cattle genomes on a local machine with 56 CPUs and 500GB RAM using the same cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. rea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:1723,usability,Error,Error,1723," cattle reference genome from creating the BAM files. . **Steps to reproduce:** . - Command:. ```. singularity run \. -B /usr/lib/locale/:/usr/lib/locale/,""${REF_PATH}/"":/ref_dir/,""${BAM_PATH}/"":/in_dir/,""${RESULTS_DIR}/"":/out_dir/ \. deepvariant_deeptrio-${BIN_VERSION_DT}.sif \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2015,usability,user,user,2015,"ariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2071,usability,command,command,2071,"ref=/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa \. --intermediate_results_dir=""/out_dir/${trioName}/"" \. --sample_name_child ""199713"" \. --sample_name_parent1 ""199710"" \. --sample_name_parent2 ""199718"" \. --reads_child=""/in_dir/199713.realigned.recalibrated.bam"" \. --reads_parent1=""/in_dir/199710.realigned.recalibrated.bam"" \. --reads_parent2=""/in_dir/199718.realigned.recalibrated.bam"" \. --output_vcf_child=""/out_dir/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2480,usability,command,command,2480,"r/199713.output.vcf.gz"" \. --output_vcf_parent1=""/out_dir/199710.output.vcf.gz"" \. --output_vcf_parent2=""/out_dir/199718.output.vcf.gz"" \. --logging_dir=""/out_dir/${trioName}/"" \. --num_shards=$(nproc) \. --vcf_stats_report=true \. ```. - Error trace: (if applicable). ```. I0307 04:23:48.405982 46912496319168 call_variants.py:458] Processed 9497443 examples in 18550 batches [0.321 sec per 100]. I0307 04:23:48.406211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:2895,usability,command,command,2895,"6211 46912496319168 call_variants.py:461] Done calling variants from a total of 9497443 examples. real	507m54.839s. user	17892m22.565s. sys	172m54.026s. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_child.tfrecord.gz"" --outfile ""/out_dir/199713.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.7",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3328,usability,error,errors,3328,"out_dir/199713-199710-199718/gvcf_child.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_child.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3471,usability,error,errors,3471,"g the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3614,usability,error,errors,3614,"199718/call_variants_output_parent1.tfrecord.gz"" --outfile ""/out_dir/199710.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG00",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3735,usability,user,user,3735,"th ""/out_dir/199713-199710-199718/gvcf_parent1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3779,usability,user,user,3779,"t1.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_n",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3823,usability,user,user,3823,"3-199710-199718//postprocess_variants_parent1.log. ***** Starting the command:*****. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:3904,usability,user,user,3904,"**. time /opt/deepvariant/bin/postprocess_variants --ref ""/ref_dir/ARS-UCD1.2_Btau5.0.1Y.fa"" --infile ""/out_dir/199713-199710-199718/call_variants_output_parent2.tfrecord.gz"" --outfile ""/out_dir/199718.output.vcf.gz"" --nonvariant_site_tfrecord_path ""/out_dir/199713-199710-199718/gvcf_parent2.tfrecord@56.gz"" 2>&1 | tee /out_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4227,usability,input,input,4227,"_dir/199713-199710-199718//postprocess_variants_parent2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity pa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4390,usability,input,input,4390,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4447,usability,input,input,4447,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4499,usability,input,input,4499,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:4551,usability,input,input,4551,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5023,usability,command,command,5023,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/429:5275,usability,error,error,5275,"t2.log. E0307 04:23:51.666978 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.667161 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. E0307 04:23:51.705964 46912496319168 errors.py:61] gVCF creation requires both nonvariant_site_tfrecord_path and gvcf_outfile flags to be set. real	0m3.173s. user	0m3.003s. sys	0m3.160s. real	0m3.194s. user	0m3.299s. sys	0m4.216s. real	0m3.254s. user	0m3.024s. sys	0m2.808s. post_process returns: [0, 0, 0]. real	2008m37.771s. user	78330m54.158s. sys	730m9.042s. ```. **Does the quick start test work on your system?** Yes. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes, see below:. ```. sudo docker run \. -v ""${INPUT_DIR}"":""/input"" \. -v ""${OUTPUT_DIR}"":""/output"" \. google/deepvariant:deeptrio-""${BIN_VERSION}"" \. /opt/deepvariant/bin/deeptrio/run_deeptrio \. --model_type=WGS \. --ref=/input/GRCh38_no_alt_analysis_set.fasta \. --reads_child=/input/HG002.chr20.10_10p1mb.bam \. --reads_parent1=/input/HG003.chr20.10_10p1mb.bam \. --reads_parent2=/input/HG004.chr20.10_10p1mb.bam \. --output_vcf_child /output/HG002.output.vcf.gz \. --output_vcf_parent1 /output/HG003.output.vcf.gz \. --output_vcf_parent2 /output/HG004.output.vcf.gz \. --sample_name_child 'HG002' \. --sample_name_parent1 'HG003' \. --sample_name_parent2 'HG004' \. --num_shards $(nproc) \. --regions ""chr20:10,000,000-10,010,000"" \. --intermediate_results_dir /output/intermediate_results_dir \. ```. **Any additional context:**. DeepVariant's single command `run_deepvariant` works on my system via Singularity. DeepVariant `postprocess_variants` successfully produces a VCF file when omitting the `--output_gvcf` flag using the same data and singularity path bindings. Only DeepTrio seems to throw an error. .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/429
https://github.com/google/deepvariant/issues/430:103,availability,avail,available,103,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:84,deployability,version,version,84,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:141,deployability,version,version,141,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:7,energy efficiency,GPU,GPU,7,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:72,energy efficiency,GPU,GPU,72,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:133,energy efficiency,Current,Current,133,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:179,energy efficiency,gpu,gpu,179,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:235,energy efficiency,GPU,GPUs,235,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:84,integrability,version,version,84,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:141,integrability,version,version,141,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:84,modifiability,version,version,84,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:141,modifiability,version,version,141,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:7,performance,GPU,GPU,7,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:72,performance,GPU,GPU,72,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:179,performance,gpu,gpu,179,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:235,performance,GPU,GPUs,235,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:103,reliability,availab,available,103,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:204,reliability,doe,does,204,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:103,safety,avail,available,103,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:103,security,availab,available,103,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:49,testability,plan,plan,49,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:19,usability,support,support,19,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/430:57,usability,support,support,57,"nVidia GPU Cuda 11 support in docker; Is there a plan to support nVidia GPU Cuda 11 version in dockers available in the dockerhub? . Current version of `google/deepvariant:latest-gpu` uses Cuda 10, which does not work on newest nVidia GPUs.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/430
https://github.com/google/deepvariant/issues/431:160,availability,error,error,160,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:244,availability,Operat,Operating,244,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:1226,availability,Error,Error,1226,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:288,deployability,version,version,288,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:306,deployability,version,version,306,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:323,deployability,Instal,Installation,323,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:166,integrability,messag,messages,166,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:288,integrability,version,version,288,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:306,integrability,version,version,306,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:166,interoperability,messag,messages,166,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:288,modifiability,version,version,288,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:306,modifiability,version,version,306,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:160,performance,error,error,160,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:1226,performance,Error,Error,1226,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:160,safety,error,error,160,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:221,safety,compl,complete,221,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:1226,safety,Error,Error,1226,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:221,security,compl,complete,221,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:1232,testability,trace,trace,1232,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:160,usability,error,error,160,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:423,usability,Command,Command,423,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/431:1226,usability,Error,Error,1226,"run_deeptrio missing child vcfs; I ran deeptrio on a trio WGS data. I got the gvcf and vcf for parent 1 and 2 but I didn't get output from child. There were no error messages that I could find as to why. The output seems complete. **Setup**. - Operating system: Windows 10. - DeepVariant version: DeepTrio version 1.1.0. - Installation method: Docker. - Type of data: Illumina, GRCh38, trio WGS. **Steps to reproduce:**. - Command:. `/opt/deepvariant/bin/deeptrio/run_deeptrio . - --model_type=WGS . - --ref=GRCh38_full_analysis_set_plus_decoy_hla.fa . - --reads_child=20A0012672_P_GRCh38.bam . - --reads_parent1=20A0012673_M_GRCh38.bam . - --reads_parent2=NBVY8432_GRCh38.bam. - --output_vcf_child 20A0012672_P_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent1 20A0012673_M_GRCh38_deeptrio.vcf.gz . - --output_vcf_parent2 NBVY8432_GRCh38_deeptrio.vcf.gz . - --sample_name_child '20A0012672_P' . - --sample_name_parent1 '20A0012673_M' . - --sample_name_parent2 'NBVY8432' . - --num_shards $(nproc) . - --intermediate_results_dir ../home/tmp . - --output_gvcf_child 20A0012672_P_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent1 20A0012673_M_GRCh38_deeptrio.gvcf.gz . - --output_gvcf_parent2 NBVY8432_GRCh38_deeptrio.gvcf.gz`. - Error trace: NA.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/431
https://github.com/google/deepvariant/issues/432:235,availability,error,error,235,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:737,availability,checkpoint,checkpoint,737,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:887,availability,error,error,887,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:88,deployability,build,build,88,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:137,deployability,instal,installed,137,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:418,deployability,fail,failing,418,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:505,deployability,instal,installed,505,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:532,deployability,version,version,532,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1048,deployability,modul,module,1048,"en running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:771,energy efficiency,model,models,771,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:827,energy efficiency,model,model,827,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1773,energy efficiency,model,model,1773,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1779,energy efficiency,model,model,1779,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1925,energy efficiency,model,model,1925,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:532,integrability,version,version,532,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1144,interoperability,platform,platform,1144,"eepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:532,modifiability,version,version,532,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1048,modifiability,modul,module,1048,"en running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1117,modifiability,pac,packages,1117,"docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inf",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:235,performance,error,error,235,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:887,performance,error,error,887,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:418,reliability,fail,failing,418,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:737,reliability,checkpoint,checkpoint,737,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:235,safety,error,error,235,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:887,safety,error,error,887,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1048,safety,modul,module,1048,"en running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:771,security,model,models,771,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:827,security,model,model,827,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1773,security,model,model,1773,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1779,security,model,model,1779,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:1925,security,model,model,1925,"pt, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 77, in freeze_graph. graph_def = optimize_for_inference_lib.optimize_for_inference(. NameError: name 'optimize_for_inference_lib' is not defined. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:900,testability,Trace,Traceback,900,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:172,usability,tool,toolkit,172,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:235,usability,error,error,235,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:386,usability,Statu,StatusCode,386,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:427,usability,Statu,StatusCode,427,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:575,usability,command,command,575,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/432:887,usability,error,error,887,"name 'optimize_for_inference_lib' is not defined when running call_variants; I tried to build deepvariant through my own docker image. I installed deepvariant and openvino toolkit. But, when I run _call_variants.zip_ script, I get the error **_name 'optimize_for_inference_lib' is not defined_**. I was retracing steps and came to conclusion that `from openvino.inference_engine import StatusCode` part of the code is failing. StatusCode cannot be imported. Have you ever encountered the same problem ? I installed DeepVariant1.1.0 version via Docker using Ubuntu 18.04. The command I run was . `python /opt/DeepVariant-1.1.0/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/DeepVariant-1.1.0/models/DeepVariant-inception_v3-1.1.0+data-wes_standard/model.ckpt --use_openvino --num_readers 32 ` . and got this error:. ```. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 409, in call_variants. checkpoint_path, input_fn=tf_dataset, model=model). File ""/tmp/Bazel.runfiles_xn6q5j3y/runfiles/com_google_deepvariant/deepvariant/openvino_estimator.py"", line 89, in __init__. freeze_graph(model, checkpoint_path, tensor_shape). File ""/tmp/Bazel.runfiles_xn6q5j3y/r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/432
https://github.com/google/deepvariant/issues/433:254,energy efficiency,model,model,254,"unspecified_caller vs. very_sensitive_caller vs. vcf_candidate_importer; Hello, I was hoping you could explain the differences between each of the options you can use for the `--variant_caller` option. How do each of these differ in terms of the type of model produced and interpretation of results? I'm having trouble finding documentation for this. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/433
https://github.com/google/deepvariant/issues/433:254,security,model,model,254,"unspecified_caller vs. very_sensitive_caller vs. vcf_candidate_importer; Hello, I was hoping you could explain the differences between each of the options you can use for the `--variant_caller` option. How do each of these differ in terms of the type of model produced and interpretation of results? I'm having trouble finding documentation for this. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/433
https://github.com/google/deepvariant/issues/433:327,usability,document,documentation,327,"unspecified_caller vs. very_sensitive_caller vs. vcf_candidate_importer; Hello, I was hoping you could explain the differences between each of the options you can use for the `--variant_caller` option. How do each of these differ in terms of the type of model produced and interpretation of results? I'm having trouble finding documentation for this. Thank you!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/433
https://github.com/google/deepvariant/issues/434:281,availability,error,error,281,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:516,availability,Operat,Operative,516,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:562,deployability,version,version,562,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:589,deployability,Instal,Installation,589,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1121,deployability,log,logs,1121,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:562,integrability,version,version,562,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:562,modifiability,version,version,562,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:634,modifiability,Pac,PacBio,634,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:932,modifiability,PAC,PACBIO,932,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:281,performance,error,error,281,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1134,reliability,Doe,Does,1134,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:281,safety,error,error,281,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:799,safety,input,input,799,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:949,safety,input,input,949,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:980,safety,input,input,980,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1121,safety,log,logs,1121,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1155,safety,test,test,1155,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1193,safety,test,test,1193,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1121,security,log,logs,1121,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1121,testability,log,logs,1121,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1155,testability,test,test,1155,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:1193,testability,test,test,1193,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:170,usability,visual,visualize,170,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:281,usability,error,error,281,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:737,usability,Command,Command,737,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:775,usability,user,user,775,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:799,usability,input,input,799,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:817,usability,user,user,817,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:949,usability,input,input,949,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/434:980,usability,input,input,980,"Could not read base quality scores; **Describe the issue:**. The prints that read base quality scores cannot be read, as result, no variants are reported. However, I can visualize these values in the reads in IGV. How is that these values cannot be read? This is the line with the error, which repeats one after. 2021-03-26 19:12:43.550815: W third_party/nucleus/io/sam_reader.cc:534] Could not read base quality scores m64036_210113_122249/147655225/ccs: Not found: Could not read base quality scores. **Setup**. - Operative system: Ubuntu 20.04. - DeepVariant version: 1.1.0 (latest). - Installation method: docker. - Type of data: PacBio HiFi. BAM files aligned to the reference with `minimap2 -ax map-pb`. **Steps to reproduce:**. - Command:. ```. docker run \. -v /home/user/working_directory:/input \. -v /home/user/working_directory:/output \. google/deepvariant:1.1.0 \. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=/input/reference.fa \. --reads=/input/file.bam \. --output_vcf=/output/file.vcf \. --call_variants_extra_args=""use_openvino=true"" \. --num_shards=4 \. --logging_dir=/output/logs. ```. **Does the quick start test work on your system?**. Yes. The test works without problem.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/434
https://github.com/google/deepvariant/issues/435:810,availability,checkpoint,checkpoint,810,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:591,deployability,log,logs,591,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:886,deployability,log,logs,886,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:905,deployability,log,log,905,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:1058,deployability,modul,module,1058,". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2515,deployability,log,logs,2515,"iles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2541,deployability,log,log,2541,"t/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2702,deployability,modul,module,2702,"riants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7z",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:827,energy efficiency,model,models,827,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:838,energy efficiency,model,model,838,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:1154,interoperability,platform,platform,1154,"""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2018,interoperability,format,format,2018,"ant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2798,interoperability,platform,platform,2798,"th(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:3866,interoperability,format,format,3866,"rror: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"". ```. Please explain what I am doing wrong. Thanks",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:1058,modifiability,modul,module,1058,". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:1127,modifiability,pac,packages,1127,"PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2702,modifiability,modul,module,2702,"riants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7z",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2771,modifiability,pac,packages,2771,"ne_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:648,performance,time,time,648,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2218,performance,time,time,2218,"s_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:810,reliability,checkpoint,checkpoint,810,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:210,safety,input,input,210,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:363,safety,input,input,363,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:389,safety,input,input,389,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:591,safety,log,logs,591,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:886,safety,log,logs,886,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:905,safety,log,log,905,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:1058,safety,modul,module,1058,". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find ma",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2273,safety,input,input,2273,"runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2515,safety,log,logs,2515,"iles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2541,safety,log,log,2541,"t/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2702,safety,modul,module,2702,"riants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1035, in get_cvo_paths_and_first_record. ','.join(paths), proto=deepvariant_pb2.CallVariantsOutput). File ""/tmp/Bazel.runfiles_vdgo7z",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:591,security,log,logs,591,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:827,security,model,models,827,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:838,security,model,model,838,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:886,security,log,logs,886,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:905,security,log,log,905,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2515,security,log,logs,2515,"iles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2541,security,log,log,2541,"t/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:591,testability,log,logs,591,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:886,testability,log,logs,886,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:905,testability,log,log,905,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:910,testability,Trace,Traceback,910,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2515,testability,log,logs,2515,"iles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2541,testability,log,log,2541,"t/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2546,testability,Trace,Traceback,2546,"riant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1053, in get_sample_name. _, record = get_cvo_paths_and_first_record(). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postproces",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:210,usability,input,input,210,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:363,usability,input,input,363,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:389,usability,input,input,389,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:631,usability,command,command,631,"Unable to run on local machine; ```(bash. BIN_VERSION=""1.1.0"". INPUT_DIR=""${PWD}/lecture8_data"". ls -1 ${INPUT_DIR}. OUTPUT_DIR=""${PWD}/AO6-output"". mkdir -p ""${OUTPUT_DIR}"". docker run \. 	-v ""${INPUT_DIR}"":""/input"" \. 	-v ""${OUTPUT_DIR}"":""/output"" \. 	google/deepvariant:""${BIN_VERSION}"" \. 	/opt/deepvariant/bin/run_deepvariant \. 	--model_type=WGS \. 	--ref=/input/ref.fa \. 	--reads=/input/sample.bam \. 	--output_vcf=/output/OUTPUT_VCF.vfc \. 	--output_gvcf=/output/OUTPUT_GVCF.vfc \. 	--call_variants_extra_args=""use_openvino=true"" \. 	--num_shards=$(nproc) \. 	--logging_dir=/output/logs. ```. ```{bash}. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2154,usability,user,user,2154,"atform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2201,usability,command,command,2201,"argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/post",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/435:2273,usability,input,input,2273,"runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 323, in call_variants. first_example = tf_utils.get_one_example_from_examples_path(examples_filename). File ""/tmp/Bazel.runfiles_7of_f3z_/runfiles/com_google_deepvariant/deepvariant/tf_utils.py"", line 205, in get_one_example_from_examples_path. 'Cannot find matching files with the pattern ""{}""'.format(source)). ValueError: Cannot find matching files with the pattern ""/tmp/tmpgv2oy1s_/make_examples.tfrecord@8.gz"". real	0m2.022s. user	0m2.036s. sys	0m0.413s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fa"" --infile ""/tmp/tmpgv2oy1s_/call_variants_output.tfrecord.gz"" --outfile ""/output/OUTPUT_VCF.vfc"" --nonvariant_site_tfrecord_path ""/tmp/tmpgv2oy1s_/gvcf.tfrecord@8.gz"" --gvcf_outfile ""/output/OUTPUT_GVCF.vfc"" ) 2>&1 | tee /output/logs/postprocess_variants.log. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1184, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_vdgo7zab/runfiles/com_google_deepvariant/deepvariant/postprocess_variants.py"", line 1107, in main. sample_name = get_sample_name",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/435
https://github.com/google/deepvariant/issues/436:124,availability,avail,available,124,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:185,availability,down,download,185,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:31,deployability,updat,update,31,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:176,deployability,releas,releases,176,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:198,deployability,version,version,198,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:232,deployability,updat,updated,232,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:298,deployability,updat,update,298,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:384,deployability,releas,release,384,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:64,energy efficiency,current,current,64,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:198,integrability,version,version,198,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:47,modifiability,pac,package,47,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:198,modifiability,version,version,198,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:124,reliability,availab,available,124,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:31,safety,updat,update,31,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:124,safety,avail,available,124,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:232,safety,updat,updated,232,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:298,safety,updat,update,298,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:31,security,updat,update,31,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:124,security,availab,available,124,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:232,security,updat,updated,232,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/436:298,security,updat,update,298,"Binaries for v1.1 necessary to update bioconda package; Hi! The current bioconda recipe requires precompiled binaries to be available at `https://github.com/google/deepvariant/releases/download/v{{ version }}/deepvariant.zip`. I've updated the bioconda recipe to work with v1.0.0, but for a smooth update to v1.1.0, it would be excellent if you could provide zipped binaries with the release. The bioconda recipe: https://github.com/bioconda/bioconda-recipes/tree/master/recipes/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/436
https://github.com/google/deepvariant/issues/437:295,availability,state,stated,295,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:528,availability,state,stated,528,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:295,integrability,state,stated,295,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:528,integrability,state,stated,528,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:18,modifiability,paramet,parameter,18,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:125,modifiability,paramet,parameter,125,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:207,modifiability,PAC,PACBIO,207,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:510,modifiability,PAC,PACBIO,510,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:652,modifiability,Pac,PacBio,652,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:738,modifiability,paramet,parameter,738,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:820,modifiability,paramet,parameter,820,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:913,performance,time,time,913,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:749,reliability,doe,does,749,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:780,reliability,doe,doesn,780,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:695,testability,understand,understanding,695,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/437:880,usability,clear,clear,880,"[no]realign_reads parameter for make_examples.py script; Hi,. I have a question regarding the use of the _**realign_reads**_ parameter for make_examples.py script. I am interested in running DeepVariant for PACBIO long reads data, and I don't want to realign reads before variant calling. It is stated in the official description: _--[no]realign_reads: If True, locally realign reads before calling variants. Reads longer than 500 bp are never realigned.(default: 'true')_, but, in the description for running PACBIO data it is stated that **_Please note, that if you create your own script make_examples must be called with --norealign_reads flag for PacBio long reads._**. I am having trouble understanding the meaning of realign reads parameter, does the TRUE value realign or doesn't realign reads (basically is the parameter NOrealign _reads, or realign reads)? Just want to clear things up so I don't waste time on long runs. Thank you in advance! :)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/437
https://github.com/google/deepvariant/issues/438:363,interoperability,specif,specific,363,"Can I make a pileup image for the locus I want? ( using ""make_examples""); Can I make a pileup image for the locus I want? ( using ""make_examples""). I am trying to create pileup images using the command ""make_examples"". By the way, ""make_example"" creates an image by selecting a location to create a pileup image from inside. But I want to create pileup images of specific locations I want, is there any way? I look forward to your reply.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/438
https://github.com/google/deepvariant/issues/438:194,usability,command,command,194,"Can I make a pileup image for the locus I want? ( using ""make_examples""); Can I make a pileup image for the locus I want? ( using ""make_examples""). I am trying to create pileup images using the command ""make_examples"". By the way, ""make_example"" creates an image by selecting a location to create a pileup image from inside. But I want to create pileup images of specific locations I want, is there any way? I look forward to your reply.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/438
https://github.com/google/deepvariant/pull/439:90,performance,time,time,90,"Add DeepTrio link from Google Open Source blog.; (We are not taking pull requests at this time.). This pull request is from a DeepVariant team member, to the gh-pages branch which is used for the DeepVariant blog.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/439
https://github.com/google/deepvariant/pull/439:138,security,team,team,138,"Add DeepTrio link from Google Open Source blog.; (We are not taking pull requests at this time.). This pull request is from a DeepVariant team member, to the gh-pages branch which is used for the DeepVariant blog.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/439
https://github.com/google/deepvariant/issues/440:811,availability,Operat,Operating,811,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:850,deployability,version,version,850,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:893,deployability,Instal,Installation,893,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:495,integrability,sub,subset,495,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:850,integrability,version,version,850,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:457,interoperability,distribut,distributions,457,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:850,modifiability,version,version,850,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:995,testability,instrument,instrument,995,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:67,usability,user,user-images,67,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/440:261,usability,guid,guidelines,261,"Question about QUAL in DeepTrio output; . ![DeepTrio_QUAL](https://user-images.githubusercontent.com/22089494/114759224-e5d49180-9d2b-11eb-9c5e-cb33c9979d2d.png). Hello, . I am running DeepTrio for a dataset with known true-positive SNPs and indels. I followed guidelines for DeepTrio but had to change --config DeepVariantWGS to DeepVariant_unfiltered at the glnexus_cli step as a default QUAL threshold of 10 removed a lot of my TP calls. I have compared distributions of QUAL score in the TP subset and all calls found by DeepTrio. Please see an attached histogram of all DeepTrio calls vs TP calls. Could you please tell me if it is expected that QUAL of TP calls is between 0 and30, while there are calls with QUAL of up to 100? If not, what I could do wrong? Thank you! Best regards,. Maria. **Setup**. - Operating system: Linux. - DeepVariant version: deepvariant_deeptrio-1.1.0.sif. - Installation method (Docker, built from source, etc.): singularity/3.6.4. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) HiSeq X Ten, hg38, WGS.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/440
https://github.com/google/deepvariant/issues/441:12,availability,error,error,12,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:361,availability,error,error,361,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:634,availability,ERROR,ERROR,634,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:795,availability,error,error,795,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4525,availability,error,error,4525,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4685,availability,error,error,4685,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4845,availability,error,error,4845,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:6,deployability,build,build,6,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:40,deployability,updat,update,40,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:201,deployability,build,build,201,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:687,deployability,BUILD,BUILD,687,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:766,deployability,fail,failed,766,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:787,deployability,fail,failed,787,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:557,energy efficiency,core,core,557,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:3264,integrability,pub,public,3264,"sycl -iquote external/gif -iquote bazel-out/k8-opt/bin/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:3316,integrability,pub,public,3316,"in/external/gif -iquote external/libjpeg_turbo -iquote bazel-out/k8-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/k8-opt/bin/external/com_google_protobuf -iquote external/zlib -iquote bazel-out/k8-opt/bin/external/zlib -iquote external/com_googlesource_code_re2 -iquote bazel-out/k8-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/k8-opt/bin/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/k8-opt/bin/external/fft2d -iquote external/highwayhash -iquote bazel-out/k8-opt/bin/external/highwayhash -iquote external/double_conversion -iquote bazel-out/k8-opt/bin/external/double_conversion -iquote external/snappy -iquote bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o b",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4406,interoperability,platform,platform,4406,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4451,interoperability,platform,platform,4451,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:5026,interoperability,specif,specific,5026,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:1136,modifiability,pac,packages,1136,"t a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/eigen_archive -iquote baz",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:1279,modifiability,paramet,parameter,1279," --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -iquote external/eigen_archive -iquote bazel-out/k8-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/k8-opt/bin/external/local_config_sycl -iquote exte",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:12,performance,error,error,12,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:361,performance,error,error,361,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:634,performance,ERROR,ERROR,634,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:795,performance,error,error,795,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:832,performance,cach,cache,832,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4525,performance,error,error,4525,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4685,performance,error,error,4685,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4845,performance,error,error,4845,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:766,reliability,fail,failed,766,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:787,reliability,fail,failed,787,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:12,safety,error,error,12,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:40,safety,updat,update,40,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:361,safety,error,error,361,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:634,safety,ERROR,ERROR,634,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:795,safety,error,error,795,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4525,safety,error,error,4525,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4685,safety,error,error,4685,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4845,safety,error,error,4845,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:40,security,updat,update,40,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4061,security,sign,sign-compare,4061,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:12,usability,error,error,12,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:361,usability,error,error,361,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:634,usability,ERROR,ERROR,634,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:795,usability,error,error,795,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:811,usability,command,command,811,"Bazel build error; Hi, I was working on update the deepvariant source code from ubuntu 16.04 to 18.04 and python 3.6 to python 3.8. Now I met a problem in build_release_binaries.shell scripts. . bazel build -c opt \. --output_filter=DONT_MATCH_ANYTHING \. --noshow_loading_progress \. --show_result=0 \. ${DV_COPT_FLAGS} \. --build_python_zip \. :binaries. The error is below:. [1,442 / 1,802] Compiling third_party/nucleus/protos/struct.pb.cc; 1s local ... (128 actions, 48 running). (17:42:57) [1,544 / 1,802] Compiling external/org_tensorflow/tensorflow/core/util/test_log.pb.cc; 6s local ... (128 actions, 47 running). (17:43:03) ERROR: /opt/deepvariant/deepvariant/realigner/python/BUILD:54:1: C++ compilation of rule '//deepvariant/realigner/python:ssw_cclib' failed (Exit 1): gcc failed: error executing command . (cd /root/.cache/bazel/_bazel_root/617054f44dc1f1e9b3fe3174f8eb2580/execroot/com_google_deepvariant && \. exec env - \. PATH=/root/bin:/root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \. PWD=/proc/self/cwd \. PYTHON_BIN_PATH=/usr/bin/python3.8 \. PYTHON_LIB_PATH=/usr/local/lib/python3.8/dist-packages \. TF2_BEHAVIOR=1 \. TF_CONFIGURE_IOS=0 \. TF_ENABLE_XLA=1 \. /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.d '-frandom-seed=bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o' -fPIC -DTF_USE_SNAPPY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -DHAVE_SYS_UIO_H -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/k8-opt/bin -iquote external/libssw -iquote bazel-out/k8-opt/bin/external/libssw -iquote external/org_tensorflow -iquote bazel-out/k8-opt/bin/external/org_tensorflow -iquote external/com_google_absl -iquote bazel-out/k8-op",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4525,usability,error,error,4525,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4685,usability,error,error,4685,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/issues/441:4845,usability,error,error,4845,"e bazel-out/k8-opt/bin/external/snappy -iquote external/clif -iquote bazel-out/k8-opt/bin/external/clif -iquote external/local_config_python -iquote bazel-out/k8-opt/bin/external/local_config_python -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -isystem external/eigen_archive -isystem bazel-out/k8-opt/bin/external/eigen_archive -isystem external/gif -isystem bazel-out/k8-opt/bin/external/gif -isystem external/com_google_protobuf/src -isystem bazel-out/k8-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/k8-opt/bin/external/zlib -isystem external/farmhash_archive/src -isystem bazel-out/k8-opt/bin/external/farmhash_archive/src -isystem external/double_conversion -isystem bazel-out/k8-opt/bin/external/double_conversion -isystem external/local_config_python/python_include -isystem bazel-out/k8-opt/bin/external/local_config_python/python_include -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-maybe-uninitialized -Wno-unused-function '-march=corei7' -Wno-sign-compare -Wno-write-strings '-std=c++14' '-std=c++11' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc -o bazel-out/k8-opt/bin/deepvariant/realigner/python/_objs/ssw_cclib/ssw.pic.o). Execution platform: @local_execution_config_platform//:platform. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:283:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:534:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. ^. bazel-out/k8-opt/bin/deepvariant/realigner/python/ssw.cc:815:1: error: cannot convert 'std::nullptr_t' to 'Py_ssize_t {aka long int}' in initialization. };. I knew that ""nullptr"" might be change to ""NULL"" in pyth3.8. But how should I change the specific files?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/441
https://github.com/google/deepvariant/pull/442:25,deployability,Instal,Install,25,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:52,deployability,Updat,Update,52,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:85,deployability,version,version,85,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:140,deployability,modul,module,140,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:85,integrability,version,version,85,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:85,modifiability,version,version,85,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:140,modifiability,modul,module,140,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:52,safety,Updat,Update,52,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:140,safety,modul,module,140,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:260,safety,test,test,260,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:52,security,Updat,Update,52,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/pull/442:260,testability,test,test,260,"Use OpenVINO from pip; * Install OpenVINO by pip. * Update OpenVINO to latest 2021.3 version. * Use `enum34==1.1.8` to fix ""AttributeError: module 'enum' has no attribute 'IntFlag'"" (https://github.com/python-poetry/poetry/issues/1122#issuecomment-628037127). test run: https://github.com/dkurt/deepvariant/actions/runs/755874669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/442
https://github.com/google/deepvariant/issues/443:228,availability,error,error,228,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1058,availability,echo,echo,1058,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:0,deployability,Build,Build,0,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:65,deployability,instal,install,65,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:120,deployability,build,build-prereq,120,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:293,deployability,build,build,293,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:568,deployability,build,build,568,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:765,deployability,Build,Build,765,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:720,energy efficiency,Current,Current,720,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:898,energy efficiency,load,loaded,898,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:917,integrability,configur,configured,917,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1079,integrability,messag,message,1079,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1105,integrability,messag,message,1105,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1079,interoperability,messag,message,1079,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1105,interoperability,messag,message,1105,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:889,modifiability,pac,packages,889,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:917,modifiability,configur,configured,917,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:228,performance,error,error,228,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:830,performance,cach,cache,830,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:898,performance,load,loaded,898,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:990,performance,time,time,990,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:228,safety,error,error,228,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:917,security,configur,configured,917,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:185,usability,stop,stopped,185,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:228,usability,error,error,228,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/443:1178,usability,help,help,1178,"Build from source Ubuntu 1.18.04 problem; Hello,. I am trying to install DeepVariant from source on Ubuntu 1.18.04. The build-prereq.sh script finished well,. but build_and_test.sh has stopped unexpectedly do not displaying any error:. ```. (18:54:51) INFO: Found applicable config definition build:linux in file /data1/SOFT/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels. (18:54:51) INFO: Found applicable config definition build:dynamic_kernels in file /data1/SOFT/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS. (18:54:51) INFO: Current date is 2021-04-16. (18:54:51) INFO: Build option --build_python_zip has changed, discarding analysis cache. (18:54:51) INFO: Analyzed target //:licenses_zip (0 packages loaded, 22 targets configured). (18:54:51) INFO: Found 1 target... (18:54:51) INFO: Elapsed time: 0.224s, Critical Path: 0.00s. (18:54:51) INFO: 0 processes. + echo 'Expect a usage message:'. Expect a usage message:. + python3 bazel-out/k8-opt/bin/deepvariant/call_variants.zip --help. + grep /call_variants.py:. /tmp/Bazel.runfiles_5qjtwbro/runfiles/com_google_deepvariant/deepvariant/call_variants.py:. + :. ```.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/443
https://github.com/google/deepvariant/issues/444:3,availability,error,error,3,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:79,availability,error,error,79,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:252,deployability,modul,module,252,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1698,deployability,modul,module,1698,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1389,energy efficiency,cpu,cpu,1389,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:548,integrability,sub,subprocess,548,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:641,integrability,sub,subprocess,641,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:722,integrability,sub,subprocess,722,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:807,integrability,buffer,buffer,807,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:252,modifiability,modul,module,252,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:312,modifiability,pac,packages,312,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:412,modifiability,pac,packages,412,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1453,modifiability,PAC,PACBIO,1453,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1698,modifiability,modul,module,1698,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:3,performance,error,error,3,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:79,performance,error,error,79,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:764,performance,time,time,764,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:779,performance,parallel,parallel,779,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1389,performance,cpu,cpu,1389,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:3,safety,error,error,3,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:43,safety,test,test,43,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:79,safety,error,error,79,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:252,safety,modul,module,252,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:924,safety,input,input,924,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1523,safety,input,input,1523,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1698,safety,modul,module,1698,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1283,security,sandbox,sandbox,1283,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:43,testability,test,test,43,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:154,testability,Trace,Traceback,154,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:3,usability,error,error,3,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:79,usability,error,error,79,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:570,usability,command,command,570,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:753,usability,Command,Command,753,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:924,usability,input,input,924,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1232,usability,statu,status,1232,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1300,usability,command,command,1300,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/444:1523,usability,input,input,1523,"An error; Hi there,. We ran deepvariant on test data, and we had the following error:. I0416 16:33:15.202579 46954465520640 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 3 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmpmxakjtgh/make_examples.tfrecord@4.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 2. We converted docker image to singularity sandbox. And our command is like this:. singularity exec -B /data -B /home -B /localhd/ \. ../deepvariant-cpu.sif \. /opt/deepvariant/bin/run_deepvariant \. --model_type PACBIO \. --ref reference/GRCh38_no_alt_analysis_set.fasta \. --reads input/HG003.GRCh38.chr20.pFDA_truthv2.bam \. --output_vcf deepvariant1/output.vcf.gz \. --num_shards ${nproc} \. --regions chr20. I am guessing we may have misconfigured some module. Any idea how to fix it? Thanks. George",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/444
https://github.com/google/deepvariant/issues/445:52,deployability,build,build,52,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:171,deployability,build,build,171,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:192,deployability,updat,updated,192,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:283,deployability,contain,container,283,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:371,deployability,contain,container,371,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:192,safety,updat,updated,192,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:192,security,updat,updated,192,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:5,usability,support,support,5,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/445:238,usability,guidanc,guidance,238,"ENH: support python3.7+; Hi, it's getting harder to build deepvariant, even using bioconda as everything it moving to python3.7 or higher. Would it be possible to get the build and Dockerfile updated to 3.7? And/or could you provide some guidance on what is needed? Using the docker container works perfectly. But I want to add bcftools and samtools (for example) to the container and also have it work on singularity. thanks,. -B.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/445
https://github.com/google/deepvariant/issues/446:13,availability,error,error,13,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:197,availability,Operat,Operating,197,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:801,availability,sli,slight,801,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1162,availability,Error,Error,1162,"ACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3998,availability,error,error,3998,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:154,deployability,fail,failed,154,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:282,deployability,version,version,282,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:303,deployability,Instal,Installation,303,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1214,deployability,fail,failed,1214,"google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1747,deployability,fail,failed,1747,"v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2477,deployability,modul,module,2477,"RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4004,deployability,log,log,4004,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4041,deployability,log,logging,4041,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:7,energy efficiency,model,model,7,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:224,energy efficiency,cloud,cloud,224,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:282,integrability,version,version,282,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:715,integrability,pub,public-data--broad-references,715,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1298,integrability,pub,public-data--broad-references,1298,"on method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1831,integrability,pub,public-data--broad-references,1831,"nk that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2773,integrability,sub,subprocess,2773,"ake_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2866,integrability,sub,subprocess,2866,"mo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tes",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2947,integrability,sub,subprocess,2947,"8fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any probl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3033,integrability,buffer,buffer,3033," /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3116,integrability,pub,public-data--broad-references,3116,"igned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:812,interoperability,mismatch,mismatch,812,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4073,interoperability,share,share,4073,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:0,modifiability,PAC,PACBIO,0,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:164,modifiability,PAC,PACBIO,164,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:282,modifiability,version,version,282,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:502,modifiability,Pac,Pacbio,502,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1027,modifiability,PAC,PACBIO,1027," checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --ex",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2477,modifiability,modul,module,2477,"RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2537,modifiability,pac,packages,2537,"eo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2637,modifiability,pac,packages,2637,"fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3879,modifiability,Pac,PacBio,3879,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:13,performance,error,error,13,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1162,performance,Error,Error,1162,"ACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1195,performance,parallel,parallel,1195,"erating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1728,performance,parallel,parallel,1728,"d-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2989,performance,time,time,2989,"7d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3005,performance,parallel,parallel,3005,"tag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3998,performance,error,error,3998,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:154,reliability,fail,failed,154,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:801,reliability,sli,slight,801,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1214,reliability,fail,failed,1214,"google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotyp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1747,reliability,fail,failed,1747,"v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3645,reliability,Doe,Does,3645,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:13,safety,error,error,13,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1162,safety,Error,Error,1162,"ACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2477,safety,modul,module,2477,"RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norea",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3666,safety,test,test,3666,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3702,safety,test,test,3702,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3868,safety,test,tested,3868,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3998,safety,error,error,3998,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4004,safety,log,log,4004,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4041,safety,log,logging,4041,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:7,security,model,model,7,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4004,security,log,log,4004,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4041,security,log,logging,4041,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:415,testability,instrument,instrument,415,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:537,testability,trace,trace,537,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1168,testability,trace,trace,1168,"data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2379,testability,Trace,Traceback,2379,"root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfre",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3666,testability,test,test,3666,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3702,testability,test,test,3702,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3868,testability,test,tested,3868,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3975,testability,context,context,3975,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4004,testability,log,log,4004,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4041,testability,log,logging,4041,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:13,usability,error,error,13,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:959,usability,Command,Command,959,"PACBIO model error; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. ```. Deepvariant failed on PACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whats",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:1162,usability,Error,Error,1162,"ACBIO data. . ```. **Setup**. - Operating system:. `google cloud through [Terra](https://terra.bio/)`. - DeepVariant version:. `1.1.0`. - Installation method (Docker, built from source, etc.):. `google/deepvariant:1.1.0`. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). ```. Pacbio bam from GIAB . https://ftp-trace.ncbi.nlm.nih.gov/ReferenceSamples/giab/data/NA12878/PacBio_SequelII_CCS_11kb/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam. reference from Broad GCP. gs://gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta. Though this is a slight ref mismatch, B37 vs hs37. I don't think that should cause that problem? The make_examples step finished successfully. ```. **Steps to reproduce:**. - Command:. ```. /opt/deepvariant/bin/run_deepvariant \. --model_type=PACBIO \. --ref=${REF_GENOME_FASTA} \. --reads=${input_read} \. --num_shards=${NUM_THREADS} \. --output_vcf=${basename}.vcf.gz. ```. - Error trace: (if applicable). ```parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2278,usability,user,user,2278,"cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 6. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2795,usability,command,command,2795,"alling --ref /cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta --reads /cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is th",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:2978,usability,Command,Command,2978,"pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam --examples /cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz --add_hp_channel --alt_aligned_pileup diff_channels --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3581,usability,statu,status,3581,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:3998,usability,error,error,3998,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/446:4098,usability,workflow,workflow,4098,"-norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels 0.12 --task 7. real 133m6.986s. user 230m53.643s. sys 1m59.690s. I0425 04:55:14.754644 140234455082752 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 19 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/cromwell_root/gcp-public-data--broad-references/hg19/v0/Homo_sapiens_assembly19.fasta"" --reads ""/cromwell_root/fc-13e1404e-623c-489f-956c-b388fa9fb975/bams/HG001.SequelII.pbmm2.hs37d5.whatshap.haplotag.RTG.trio.bam"" --examples ""/cromwell_root/tmp.e4eeba80/tmpphthddeo/make_examples.tfrecord@20.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --parse_sam_aux_fields --norealign_reads --sort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} )' returned non-zero exit status 247. 2021/04/25 04:55:23 Starting delocalization. ```. **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? `Yes. I tested the PacBio case study on chr20 on my system. It ran through without any problems`. **Any additional context:**. `The total error log is quite lengthy but mostly just logging make_examples.py. I can share with you the Terra workflow which you can reproduce. To do that, I probably need your email address. `.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/446
https://github.com/google/deepvariant/issues/448:0,deployability,build,build,0,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:52,deployability,contain,container,52,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:90,deployability,contain,container,90,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:113,deployability,build,build,113,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:157,deployability,build,build-prereq,157,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:212,safety,test,test,212,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:105,testability,plan,plan,105,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:212,testability,test,test,212,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/448:25,usability,interact,interactive,25,build from source; Run a interactive mode of docker container (different than deepvariant container) and plan to build the deepvariant from source:. run the build-prereq.sh and run build_and_test.sh. Then how to test deepvariant function?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/448
https://github.com/google/deepvariant/issues/449:88,safety,input,input,88,"Searching for the 6 channel code :); Hi,. I am searching for the code that converts the input files (BAM) to the 6 channels that you used in CNN. Can you help me out please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/449
https://github.com/google/deepvariant/issues/449:88,usability,input,input,88,"Searching for the 6 channel code :); Hi,. I am searching for the code that converts the input files (BAM) to the 6 channels that you used in CNN. Can you help me out please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/449
https://github.com/google/deepvariant/issues/449:154,usability,help,help,154,"Searching for the 6 channel code :); Hi,. I am searching for the code that converts the input files (BAM) to the 6 channels that you used in CNN. Can you help me out please?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/449
https://github.com/google/deepvariant/issues/450:20,availability,error,error,20,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:229,availability,avail,available,229,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:524,availability,error,error,524,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:780,availability,error,errors,780,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:20,performance,error,error,20,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:524,performance,error,error,524,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:780,performance,error,errors,780,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:229,reliability,availab,available,229,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:752,reliability,doe,does,752,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:20,safety,error,error,20,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:229,safety,avail,available,229,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:524,safety,error,error,524,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:780,safety,error,errors,780,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:229,security,availab,available,229,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:20,usability,error,error,20,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:524,usability,error,error,524,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:576,usability,visual,visually,576,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/450:780,usability,error,errors,780,"DeepTrio and type 2 error question; Well, this is not really a problem. It's rather a question. Someone asked about the de novo germline calling last year [#377](https://github.com/google/deepvariant/issues/377). Deeptrio is now available and I want to ask general question in regards with denovo variants in the child. . Background: the biggest issue with calling de novo variants (i.e. variants that are found in proband, generally as heterozygous, negative in parents) is there are ton's of false negative calls (Type II error) (i.e. variants not called in parents but are visually obvious in the alignment). . It seems to me that DeepTrio should address this issue particularly well but I am not sure if that is the motivation behind DeepTrio. How does DeepTrio handle type 2 errors for de novo germline variant calling? can this be added as an enhancement? Thank you.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/450
https://github.com/google/deepvariant/issues/451:181,interoperability,Specif,Specifically,181,"Using deepvariant/deeptrio on triobinned assemblies; Hi,. I've had great success with DV/DT so far, but ran into some difficult use cases when dealing with trio-binned individuals. Specifically, there is no straightforward way to bin the child short reads into haplotypes as there is for long reads. I would anticipate running DT using the full set of F1 hybrid short reads aligned to only one haplotype would introduce a bunch of ""false"" variants coming from the other haplotype's reads. I've seen whatshap says phasing is hard with short reads, so it probably isn't ideal to follow a similar approach to the PacBio haplotype phasing. However, I have come across a similar approach in a [different context](https://github.com/DecodeGenetics/Ratatosk/blob/master/phasing.md). . Do you have any suggestions or insights into how DV/DT might be used with short read data from a trio, but on a haplotype-resolved assembly as the reference? I considered merging the haplotypes into a diploid fasta, but then many reads would likely have multiple mappings as the haplotypes are not that heterozygous, which probably would hurt more than it would help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/451
https://github.com/google/deepvariant/issues/451:610,modifiability,Pac,PacBio,610,"Using deepvariant/deeptrio on triobinned assemblies; Hi,. I've had great success with DV/DT so far, but ran into some difficult use cases when dealing with trio-binned individuals. Specifically, there is no straightforward way to bin the child short reads into haplotypes as there is for long reads. I would anticipate running DT using the full set of F1 hybrid short reads aligned to only one haplotype would introduce a bunch of ""false"" variants coming from the other haplotype's reads. I've seen whatshap says phasing is hard with short reads, so it probably isn't ideal to follow a similar approach to the PacBio haplotype phasing. However, I have come across a similar approach in a [different context](https://github.com/DecodeGenetics/Ratatosk/blob/master/phasing.md). . Do you have any suggestions or insights into how DV/DT might be used with short read data from a trio, but on a haplotype-resolved assembly as the reference? I considered merging the haplotypes into a diploid fasta, but then many reads would likely have multiple mappings as the haplotypes are not that heterozygous, which probably would hurt more than it would help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/451
https://github.com/google/deepvariant/issues/451:727,modifiability,Deco,DecodeGenetics,727,"Using deepvariant/deeptrio on triobinned assemblies; Hi,. I've had great success with DV/DT so far, but ran into some difficult use cases when dealing with trio-binned individuals. Specifically, there is no straightforward way to bin the child short reads into haplotypes as there is for long reads. I would anticipate running DT using the full set of F1 hybrid short reads aligned to only one haplotype would introduce a bunch of ""false"" variants coming from the other haplotype's reads. I've seen whatshap says phasing is hard with short reads, so it probably isn't ideal to follow a similar approach to the PacBio haplotype phasing. However, I have come across a similar approach in a [different context](https://github.com/DecodeGenetics/Ratatosk/blob/master/phasing.md). . Do you have any suggestions or insights into how DV/DT might be used with short read data from a trio, but on a haplotype-resolved assembly as the reference? I considered merging the haplotypes into a diploid fasta, but then many reads would likely have multiple mappings as the haplotypes are not that heterozygous, which probably would hurt more than it would help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/451
https://github.com/google/deepvariant/issues/451:699,testability,context,context,699,"Using deepvariant/deeptrio on triobinned assemblies; Hi,. I've had great success with DV/DT so far, but ran into some difficult use cases when dealing with trio-binned individuals. Specifically, there is no straightforward way to bin the child short reads into haplotypes as there is for long reads. I would anticipate running DT using the full set of F1 hybrid short reads aligned to only one haplotype would introduce a bunch of ""false"" variants coming from the other haplotype's reads. I've seen whatshap says phasing is hard with short reads, so it probably isn't ideal to follow a similar approach to the PacBio haplotype phasing. However, I have come across a similar approach in a [different context](https://github.com/DecodeGenetics/Ratatosk/blob/master/phasing.md). . Do you have any suggestions or insights into how DV/DT might be used with short read data from a trio, but on a haplotype-resolved assembly as the reference? I considered merging the haplotypes into a diploid fasta, but then many reads would likely have multiple mappings as the haplotypes are not that heterozygous, which probably would hurt more than it would help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/451
https://github.com/google/deepvariant/issues/451:1140,usability,help,help,1140,"Using deepvariant/deeptrio on triobinned assemblies; Hi,. I've had great success with DV/DT so far, but ran into some difficult use cases when dealing with trio-binned individuals. Specifically, there is no straightforward way to bin the child short reads into haplotypes as there is for long reads. I would anticipate running DT using the full set of F1 hybrid short reads aligned to only one haplotype would introduce a bunch of ""false"" variants coming from the other haplotype's reads. I've seen whatshap says phasing is hard with short reads, so it probably isn't ideal to follow a similar approach to the PacBio haplotype phasing. However, I have come across a similar approach in a [different context](https://github.com/DecodeGenetics/Ratatosk/blob/master/phasing.md). . Do you have any suggestions or insights into how DV/DT might be used with short read data from a trio, but on a haplotype-resolved assembly as the reference? I considered merging the haplotypes into a diploid fasta, but then many reads would likely have multiple mappings as the haplotypes are not that heterozygous, which probably would hurt more than it would help.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/451
https://github.com/google/deepvariant/issues/452:9,availability,error,error,9,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:41,availability,error,error,41,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:637,availability,operat,operations,637,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:691,availability,operat,operations,691,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:930,availability,servic,service,930,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:938,availability,servic,service,938,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:958,availability,servic,service,958,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1119,availability,servic,service,1119,"on or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1127,availability,servic,service,1127,"vice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1389,availability,servic,service,1389,": [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1397,availability,servic,service,1397,"221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1417,availability,servic,service,1417,"16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1578,availability,servic,service,1578,"the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1586,availability,servic,service,1586,"owing CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:67,deployability,version,version,67,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:930,deployability,servic,service,930,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:938,deployability,servic,service,938,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:958,deployability,servic,service,958,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1119,deployability,servic,service,1119,"on or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1127,deployability,servic,service,1127,"vice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1184,deployability,Version,Version,1184,"9: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1389,deployability,servic,service,1389,": [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1397,deployability,servic,service,1397,"221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1417,deployability,servic,service,1417,"16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1578,deployability,servic,service,1578,"the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1586,deployability,servic,service,1586,"owing CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3328,deployability,Fail,Failed,3328,"fault/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3410,deployability,fail,failed,3410,"5-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3572,deployability,fail,failed,3572,"305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3768,deployability,modul,module,3768,"t/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4954,deployability,fail,failed,4954,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:0,energy efficiency,GPU,GPU,0,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:82,energy efficiency,gpu,gpu,82,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:451,energy efficiency,core,core,451,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:517,energy efficiency,optim,optimized,517,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:596,energy efficiency,CPU,CPU,596,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:800,energy efficiency,core,core,800,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:846,energy efficiency,CPU,CPU,846,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:850,energy efficiency,Frequenc,Frequency,850,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1719,energy efficiency,core,core,1719," with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1739,energy efficiency,gpu,gpu,1739,"e compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1874,energy efficiency,core,coreClock,1874,"1-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I ten",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1894,energy efficiency,core,coreCount,1894,"674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_execu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3030,energy efficiency,core,core,3030,"form/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3050,energy efficiency,gpu,gpu,3050,"der.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3089,energy efficiency,gpu,gpu,3089,"library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3293,energy efficiency,core,core,3293,"nsorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3404,energy efficiency,GPU,GPU,3404," 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3566,energy efficiency,GPU,GPU,3566,":52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4948,energy efficiency,GPU,GPU,4948,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:67,integrability,version,version,67,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:930,integrability,servic,service,930,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:938,integrability,servic,service,938,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:958,integrability,servic,service,958,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1119,integrability,servic,service,1119,"on or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1127,integrability,servic,service,1127,"vice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1184,integrability,Version,Version,1184,"9: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1389,integrability,servic,service,1389,": [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1397,integrability,servic,service,1397,"221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1417,integrability,servic,service,1417,"16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1578,integrability,servic,service,1578,"the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1586,integrability,servic,service,1586,"owing CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:220,interoperability,platform,platform,220,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:456,interoperability,platform,platform,456,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:805,interoperability,platform,platform,805,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:992,interoperability,platform,platform,992,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1250,interoperability,platform,platform,1250," Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcubla",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1451,interoperability,platform,platform,1451,"/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2028,interoperability,platform,platform,2028,"hat XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2175,interoperability,platform,platform,2175,"ault Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2320,interoperability,platform,platform,2320,"cuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2464,interoperability,platform,platform,2464,"is does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2609,interoperability,platform,platform,2609,"tor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is in",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2756,interoperability,platform,platform,2756,"6] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:2903,interoperability,platform,platform,2903," deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(mai",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3162,interoperability,platform,platform,3162,"executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3864,interoperability,platform,platform,3864,"1828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.pyth",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:67,modifiability,version,version,67,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:930,modifiability,servic,service,930,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:938,modifiability,servic,service,938,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:958,modifiability,servic,service,958,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1119,modifiability,servic,service,1119,"on or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1127,modifiability,servic,service,1127,"vice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1184,modifiability,Version,Version,1184,"9: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/defa",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1389,modifiability,servic,service,1389,": [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1397,modifiability,servic,service,1397,"221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1417,modifiability,servic,service,1417,"16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1578,modifiability,servic,service,1578,"the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1586,modifiability,servic,service,1586,"owing CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorfl",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3768,modifiability,modul,module,3768,"t/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3837,modifiability,pac,packages,3837,".10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_gr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4542,modifiability,pac,packages,4542,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4710,modifiability,pac,packages,4710,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:0,performance,GPU,GPU,0,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:9,performance,error,error,9,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:41,performance,error,error,41,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:82,performance,gpu,gpu,82,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:517,performance,optimiz,optimized,517,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:551,performance,Network,Network,551,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:596,performance,CPU,CPU,596,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:616,performance,perform,performance-critical,616,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:846,performance,CPU,CPU,846,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1739,performance,gpu,gpu,1739,"e compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3050,performance,gpu,gpu,3050,"der.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3089,performance,gpu,gpu,3089,"library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Baze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3404,performance,GPU,GPU,3404," 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3566,performance,GPU,GPU,3566,":52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4948,performance,GPU,GPU,4948,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1012,reliability,doe,does,1012,"; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/st",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:1471,reliability,doe,does,1471,"ure_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:56:52.195656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10. 2021-05-06 16:56:52.199014: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3328,reliability,Fail,Failed,3328,"fault/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. Fi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3410,reliability,fail,failed,3410,"5-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3572,reliability,fail,failed,3572,"305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4954,reliability,fail,failed,4954,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:9,safety,error,error,9,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:41,safety,error,error,41,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:379,safety,input,input,379,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3768,safety,modul,module,3768,"t/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in _",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:551,security,Network,Network,551,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3313,security,session,session,3313,"or/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAG",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3345,security,session,session,3345,"c:48] Successfully opened dynamic library libcufft.so.10. 2021-05-06 16:56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4473,security,Session,Session,4473,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4576,security,session,session,4576,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4619,security,Session,Session,4619,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4744,security,session,session,4744,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3620,testability,Trace,Traceback,3620,"/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Sessio",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:9,usability,error,error,9,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:41,usability,error,error,41,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:379,usability,input,input,379,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:616,usability,perform,performance-critical,616,"GPU mode error; Hi,. I got the following error: . I'm using Docker version 1.1.0. gpu NVIDIA GeForce RTX 3090. Any suggestion or advice? Thanks in advance. Amin. `2021-05-06 16:56:50.765879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. I0506 16:56:52.008759 140393620989696 call_variants.py:338] Shape of input examples: [100, 221, 6]. 2021-05-06 16:56:52.013998: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: AVX2 AVX512F FMA. To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-05-06 16:56:52.046181: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100000000 Hz. 2021-05-06 16:56:52.053674: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47507d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.053727: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version. 2021-05-06 16:56:52.058754: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1. 2021-05-06 16:56:52.188018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47b9240 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:. 2021-05-06 16:56:52.188089: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6. 2021-05-06 16:56:52.191811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: . pciBusID: 0000:20:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6. coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.70GiB deviceMemoryBandwidth: 871.81GiB/s. 2021-05-06 16:56:52.191885: I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3418,usability,Statu,Status,3418,"56:52.199715: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10. 2021-05-06 16:56:52.203305: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:3580,usability,Statu,Status,3580,"ensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10. 2021-05-06 16:56:52.205473: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10. 2021-05-06 16:56:52.211828: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7. 2021-05-06 16:56:52.216068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:4962,usability,Statu,Status,4962,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/452:5018,usability,user,user,5018,"/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0. 2021-05-06 16:56:52.216108: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1. 2021-05-06 16:58:21.551842: E tensorflow/core/common_runtime/session.cc:91] Failed to create session: Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. 2021-05-06 16:58:21.551943: E tensorflow/c/c_api.cc:2184] Internal: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/tmp/Bazel.runfiles_1q2x77gk/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 393, in call_variants. with tf.compat.v1.Session(config=config) as sess:. File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1586, in __init__. super(Session, self).__init__(target, graph, config=config). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 701, in __init__. self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts). tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: device kernel image is invalid. real	1m31.942s. user	1m31.967s. sys	0m8.062s. `",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/452
https://github.com/google/deepvariant/issues/453:729,availability,Operat,Operating,729,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1044,availability,Error,Error,1044,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:771,deployability,version,version,771,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:787,deployability,Instal,Installation,787,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:771,integrability,version,version,771,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:771,modifiability,version,version,771,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1044,performance,Error,Error,1044,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1026,reliability,Doe,Does,1026,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1044,safety,Error,Error,1044,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:878,testability,instrument,instrument,878,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1050,testability,trace,trace,1050,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1017,usability,Command,Command,1017,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/453:1044,usability,Error,Error,1044,"Clarification on variant call(s); **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. We found a back-to-back call of two SNPs that we cannot explain as the BAM file suggests a deletion. IGV screenshot: https://www.dropbox.com/s/c0wfelxc1cca14b/igv_snapshot.png?dl=0. Happy to provide a BAM file etc. But maybe this is easy enough to explain; I just cannot figure out why this comes out as:. TC and GC and not as TC and G/-. chr19 15174241 rs1044006 T C 66 . AC=1;AF=0.5;AN=2;AQ=66;DP=78 GT:AD:DP:GQ:PL:RNC 0/1:0,78:78:10:20,0,9:. chr19 15174242 chr19_15174242_G_C G C 53 . AC=1;AF=0.5;AN=2;AQ=53;DP=177 GT:AD:DP:GQ:PL:RNC 0/1:77,100:177:50:53,0,52:. **Setup**. - Operating system: Centos 7. - DeepVariant version: 1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?): Novaseq 6000, exomes, GRCh38. **Steps to reproduce:**. - Command: Does not apply. - Error trace: (if applicable).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/453
https://github.com/google/deepvariant/issues/454:346,availability,avail,available,346,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:404,deployability,releas,release,404,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:45,energy efficiency,model,model,45,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:183,energy efficiency,model,model,183,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:783,energy efficiency,model,model,783,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:819,energy efficiency,model,model,819,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:842,energy efficiency,predict,predict,842,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:1061,energy efficiency,predict,prediction,1061,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:190,interoperability,Specif,Specifically,190,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:1092,performance,time,time,1092,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:346,reliability,availab,available,346,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:346,safety,avail,available,346,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:842,safety,predict,predict,842,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:1061,safety,predict,prediction,1061,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:45,security,model,model,45,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:183,security,model,model,183,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:346,security,availab,available,346,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:783,security,model,model,783,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:819,security,model,model,819,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:372,testability,trace,trace,372,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/454:959,usability,custom,customized,959,"No class labeling output in variant calls by model trained with customized_classes_labeler; Hello, . I've been attempting to use the customized_classes_labeler to train a DeepVariant model. Specifically, I've been trying use the ""callsets"" field from the INFO field of a Genome In A Bottle VCF file. I've been working with NA12878, VCF/BED files available here: ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/. At first, I could not make training examples using this as that field is an integer, but by making a copy of the VCF where I changed that field to be a string, I was able to make examples (using the `--labeler algorithm`, `--customized_classes_labeler_info_field_name`, and `--customized_classes_labeler_classes_list` options) and train the model. However, when I use the best model from training to predict variants, this class label information is not included in the VCF file. Am I misinterpreting how to use this customized class labeling? Any suggestions on how to incorporate this field into training and variant prediction? Thank you for your time!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/454
https://github.com/google/deepvariant/issues/455:239,availability,Operat,Operating,239,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:828,availability,Error,Error,828,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:886,availability,operat,operation,886,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:908,availability,error,error,908,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2966,availability,error,error,2966,"un_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7322,availability,operat,operation,7322," third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). Fil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7344,availability,error,error,7344,"/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9379,availability,error,error,9379," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9554,availability,error,error,9554," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:218,deployability,fail,failed,218,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:282,deployability,version,version,282,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:299,deployability,Instal,Installation,299,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:896,deployability,fail,failed,896,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1511,deployability,Fail,Failed,1511," run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1757,deployability,modul,module,1757,"G002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2738,deployability,Fail,Failed,2738," line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2766,deployability,Fail,Failed,2766,".run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3243,deployability,contain,container,3243,"ine 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1000 1000 9.5G May 7 07:42 HG004.bam. -rw-rw-r-- 1 1000 1000 9.5G Apr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3335,deployability,VERSION,VERSION,3335,"egion). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1000 1000 9.5G May 7 07:42 HG004.bam. -rw-rw-r-- 1 1000 1000 9.5G Apr 30 08:49 HG004.bam.bak. -rw-rw-r-- 1 1000 1000 9.3M Apr 30 09:05 HG004_truth.bed. -rw-rw-r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7332,deployability,fail,failed,7332,"arty/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7947,deployability,Fail,Failed,7947,"2686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8193,deployability,modul,module,8193,".529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9151,deployability,Fail,Failed,9151," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9179,deployability,Fail,Failed,9179," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9695,deployability,version,version,9695," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:282,integrability,version,version,282,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3335,integrability,VERSION,VERSION,3335,"egion). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1000 1000 9.5G May 7 07:42 HG004.bam. -rw-rw-r-- 1 1000 1000 9.5G Apr 30 08:49 HG004.bam.bak. -rw-rw-r-- 1 1000 1000 9.3M Apr 30 09:05 HG004_truth.bed. -rw-rw-r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9695,integrability,version,version,9695," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:282,modifiability,version,version,282,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1104,modifiability,exten,extend,1104,"sh.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1757,modifiability,modul,module,1757,"G002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3335,modifiability,VERSION,VERSION,3335,"egion). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1000 1000 9.5G May 7 07:42 HG004.bam. -rw-rw-r-- 1 1000 1000 9.5G Apr 30 08:49 HG004.bam.bak. -rw-rw-r-- 1 1000 1000 9.3M Apr 30 09:05 HG004_truth.bed. -rw-rw-r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6240,modifiability,deco,decode,6240,"d] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7540,modifiability,exten,extend,7540,"3] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8193,modifiability,modul,module,8193,".529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9695,modifiability,version,version,9695," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:828,performance,Error,Error,828,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:908,performance,error,error,908,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2966,performance,error,error,2966,"un_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7139,performance,Overhead,Overhead,7139,"om v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvari",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7344,performance,error,error,7344,"/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9379,performance,error,error,9379," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9554,performance,error,error,9554," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:21,reliability,pra,practices,21,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:158,reliability,pra,practices,158,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:218,reliability,fail,failed,218,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:896,reliability,fail,failed,896,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1511,reliability,Fail,Failed,1511," run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2738,reliability,Fail,Failed,2738," line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2766,reliability,Fail,Failed,2766,".run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3100,reliability,Doe,Does,3100," 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7332,reliability,fail,failed,7332,"arty/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7947,reliability,Fail,Failed,7947,"2686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). F",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9151,reliability,Fail,Failed,9151," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9179,reliability,Fail,Failed,9179," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:828,safety,Error,Error,828,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:908,safety,error,error,908,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1568,safety,except,exception,1568,"variant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/ru",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1587,safety,except,exception,1587,"pvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_d",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1757,safety,modul,module,1757,"G002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM re",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2966,safety,error,error,2966,"un_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3121,safety,test,test,3121,"examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5272,safety,input,input,5272,"w-rw-r-- 1 1000 1000 9.3M Apr 30 09:05 HG004_truth.bed. -rw-rw-r-- 1 1000 1000 132M Apr 30 09:05 HG004_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:05 HG004_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 4.6M Apr 30 08:59 agilent_sureselect_human_all_exon_v5_b37_targets.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5490,safety,input,inputs,5490,"8:59 agilent_sureselect_human_all_exon_v5_b37_targets.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5542,safety,input,input,5542,"s.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6215,safety,input,input,6215,"--task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 14043268611046",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6455,safety,input,input,6455,"es.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6636,safety,input,input,6636,"g /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7162,safety,input,inputs,7162,"or_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7344,safety,error,error,7344,"/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8004,safety,except,exception,8004,"cords to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepv",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8023,safety,except,exception,8023,"h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8193,safety,modul,module,8193,".529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse B",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9379,safety,error,error,9379," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9554,safety,error,error,9554," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9690,safety,test,test,9690," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9730,safety,except,exception,9730," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1505,security,loss,loss,1505," docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2732,security,loss,loss,2732,"es.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7941,security,loss,loss,7941,"5 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(reg",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9145,security,loss,loss,9145," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:390,testability,instrument,instrument,390,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:834,testability,trace,trace,834,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:936,testability,Trace,Traceback,936,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:1608,testability,Trace,Traceback,1608,"=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3121,testability,test,test,3121,"examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3176,testability,context,context,3176,"xbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7372,testability,Trace,Traceback,7372," HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:8044,testability,Trace,Traceback,8044,"00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", li",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9690,testability,test,test,9690," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:499,usability,Command,Command,499,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:828,usability,Error,Error,828,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:908,usability,error,error,908,"Run demo inside Best practices for multi-sample variant calling with DeepVariant and it report bam file crash.; **Describe the issue:**. run demo inside Best practices for multi-sample variant calling with DeepVariant failed. **Setup**. - Operating system: centos 7,. - DeepVariant version:1.1.0. - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command: docker run -v ""${DIR}"":""/data"" google/deepvariant:1.1.0 /opt/deepvariant/bin/run_deepvariant --model_type=WES --ref=""/data/hs37d5.fa"" --reads=""/data/HG002.bam"" --regions=""/data/agilent_sureselect_human_all_exon_v5_b37_targets.bed"" --output_vcf=""/data/HG002.vcf.gz"" --output_gvcf=""/data/HG002.gvcf.gz"" --num_shards=25. - Error trace: (if applicable): . [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1529, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2136, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 300, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/absl_py/absl/app.py"", line 251, in _run_main. sys.exit(main(argv)). ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:2966,usability,error,error,2966,"un_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2126, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:3212,usability,command,command,3212,"deepvariant/make_examples.py"", line 2003, in make_examples_runner. candidates, examples, gvcfs = region_processor.process(region). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1472, in process. self.in_memory_sam_reader.replace_reads(self.region_reads(region)). File ""/tmp/Bazel.runfiles_n9h1txbv/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1534, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. **Does the quick start test work on your system?**. it work. **Any additional context:**. I also run the mistaken command directly inside docker container, . [gosadmin@node3 trio]$ docker run -it -v ""${DIR}"":""/data"" google/deepvariant:${VERSION} /bin/bash. root@d2911291b750:/data# ls -alh. total 42G. drwxrwxr-x 2 1000 1000 4.0K May 8 03:39 . drwxr-xr-x 1 root root 29 May 8 08:21 .. -rw-rw-r-- 1 1000 1000 6.9M Apr 30 08:19 HG002.bai. -rw-rw-r-- 1 1000 1000 9.7G Apr 30 08:19 HG002.bam. -rw-rw-r-- 1 1000 1000 9.6M Apr 30 09:01 HG002_truth.bed. -rw-rw-r-- 1 1000 1000 147M Apr 30 09:00 HG002_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:00 HG002_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 6.8M Apr 30 08:33 HG003.bai. -rw-rw-r-- 1 1000 1000 8.4G Apr 30 08:33 HG003.bam. -rw-rw-r-- 1 1000 1000 9.2M Apr 30 09:03 HG003_truth.bed. -rw-rw-r-- 1 1000 1000 129M Apr 30 09:02 HG003_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:02 HG003_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 7.0M May 7 07:42 HG004.bai. -rw-rw-r-- 1 1000 1000 7.0M Apr 30 08:50 HG004.bai.bak. -rw-rw-r-- 1 1000 1000 9.5G May 7 07:42 HG004.bam.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5272,usability,input,input,5272,"w-rw-r-- 1 1000 1000 9.3M Apr 30 09:05 HG004_truth.bed. -rw-rw-r-- 1 1000 1000 132M Apr 30 09:05 HG004_truth.vcf.gz. -rw-rw-r-- 1 1000 1000 1.5M Apr 30 09:05 HG004_truth.vcf.gz.tbi. -rw-rw-r-- 1 1000 1000 4.6M Apr 30 08:59 agilent_sureselect_human_all_exon_v5_b37_targets.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5490,usability,input,inputs,5490,"8:59 agilent_sureselect_human_all_exon_v5_b37_targets.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:5542,usability,input,input,5542,"s.bed. -rw-r--r-- 1 root root 25K May 7 09:40 gvcf.tfrecord-00000-of-00030.gz. -rw-rw-r-- 1 1000 1000 3.0G Apr 30 08:54 hs37d5.fa. -rw-rw-r-- 1 1000 1000 2.8K Apr 30 08:58 hs37d5.fa.fai. -rw-rw-r-- 1 1000 1000 852M May 7 08:11 hs37d5.fa.gz. -rw-r--r-- 1 root root 1.2M May 7 09:40 make_examples.tfrecord-00000-of-00030.gz. root@a8d04f73bc21:/opt/deepvariant/bin# mkdir /tmp/tmpd7h_gv7l. root@a8d04f73bc21:/opt/deepvariant/bin# ./make_examples --mode calling --ref /data/hs37d5.fa --reads /data/HG002.bam --examples /tmp/tmpd7h_gv7l/make_examples.tfrecord@25.gz --gvcf /tmp/tmpd7h_gv7l/gvcf.tfrecord@25.gz -regions /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed --task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223]",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6215,usability,input,input,6215,"--task 8. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.928799 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:12.947474 140432686110464 make_examples.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 14043268611046",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6455,usability,input,input,6455,"es.py:648] Task 8/25: Preparing inputs. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:35:12.988700 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_go",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:6636,usability,input,input,6636,"g /data/HG002.bam with NativeSamReader. I0508 07:35:13.011471 140432686110464 make_examples.py:648] Task 8/25: Common contigs are ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', 'X', 'Y', 'MT']. I0508 07:35:13.020151 140432686110464 genomics_reader.py:223] Reading /data/agilent_sureselect_human_all_exon_v5_b37_targets.bed with NativeBedReader. I0508 07:36:27.125286 140432686110464 make_examples.py:648] Task 8/25: Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvarian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7162,usability,input,inputs,7162,"or_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-08 07:36:27.125969: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_e",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:7344,usability,error,error,7344,"/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.267024 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. [W::bam_hdr_read] EOF marker is absent. The input is probably truncated. I0508 07:36:27.306630 140432686110464 genomics_reader.py:223] Reading /data/HG002.bam with NativeSamReader. I0508 07:36:27.465119 140432686110464 make_examples.py:648] Task 8/25: Writing examples to /tmp/tmpd7h_gv7l/make_examples.tfrecord-00008-of-00025.gz. I0508 07:36:27.465305 140432686110464 make_examples.py:648] Task 8/25: Writing gvcf records to /tmp/tmpd7h_gv7l/gvcf.tfrecord-00008-of-00025.gz. I0508 07:36:27.465700 140432686110464 make_examples.py:648] Task 8/25: Overhead for preparing inputs: 74 seconds. I0508 07:36:27.529915 140432686110464 make_examples.py:648] Task 8/25: 0 candidates (0 examples) [0.06s elapsed]. [E::bgzf_read] Read block operation failed with error 2 after 0 of 4 bytes. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1611, in region_reads. reads.extend(sam_reader.query(region)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 82, in __next__. record, not_done = self._raw_next(). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9379,usability,error,error,9379," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/455:9554,usability,error,error,9554," File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/third_party/nucleus/io/clif_postproc.py"", line 141, in _raw_next. not_done = self._cc_iterable.PythonNext(record). ValueError: Data loss: Failed to parse SAM record. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2246, in <module>. app.run(main). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2236, in main. make_examples_runner(options). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 2106, in make_examples_runner. candidates, examples, gvcfs, runtimes = region_processor.process(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1540, in process. reads = self.region_reads(region). File ""/tmp/Bazel.runfiles_y3fqbfu4/runfiles/com_google_deepvariant/deepvariant/make_examples.py"", line 1616, in region_reads. error_message + '\nFailed to parse BAM/CRAM file. '. ValueError: Data loss: Failed to parse SAM record. Failed to parse BAM/CRAM file. This is often caused by:. (1) When using a CRAM file, and setting --use_ref_for_cram to false (which means you want to use the embedded ref instead of a ref file), this error could be because of inability to find the embedded ref file. (2) Your BAM/CRAM file could be corrupted. Please check its md5. If you cannot find out the reason why this error is occurring, please report to https://github.com/google/deepvariant/issues. root@a8d04f73bc21:/opt/deepvariant/bin# exit. i also test version 1.0.0, it also return same exception .",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/455
https://github.com/google/deepvariant/issues/456:150,availability,avail,available,150,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:107,deployability,API,API,107,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:21,energy efficiency,model,model,21,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:107,integrability,API,API,107,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:107,interoperability,API,API,107,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:150,reliability,availab,available,150,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:150,safety,avail,available,150,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:0,security,Access,Accessing,0,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:21,security,model,model,21,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/456:150,security,availab,available,150,"Accessing tensorflow model defintion; Would like to train from basic tensorflow, without dockers and other API's. Is the TensorFlow code for training available?",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/456
https://github.com/google/deepvariant/issues/457:157,availability,error,error,157,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:316,availability,error,error,316,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4554,availability,checkpoint,checkpoint,4554,"140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4750,deployability,contain,contain,4750,"7-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4571,energy efficiency,model,models,4571," genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4585,energy efficiency,model,model,4585,"er.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1013,integrability,event,eventhough,1013,"ds conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 |",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2047,integrability,buffer,buffer,2047,"ried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /i",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:21,interoperability,conflict,conflict,21,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:970,interoperability,conflict,conflict,970,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1248,interoperability,conflict,conflicts,1248," from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:261,modifiability,pac,pacbio,261,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:662,modifiability,PAC,PACBIO,662,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1346,modifiability,PAC,PACBIO,1346,"y records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_hap",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1847,modifiability,interm,intermediate,1847,"_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1895,modifiability,Interm,Intermediate,1895,". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3366,modifiability,deco,decode,3366,"action_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Runnin",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4578,modifiability,pac,pacbio,4578,"cs_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:157,performance,error,error,157,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:316,performance,error,error,316,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2004,performance,time,time,2004," flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2019,performance,parallel,parallel,2019," I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4000,performance,Overhead,Overhead,4000,"09179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4392,performance,time,time,4392,"nce you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Wr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4851,performance,time,time,4851,"py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 139970945300224 genomics_reader.py:223] Reading /output/output.vc",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1637,reliability,doe,does,1637,"epvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --pars",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4554,reliability,checkpoint,checkpoint,4554,"140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 13",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:157,safety,error,error,157,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:316,safety,error,error,316,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:525,safety,input,input,525,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:676,safety,input,input,676,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:701,safety,input,input,701,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2112,safety,input,input,2112,"aplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2139,safety,input,input,2139,"ux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 1404091794",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2474,safety,input,input,2474,"aplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2970,safety,input,inputs,2970,"* Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 14040917944",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3049,safety,input,input,3049,"r /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3341,safety,input,input,3341,"y_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3608,safety,input,input,3608,"hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3740,safety,input,input,3740,"zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4023,safety,input,inputs,4023,"eader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4906,safety,input,input,4906,"es.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 139970945300224 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real 0m2.472s. user 0m2.962s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4571,security,model,models,4571," genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 g",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4585,security,model,model,4585,"er.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:157,usability,error,error,157,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:316,usability,error,error,316,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:464,usability,command,command,464,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:525,usability,input,input,525,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:676,usability,input,input,676,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:701,usability,input,input,701,"parse_sam_aux_fields conflict ValueError; Dear developers! I am very curious to use DeepVariant on our in house data. In trying to do so, I stumbled upon an error I cannot seem to circumvent. . **Problem:**. I am trying to run my bamfile that originated from a pacbio LAA output, mapped with minimap2. I receive the error that it's unable to read any records. As I got the warGning (lol!) that --'add_hp_channel' is set but not 'parse_sam_aux_fields'. . **Initial command:**. sudo docker run -v ""2021-05-11_deepvariant_PB"":""/input/"" -v ""2021-05-11_deepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1545,usability,command,command,1545,"eepvariant_PB/output_DV"":""/output/"" google/deepvariant:""1.1.0"" /opt/deepvariant/bin/run_deepvariant --model_type=PACBIO --ref=/input/ref.fasta --reads=/input/R9_Z-1707-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1713,usability,Tool,Tool,1713,"7-003_cluster1_RC492.bam --output_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. T",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1741,usability,command,command,1741,"put_vcf=/output/output.vcf.gz. **What I tried:**. I tried to rerun with the following extra argument: --make_examples_extra_args=""parse_sam_aux_fields=true"". This gives me the ValueError from run_deepvariant.py that it is in conflict with the sort_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be ze",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:1987,usability,command,command,1987,"t_by_haplotypes flag, eventhough I didn't use it. Then, I tried to add both arguments: --make_examples_extra_args=""sort_by_haplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2112,usability,input,input,2112,"aplotypes=false,parse_sam_aux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2139,usability,input,input,2139,"ux_fields=true"", but this gives the same ValueError. . `ValueError: The extra_args ""parse_sam_aux_fields"" conflicts with other flags. Please fix and try again. Starting in v1.1.0, if you are running with PACBIO and want to use HP tags, please use the new --use_hp_information flag instead of using --make_examples_extra_args=""sort_by_haplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 1404091794",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2474,usability,input,input,2474,"aplotypes=true,parse_sam_aux_fields=true""`. I also tried to run the command with --sample_name=Z-1707-003_cluster1_RC492_phase0 (the RG for the bamfile), which does not give the warning anymore, but still leaves me with an empty vcf. **Tool stderr for the initial command:**. ```. I0511 12:24:29.658635 140614860437248 run_deepvariant.py:317] Re-using the directory for intermediate results in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2860,usability,stop,stop,2860,"sults in /tmp/tmpq5tvks3j. ***** Intermediate results will be written to /tmp/tmpq5tvks3j in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] W",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:2970,usability,input,inputs,2970,"* Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 14040917944",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3049,usability,input,input,3049,"r /opt/deepvariant/bin/make_examples --mode calling --ref ""/input/ref.fasta"" --reads ""/input/R9_Z-1707-003_cluster1_RC492.bam"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --norealign_reads --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3341,usability,input,input,3341,"y_haplotypes --vsc_min_fraction_indels ""0.12"" --task {} ). I0511 12:24:31.945842 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. W0511 12:24:31.946794 140409179444992 make_examples.py:589] WARGNING! --add_hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3608,usability,input,input,3608,"hp_channel is set but --parse_sam_aux_fields is not set. This will cause aux fields to not be read in. The relevant values might be zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:3740,usability,input,input,3740,"zero. For example, for --add_hp_channel, resulting in an empty. HP channel. If this is not what you intended, please stop and enable --parse_sam_aux_fields. I0511 12:24:32.430390 140409179444992 make_examples.py:648] Preparing inputs. I0511 12:24:32.438421 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4023,usability,input,inputs,4023,"eader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.440476 140409179444992 make_examples.py:648] Common contigs are ['T86']. I0511 12:24:32.442919 140409179444992 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4328,usability,user,user,4328,"using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4375,usability,command,command,4375,"sing the reference you passed in with --ref. 2021-05-11 12:24:32.443393: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. I0511 12:24:32.447968 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.453339 140409179444992 genomics_reader.py:223] Reading /input/R9_Z-1707-003_cluster1_RC492.bam with NativeSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_varia",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4787,usability,user,user,4787,"eSamReader. I0511 12:24:32.579413 140409179444992 make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 1",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4834,usability,command,command,4834," make_examples.py:648] Writing examples to /tmp/tmpq5tvks3j/make_examples.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 139970945300224 genomics_reader.py:223] Reading /o",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:4906,usability,input,input,4906,"es.tfrecord-00000-of-00001.gz. I0511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 139970945300224 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real 0m2.472s. user 0m2.962s.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/457:5895,usability,user,user,5895,"511 12:24:32.579596 140409179444992 make_examples.py:648] Overhead for preparing inputs: 0 seconds. I0511 12:24:32.587054 140409179444992 make_examples.py:648] 0 candidates (0 examples) [0.01s elapsed]. I0511 12:24:32.591045 140409179444992 make_examples.py:648] Found 0 candidate variants. I0511 12:24:32.591111 140409179444992 make_examples.py:648] Created 0 examples. real 0m3.165s. user 0m3.133s. sys 0m1.450s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --examples ""/tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/pacbio/model.ckpt"" ). W0511 12:24:34.935784 140411820246784 call_variants.py:327] Unable to read any records from /tmp/tmpq5tvks3j/make_examples.tfrecord@1.gz. Output will contain zero records. real 0m2.355s. user 0m2.789s. sys 0m1.594s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/input/ref.fasta"" --infile ""/tmp/tmpq5tvks3j/call_variants_output.tfrecord.gz"" --outfile ""/output/output.vcf.gz"" ). I0511 12:24:37.234371 139970945300224 postprocess_variants.py:1083] Could not determine sample name and --sample_name is unset. Using the default sample name. Sample name: default. I0511 12:24:37.235468 139970945300224 postprocess_variants.py:1111] call_variants_output is empty. Writing out empty VCF. I0511 12:24:37.235656 139970945300224 postprocess_variants.py:1139] Writing variants to VCF. I0511 12:24:37.235709 139970945300224 postprocess_variants.py:723] Writing output to VCF file: /output/output.vcf.gz. I0511 12:24:37.236480 139970945300224 genomics_writer.py:176] Writing /output/output.vcf.gz with NativeVcfWriter. I0511 12:24:37.237797 139970945300224 postprocess_variants.py:1147] VCF creation took 3.563165664672851e-05 minutes. I0511 12:24:37.239083 139970945300224 genomics_reader.py:223] Reading /output/output.vcf.gz with NativeVcfReader. real 0m2.472s. user 0m2.962s. sys 0m1.380. ```. Thanks a lot!!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/457
https://github.com/google/deepvariant/issues/458:136,availability,error,error,136,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1794,availability,checkpoint,checkpoint,1794,"06e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1827,availability,checkpoint,checkpoint,1827,"-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2646,availability,checkpoint,checkpoint,2646,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:536,deployability,modul,module,536,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1955,deployability,LOG,LOGDIR,1955,". File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1979,deployability,log,logs,1979,"kspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2000,deployability,LOG,LOGDIR,2000,"4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2088,deployability,LOG,LOGDIR,2088,"l.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2096,deployability,log,log,2096,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2110,deployability,LOG,LOGDIR,2110,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2493,deployability,log,log,2493,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2739,deployability,log,log,2739,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2977,deployability,log,log,2977,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:20,energy efficiency,model,model,20,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:112,energy efficiency,model,model,112,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2662,energy efficiency,model,models,2662,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2676,energy efficiency,model,model,2676,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:3019,energy efficiency,model,model,3019,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:632,interoperability,platform,platform,632,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:13,modifiability,PAC,PACBIO,13,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:71,modifiability,PAC,PACBIO,71,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:105,modifiability,PAC,PACBIO,105,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:536,modifiability,modul,module,536,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:605,modifiability,pac,packages,605,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2669,modifiability,pac,pacbio,2669,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:136,performance,error,error,136,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2023,performance,time,time,2023,"/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2052,performance,parallel,parallel,2052,"b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do y",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1794,reliability,checkpoint,checkpoint,1794,"06e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_varian",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1827,reliability,checkpoint,checkpoint,1827,"-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2646,reliability,checkpoint,checkpoint,2646,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:43,safety,test,tested,43,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:136,safety,error,error,136,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:241,safety,input,input,241,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:536,safety,modul,module,536,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1955,safety,LOG,LOGDIR,1955,". File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1979,safety,log,logs,1979,"kspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2000,safety,LOG,LOGDIR,2000,"4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2088,safety,LOG,LOGDIR,2088,"l.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2096,safety,log,log,2096,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2110,safety,LOG,LOGDIR,2110,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2493,safety,log,log,2493,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2739,safety,log,log,2739,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2977,safety,log,log,2977,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:3069,safety,input,input,3069,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:20,security,model,model,20,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:112,security,model,model,112,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1955,security,LOG,LOGDIR,1955,". File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1979,security,log,logs,1979,"kspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2000,security,LOG,LOGDIR,2000,"4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2088,security,LOG,LOGDIR,2088,"l.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2096,security,log,log,2096,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2110,security,LOG,LOGDIR,2110,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2493,security,log,log,2493,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2662,security,model,models,2662,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2676,security,model,model,2676,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2739,security,log,log,2739,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2977,security,log,log,2977,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:3019,security,model,model,3019,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:43,testability,test,tested,43,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:272,testability,Trace,Traceback,272,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1955,testability,LOG,LOGDIR,1955,". File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./po",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1979,testability,log,logs,1979,"kspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2000,testability,LOG,LOGDIR,2000,"4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2088,testability,LOG,LOGDIR,2088,"l.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2096,testability,log,log,2096,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2110,testability,LOG,LOGDIR,2110,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2493,testability,log,log,2493,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2739,testability,log,log,2739,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:2977,testability,log,log,2977,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:136,usability,error,error,136,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:241,usability,input,input,241,"Problem with PACBIO model; Hi everyone,. I tested DeepVariant 1.1.0 on PACBIO data (HG002, chr20), using PACBIO model and got following error in call_variants.py script:. `I0519 14:15:32.843033 139847781275392 call_variants.py:338] Shape of input examples: [100, 221, 8]. Traceback (most recent call last):. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 502, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:1887,usability,command,command,1887,"files/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infil",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/458:3069,usability,input,input,3069,"les_o79jsi96/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 492, in main. use_tpu=FLAGS.use_tpu,. File ""/sbgenomics/workspaces/aa109ba2-5d46-4def-a398-4a7e1ee8806e/tasks/2555e949-a7d7-40a9-9a24-b002adf182c2/deepvariant-1-0-0/Bazel.runfiles_o79jsi96/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 351, in call_variants. num_channels_in_checkpoint_model, example_shape[2])). **ValueError: The number of channels in examples and checkpoint should match, but the checkpoint has 9 channels while the examples have 8.**`. My command line looks like this:. `export HOME=/root && N_SHARDS=32 && LOGDIR=/opt/deepvariant/logs/ && mkdir -p ""${LOGDIR}"" && ( /usr/bin/time seq 0 $((N_SHARDS-1)) | parallel --eta --halt 2 --joblog ""${LOGDIR}/log"" --res ""${LOGDIR}"" python /opt/deepvariant/bin/make_examples.zip --mode calling --task {} --examples ""./examples.tfrecord@${N_SHARDS}.gz"" --alt_aligned_pileup diff_channels --reads /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/HG002.merged.bam --ref Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --norealign_reads --regions 20 --sample_name HG002 ) > ./make_examples.log 2>&1 && ( python /opt/deepvariant/bin/call_variants.zip --outfile ./call_variants_output.tfrecord.gz --examples ./examples.tfrecord@${N_SHARDS}.gz --checkpoint /opt/models/pacbio/model.ckpt --use_openvino --num_readers 32 ) > ./call_variants.log 2>&1 && ( python /opt/deepvariant/bin/postprocess_variants.zip --ref /Projects/aa109ba2-5d46-4def-a398-4a7e1ee8806e/GRCh38ERCC.ensembl.fasta --infile ./call_variants_output.tfrecord.gz --outfile ./HG002.vcf ) > ./postprocess_variants.log 2>&1`. When I try and run with HYBRID model, everything goes smoothly. Do you have some input on this? Thanks,. Ajsa.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/458
https://github.com/google/deepvariant/issues/459:220,availability,Operat,Operating,220,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:470,availability,Error,Error,470,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:253,deployability,version,version,253,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:265,deployability,Instal,Installation,265,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:16,energy efficiency,model,model,16,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:253,integrability,version,version,253,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:253,modifiability,version,version,253,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:470,performance,Error,Error,470,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:502,reliability,Doe,Does,502,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:470,safety,Error,Error,470,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:523,safety,test,test,523,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:559,safety,test,test,559,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:16,security,model,model,16,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:349,testability,instrument,instrument,349,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:476,testability,trace,trace,476,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:523,testability,test,test,523,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:559,testability,test,test,559,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:734,testability,context,context,734,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:153,usability,clear,clear,153,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:458,usability,Command,Command,458,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/459:470,usability,Error,Error,470,"Training on non-model organisms; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. **Describe the issue:**. (A clear and concise description of what the issue is.). **Setup**. - Operating system:. - DeepVariant version:. - Installation method (Docker, built from source, etc.):. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?). **Steps to reproduce:**. - Command:. - Error trace: (if applicable). **Does the quick start test work on your system?**. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/459
https://github.com/google/deepvariant/issues/460:20,availability,slo,slow,20,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/issues/460:467,availability,slo,slower,467,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/issues/460:1215,deployability,contain,containing,1215,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/issues/460:20,reliability,slo,slow,20,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/issues/460:467,reliability,slo,slower,467,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/issues/460:1039,usability,experien,experienced,1039,"deepvariant is very slow on alignements produced by hisat2 and reports only half of expected SNPs/INDELs; Hi, is there any recommendation regarding short-read aligner that works the best with deepvariant? I have looked into your tutorials, but they always start from BAM files... . I aligned HG002 (Illumina, 30x) using hisat2, bwa-mem2 and snap-aligner. Initially I've looked at 3 Mb (chr20:10,000,000-13,000,000). . To my big surprise deepvariant was running ~100x slower on BAM file produced by hisat2 (duplicates were marked using `samtools markdup`) compared to the BAM produced by either bwa-mem2 or snap-aligner. And it reported only ~half of expected SNPs/INDELs from hisat2 alignments (recall ~0.5, while precision ~0.99). . Deepvariant reached expected precision/recall (over 0.99) when using BAM produced by bwa-mem2 (duplicates were marked using `samtools markdup`) or snap-aligner. . So the issue seems to be related to hisat2 alignemnts (as marking duplicates using samtools is the same for hisat2 and bwa-mem2). Have anyone experienced similar problem before? . I'm using default settings for all programs. For hisat2 I'm using SNP-aware reference (grch38_snp) that suppose to align better SNP/INDEL containing reads.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/460
https://github.com/google/deepvariant/pull/461:83,performance,time,time,83,Add DeepVariant over the years blog post.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/461
https://github.com/google/deepvariant/pull/461:143,security,team,team,143,Add DeepVariant over the years blog post.; We are not taking pull requests at this time. This is an internal pull request from the DeepVariant team.,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/461
https://github.com/google/deepvariant/issues/462:252,availability,down,downloaded,252,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:393,availability,Operat,Operating,393,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1372,availability,Error,Error,1372,".md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2823,availability,Down,Downloaded,2823,"ete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.p",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:10,deployability,instal,install,10,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:18,deployability,fail,failing,18,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:223,deployability,instal,installed,223,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:466,deployability,version,version,466,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:498,deployability,Instal,Installation,498,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4692,deployability,fail,failed,4692,"I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise Calle",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5254,deployability,modul,module,5254,"py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your syste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:466,integrability,version,version,466,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3197,integrability,buffer,buffer,3197,"82e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5550,integrability,sub,subprocess,5550,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5643,integrability,sub,subprocess,5643,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5724,integrability,sub,subprocess,5724,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5809,integrability,buffer,buffer,5809,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:466,modifiability,version,version,466,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2965,modifiability,interm,intermediate,2965,"l complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Co",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3029,modifiability,Interm,Intermediate,3029,"mplete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6'",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4502,modifiability,deco,decode,4502,"""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5254,modifiability,modul,module,5254,"py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your syste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5314,modifiability,pac,packages,5314,"ativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvaria",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5414,modifiability,pac,packages,5414,"use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1372,performance,Error,Error,1372,".md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3154,performance,time,time,3154,"plete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr2",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3169,performance,parallel,parallel,3169,"39e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4673,performance,parallel,parallel,4673," NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5766,performance,time,time,5766,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5781,performance,parallel,parallel,5781,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:18,reliability,fail,failing,18,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4692,reliability,fail,failed,4692,"I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise Calle",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6213,reliability,Doe,Does,6213,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:840,safety,input,input,840,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:849,safety,input,input,849,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1090,safety,input,input,1090,"/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1147,safety,input,input,1147,"ribe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1372,safety,Error,Error,1372,".md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1523,safety,compl,complete,1523,"built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1553,safety,compl,complete,1553,"er. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1583,safety,compl,complete,1583,"g instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 946",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1613,safety,compl,complete,1613,", anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 294",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1643,safety,compl,complete,1643,"ike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1673,safety,compl,complete,1673,"tart data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1703,safety,compl,complete,1703,"e:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 902",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1733,safety,compl,complete,1733,"p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Dig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1763,safety,compl,complete,1763,"rmediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1793,safety,compl,complete,1793,"ION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1823,safety,compl,complete,1823,". -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Down",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1853,safety,compl,complete,1853,". -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1883,safety,compl,complete,1883," \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1913,safety,compl,complete,1913,"ference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1943,safety,compl,complete,1943,":""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1973,safety,compl,complete,1973,variant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2003,safety,compl,complete,2003, --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermedia,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2033,safety,compl,complete,2033,ference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermed,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2063,safety,compl,complete,2063,_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written t,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2093,safety,compl,complete,2093,G003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2123,safety,compl,complete,2123,p.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Ru,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2153,safety,compl,complete,2153,capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( tim,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2183,safety,compl,complete,2183, --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2213,safety,compl,complete,2213,tput.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvari,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2243,safety,compl,complete,2243,output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode c,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2273,safety,compl,complete,2273,". --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2303,safety,compl,complete,2303,"ntermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2333,safety,compl,complete,2333,"t/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2363,safety,compl,complete,2363,"`. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2393,safety,compl,complete,2393,"le). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_resu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2423,safety,compl,complete,2423," 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2453,safety,compl,complete,2453,"cally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/interme",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2483,safety,compl,complete,2483,"gle/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2513,safety,compl,complete,2513," Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2543,safety,compl,complete,2543," Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2573,safety,compl,complete,2573," Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2603,safety,compl,complete,2603," Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2633,safety,compl,complete,2633," Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2663,safety,compl,complete,2663," Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2693,safety,compl,complete,2693," Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2723,safety,compl,complete,2723," Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 1397889279",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3316,safety,input,input,3316,"9645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with Na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3507,safety,input,input,3507,"ll complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3630,safety,input,input,3630,"complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3765,safety,input,inputs,3765,"04f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3844,safety,input,input,3844,"or google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4274,safety,input,input,4274,"8_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4477,safety,input,input,4477,"tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4810,safety,input,input,4810,"nomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buff",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4995,safety,input,input,4995,"chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/interm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5254,safety,modul,module,5254,"py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your syste",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5928,safety,input,input,5928,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6119,safety,input,input,6119,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6234,safety,test,test,6234,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6273,safety,test,test,6273,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1523,security,compl,complete,1523,"built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1553,security,compl,complete,1553,"er. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1583,security,compl,complete,1583,"g instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 946",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1613,security,compl,complete,1613,", anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 294",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1643,security,compl,complete,1643,"ike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a9",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1673,security,compl,complete,1673,"tart data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 669",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1703,security,compl,complete,1703,"e:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 902",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1733,security,compl,complete,1733,"p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Dig",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1763,security,compl,complete,1763,"rmediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1793,security,compl,complete,1793,"ION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85a",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1823,security,compl,complete,1823,". -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Down",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1853,security,compl,complete,1853,". -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1883,security,compl,complete,1883," \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1913,security,compl,complete,1913,"ference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1943,security,compl,complete,1943,":""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1973,security,compl,complete,1973,variant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2003,security,compl,complete,2003, --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermedia,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2033,security,compl,complete,2033,ference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermed,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2063,security,compl,complete,2063,_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written t,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2093,security,compl,complete,2093,G003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2123,security,compl,complete,2123,p.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Ru,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2153,security,compl,complete,2153,capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( tim,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2183,security,compl,complete,2183, --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2213,security,compl,complete,2213,tput.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvari,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2243,security,compl,complete,2243,output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode c,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2273,security,compl,complete,2273,". --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh3",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2303,security,compl,complete,2303,"ntermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2333,security,compl,complete,2333,"t/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.w",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2363,security,compl,complete,2363,"`. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examp",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2393,security,compl,complete,2393,"le). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_resu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2423,security,compl,complete,2423," 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2453,security,compl,complete,2453,"cally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/interme",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2483,security,compl,complete,2483,"gle/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecor",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2513,security,compl,complete,2513," Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2543,security,compl,complete,2543," Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" -",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2573,security,compl,complete,2573," Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2603,security,compl,complete,2603," Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_r",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2633,security,compl,complete,2633," Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/H",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2663,security,compl,complete,2663," Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2693,security,compl,complete,2693," Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2723,security,compl,complete,2723," Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 1397889279",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:589,testability,instrument,instrument,589,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1378,testability,trace,trace,1378,"*Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 8283061",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5156,testability,Trace,Traceback,5156,"chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --t",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6234,testability,test,test,6234,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6273,testability,test,test,6273,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6453,testability,context,context,6453,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:284,usability,guid,guide,284,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:715,usability,Command,Command,715,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:840,usability,input,input,840,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:849,usability,input,input,849,"Fresh AWS install failing on quick start data; **Have you checked the FAQ? https://github.com/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1090,usability,input,input,1090,"/google/deepvariant/blob/r1.1/docs/FAQ.md**:. Yes. **Describe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull ",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1147,usability,input,input,1147,"ribe the issue:**. Launching an Ubuntu 20.04 server t2 micro EC2 on AWS, installed docker using snap, downloaded data from quickstart guide verbatim https://github.com/google/deepvariant/blob/r1.0/docs/deepvariant-quick-start.md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:1372,usability,Error,Error,1372,".md. **Setup**. - Operating system: Ubuntu 20.04 server t2 micro EC2 on AWS. - DeepVariant version: BIN_VERSION=""1.1.0"". - Installation method (Docker, built from source, etc.): Docker. - Type of data: (sequencing instrument, reference genome, anything special that is unlike the case studies?) Quick start data. **Steps to reproduce:**. - Command:. ```. mkdir -p output. mkdir -p output/intermediate_results_dir. BIN_VERSION=""1.1.0"". sudo docker run \. -v ""${PWD}/input"":""/input"" \. -v ""${PWD}/output"":""/output"" \. -v ""${PWD}/reference"":""/reference"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type WES \. --ref /reference/GRCh38_no_alt_analysis_set.fasta \. --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam \. --regions /input/idt_capture_novogene.grch38.bed \. --output_vcf /output/HG003.output.vcf.gz \. --output_gvcf /output/HG003.output.g.vcf.gz \. --num_shards $(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. - Error trace: (if applicable). ```. Unable to find image 'google/deepvariant:1.1.0' locally. 1.1.0: Pulling from google/deepvariant. be8ec4e48d7f: Pull complete . 33b8b485aff0: Pull complete . d887158cc58c: Pull complete . 05895bb28c18: Pull complete . 35be0878dcf6: Pull complete . 03fb656082b2: Pull complete . 1d3e393af6d8: Pull complete . 9663085972fa: Pull complete . 10ac03989960: Pull complete . 401f11974a9b: Pull complete . 67f12673f7e4: Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 8",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:2815,usability,Statu,Status,2815,"Pull complete . 99116330e4f4: Pull complete . 6fbbce8e3587: Pull complete . c223e83ce2e3: Pull complete . c02ebb3220a1: Pull complete . 0c7a427ce17a: Pull complete . ec9cd66333fe: Pull complete . 9d57046ae5b9: Pull complete . 0f5478ac499a: Pull complete . b07098b67a6d: Pull complete . 0accf0f55269: Pull complete . ccc95462eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomic",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3137,usability,command,command,3137,"2eb8f: Pull complete . f1416983139e: Pull complete . 2242c582e0cc: Pull complete . 8f749be1be0b: Pull complete . 03fdf02906f9: Pull complete . ea2763a10d98: Pull complete . fff529645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18',",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3316,usability,input,input,3316,"9645086: Pull complete . 42ad15be12fa: Pull complete . 82830610edc8: Pull complete . d1a85d710a45: Pull complete . a7463a89d05f: Pull complete . 966acfe9e7ff: Pull complete . 987808dd3c93: Pull complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with Na",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3507,usability,input,input,3507,"ll complete . 079d9da9d9ee: Pull complete . 875aa906c231: Pull complete . 9463688d586c: Pull complete . 2943d0ab0b4f: Pull complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode C",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3630,usability,input,input,3630,"complete . 7a91c30c18a7: Pull complete . 66996f762384: Pull complete . 90237953ba0a: Pull complete . Digest: sha256:b269b5b547bd8aa46f104f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] S",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3765,usability,input,inputs,3765,"04f7bbdffaf6cdcf1df0143cfe85aa7f5a68767fa49bc. Status: Downloaded newer image for google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:3844,usability,input,input,3844,"or google/deepvariant:1.1.0. I0611 15:20:51.532788 140688071014144 run_deepvariant.py:317] Re-using the directory for intermediate results in /output/intermediate_results_dir. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4274,usability,input,input,4274,"8_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main).",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4477,usability,input,input,4477,"tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} ). I0611 15:20:58.470178 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.487128 139788927993600 make_examples.py:648] Preparing inputs. I0611 15:20:58.513385 139788927993600 genomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4810,usability,input,input,4810,"nomics_reader.py:223] Reading /input/HG003.novaseq.wes_idt.100x.dedup.bam with NativeSamReader. I0611 15:20:58.537174 139788927993600 make_examples.py:648] Common contigs are ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buff",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:4995,usability,input,input,4995,"chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/interm",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5059,usability,user,user,5059,"'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX', 'chrY', 'chrM']. I0611 15:20:58.552222 139788927993600 genomics_reader.py:223] Reading /input/idt_capture_novogene.grch38.bed with NativeBedReader. I0611 15:22:06.001182 139788927993600 make_examples.py:648] Starting from v0.9.0, --use_ref_for_cram is default to true. If you are using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5572,usability,command,command,5572,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5755,usability,Command,Command,5755,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:5928,usability,input,input,5928,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6119,usability,input,input,6119,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/462:6194,usability,statu,status,6194,"e using CRAM input, note that we will decode CRAM using the reference you passed in with --ref. 2021-06-11 15:22:06.016750: I third_party/nucleus/io/sam_reader.cc:662] Setting HTS_OPT_BLOCK_SIZE to 134217728. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /reference/GRCh38_no_alt_analysis_set.fasta --reads /input/HG003.novaseq.wes_idt.100x.dedup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --regions /input/idt_capture_novogene.grch38.bed --task 0. real	1m16.629s. user	1m9.338s. sys	0m1.008s. I0611 15:22:08.176606 140688071014144 run_deepvariant.py:416] None. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 421, in <module>. app.run(main). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run. _run_main(main, args). File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 414, in main. subprocess.check_call(command, shell=True, executable='/bin/bash'). File ""/usr/lib/python3.6/subprocess.py"", line 311, in check_call. raise CalledProcessError(retcode, cmd). subprocess.CalledProcessError: Command '( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""/input/HG003.novaseq.wes_idt.100x.dedup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --regions ""/input/idt_capture_novogene.grch38.bed"" --task {} )' returned non-zero exit status 247. ```. **Does the quick start test work on your system?** No. Please test with https://github.com/google/deepvariant/blob/r0.10/docs/deepvariant-quick-start.md. Is there any way to reproduce the issue by using the quick start? Yes. **Any additional context:**.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/462
https://github.com/google/deepvariant/issues/463:97,availability,cluster,cluster,97,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:215,availability,slo,slow,215,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:97,deployability,cluster,cluster,97,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:280,energy efficiency,alloc,allocate,280,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:294,energy efficiency,cpu,cpu,294,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:298,energy efficiency,core,core,298,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:21,performance,time,time,21,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:294,performance,cpu,cpu,294,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:307,performance,memor,memory,307,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:215,reliability,slo,slow,215,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:314,reliability,doe,does,314,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:360,reliability,doe,does,360,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:307,usability,memor,memory,307,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/463:323,usability,help,help,323,very long processing time of running deepvariant on a HPC server ; I am using deepvariant on our cluster using singularity. I could setup singularity and get it running. My problem now is that the process is pretty slow and it takes more than a day for just one sample. However I allocate more cpu core and memory does not help. Increasing the number of shard does not resolve it and even make it worse. Could someone please give me some clue on how to find it solution for this issue?,MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/463
https://github.com/google/deepvariant/issues/464:378,interoperability,specif,specific,378,"Recommendations regarding minimum values for advancing candidates in make_examples?; Hello,. I was wondering if you had any recommendations as far as deviating from default values for options like `--min_base_quality`, `--min_mapping_quality`, `--vsc_min_count_snps`, etc. when running `make_examples` for retraining DeepVariant? How were the default values selected? Are there specific situations in which you would recommend changing them? . Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/464
https://github.com/google/deepvariant/issues/464:26,usability,minim,minimum,26,"Recommendations regarding minimum values for advancing candidates in make_examples?; Hello,. I was wondering if you had any recommendations as far as deviating from default values for options like `--min_base_quality`, `--min_mapping_quality`, `--vsc_min_count_snps`, etc. when running `make_examples` for retraining DeepVariant? How were the default values selected? Are there specific situations in which you would recommend changing them? . Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/464
https://github.com/google/deepvariant/issues/464:463,usability,help,help,463,"Recommendations regarding minimum values for advancing candidates in make_examples?; Hello,. I was wondering if you had any recommendations as far as deviating from default values for options like `--min_base_quality`, `--min_mapping_quality`, `--vsc_min_count_snps`, etc. when running `make_examples` for retraining DeepVariant? How were the default values selected? Are there specific situations in which you would recommend changing them? . Thank you for your help!",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/464
https://github.com/google/deepvariant/issues/465:62,availability,error,error,62,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:128,availability,cluster,cluster,128,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:145,availability,error,error,145,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:207,availability,error,error,207,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1921,availability,checkpoint,checkpoint,1921,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:14,deployability,fail,failed,14,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:128,deployability,cluster,cluster,128,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:444,deployability,log,logs,444,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:460,deployability,log,logs,460,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:591,deployability,log,logs,591,"parallel: job failed:; Does anyone know what caused the below error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/log",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1060,deployability,log,logs,1060,"error? I use deepvariant image on singularity and running it on a cluster but this error happens on many machines. I don't know what causes this error. I0624 02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.15",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1218,deployability,log,logs,1218,"02:14:00.095050 47429297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/outpu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1237,deployability,log,log,1237,"29297437696 run_deepvariant.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_resu",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1261,deployability,fail,failed,1261,"nt.py:313] Creating a directory for intermediate results in /output/intermediate_results_dir. I0624 02:14:01.826225 47429297437696 run_deepvariant.py:405] Creating a directory for logs in /output/logs. I0624 02:14:01.954994 47429297437696 run_deepvariant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_out",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1513,deployability,log,logs,1513,"ant.py:227] Creating a make_examples runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1997,deployability,log,logs,1997,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:2016,deployability,log,log,2016,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:2473,deployability,log,logs,2473,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:2499,deployability,log,log,2499,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1938,energy efficiency,model,models,1938,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
https://github.com/google/deepvariant/issues/465:1949,energy efficiency,model,model,1949,"les runtime by region directory in /output/logs/make_examples_runtime_by_region. ***** Intermediate results will be written to /output/intermediate_results_dir in docker. ****. ***** Running the command:*****. ( time seq 0 0 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --reads ""/input/S-001737188.markdup.bam"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --runtime_by_region ""/output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv"" --gvcf ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --task {} ) 2>&1 | tee /output/logs/make_examples.log. parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref /ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --reads /input/S-001737188.markdup.bam --examples /output/intermediate_results_dir/make_examples.tfrecord@1.gz --runtime_by_region /output/logs/make_examples_runtime_by_region/make_examples_runtime@1.tsv --gvcf /output/intermediate_results_dir/gvcf.tfrecord@1.gz --task 0. real	14m5.230s. user	0m1.869s. sys	0m3.689s. ***** Running the command:*****. ( time /opt/deepvariant/bin/call_variants --outfile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --examples ""/output/intermediate_results_dir/make_examples.tfrecord@1.gz"" --checkpoint ""/opt/models/wgs/model.ckpt"" --use_openvino ) 2>&1 | tee /output/logs/call_variants.log. real	6m35.370s. user	0m1.385s. sys	0m1.152s. ***** Running the command:*****. ( time /opt/deepvariant/bin/postprocess_variants --ref ""/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa"" --infile ""/output/intermediate_results_dir/call_variants_output.tfrecord.gz"" --outfile ""/output/S-001737188.vcf.gz"" --nonvariant_site_tfrecord_path ""/output/intermediate_results_dir/gvcf.tfrecord@1.gz"" --gvcf_outfile ""/output/S-001737188.g.vcf.gz"" ) 2>&1 | tee /output/logs/postprocess_variants.log. real	10m14.442s. user	0m1.472s. sys	0m1.164s",MatchSource.ISSUE,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/465
